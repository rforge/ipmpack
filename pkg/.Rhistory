cor.test(c(dff$hdi[,1]),c(rowMeans(log(dff$unvacc.ppsize.measles),na.rm=TRUE))))
names(dff)
cor.test(c(dff$hdi[,1]),c(rowMeans(log(dff$unvacc.pop.rubella),na.rm=TRUE))))
cor.test(c(dff$hdi[,1]),c(rowMeans(log(dff$unvacc.pop.rubella),na.rm=TRUE)))
 cor.test(c(dff$hdi[,1]),c(rowMeans(log(dff$unvacc.pop.rubella),na.rm=TRUE)))#
 cor.test(c(dff$hdi[,1]),c(rowMeans(log(dff$unvacc.pop.measles),na.rm=TRUE)))#
 cor.test(c(dff$hdi[,1]),c(rowMeans(log(dff$unvacc.pop.pertussis),na.rm=TRUE)))
cor.test(c(dff$hdi[,1]),c(rowMeans(log(dff$unvacc.pop.rubella),na.rm=TRUE))))
names( b0.1)
summary(b0.1[[1]])
summary(b1.1[[1]])
summary(b2.1[[1]])
   tmp<-predictFit(b1[[1]],dff,disease="rubella", just.odds=TRUE)
    #picGGplot(b0,b1,b2, ymax=5)#
    HistMedPopSizeMedGGplot(dff,b0.1,b1.1,b2.1)#
    HistMedPopSizeExtremeGGplot(dff,b0.1,b1.1,b2.1)
reload.source()
    #picGGplot(b0,b1,b2, ymax=5)#
    HistMedPopSizeMedGGplot(dff,b0.1,b1.1,b2.1)#
    HistMedPopSizeExtremeGGplot(dff,b0.1,b1.1,b2.1)
picGGplot(b0.1,b1.1,b2.1, ymax=5)
sumary(b0[[1]])
summary(b0[[1]])
summary(b0[[2]])
summary(b0[[3]])
  #just main effects#
    b0 <- checkBasicRelsBayes(dff,disease="rubella", explV="y~x.unvacc.kids+x.hdi+x.nmigrants+x.isl",add=FALSE)#
    b1 <- checkBasicRelsBayes(dff,disease="measles", explV="y~x.unvacc.kids+x.hdi+x.nmigrants+x.isl",add=TRUE)#
    b2 <- checkBasicRelsBayes(dff,disease="pertussis", explV="y~x.unvacc.kids+x.hdi+x.nmigrants+x.isl",add=TRUE)#
#
    #picGGplot(b0,b1,b2, ymax=5)#
    HistMedPopSizeMedGGplot(dff,b0,b1,b2)#
    HistMedPopSizeExtremeGGplot(dff,b0,b1,b2)
summary(b2[[3]])
summary(b2.1[[1]])
plot(b2.1[[1]])
plot(b2.1[[3]])
reload.source()
#
    #just main effects#
    b0 <- checkBasicRelsBayes(dff,disease="rubella", explV="y~x.unvacc.kids+x.hdi+x.nmigrants+x.isl",add=FALSE)#
    b1 <- checkBasicRelsBayes(dff,disease="measles", explV="y~x.unvacc.kids+x.hdi+x.nmigrants+x.isl",add=TRUE)#
    b2 <- checkBasicRelsBayes(dff,disease="pertussis", explV="y~x.unvacc.kids+x.hdi+x.nmigrants+x.isl",add=TRUE)#
#
    #picGGplot(b0,b1,b2, ymax=5)#
    HistMedPopSizeMedGGplot(dff,b0,b1,b2)#
    HistMedPopSizeExtremeGGplot(dff,b0,b1,b2)#
    #
    quartz()#
    #all the two-ways, except those with islands. CURRENT IMPLEMENTED#
    explVar <- "y~x.unvacc.kids+x.hdi+x.nmigrants+x.isl+x.unvacc.kids:x.hdi+x.unvacc.kids:x.nmigrants+x.hdi:x.nmigrants"#
    b0.1 <- checkBasicRelsBayes(dff,disease="rubella",explV=explVar,add=FALSE, interactions=TRUE)#
    b1.1 <- checkBasicRelsBayes(dff,disease="measles",explV=explVar,add=TRUE, interactions=TRUE)#
    b2.1 <- checkBasicRelsBayes(dff,disease="pertussis",explV=explVar,add=TRUE, interactions=TRUE)#
#
    #picGGplot(b0.1,b1.1,b2.1, ymax=5)#
    HistMedPopSizeMedGGplot(dff,b0.1,b1.1,b2.1)#
    HistMedPopSizeExtremeGGplot(dff,b0.1,b1.1,b2.1)
plot(b2.1[[3]])
reload.source()
  b2.1 <- checkBasicRelsBayes(dff,disease="pertussis",explV=explVar,add=TRUE, interactions=TRUE)
plot(b2.1[[3]])
  HistMedPopSizeMedGGplot(dff,b0.1,b1.1,b2.1)
reload.source()
  b2.1 <- checkBasicRelsBayes(dff,disease="pertussis",explV=explVar,add=TRUE, interactions=TRUE)
  HistMedPopSizeMedGGplot(dff,b0.1,b1.1,b2.1)
plot(b2.1[[3]])
summary(b2.1[[3]])
library(MCMCglmm)
?MCMCglmm
?predict.glm
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Impl.r")#
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Base.r")#
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Util.r")
dff <- generateData()#
Tmatrix <- create.compound.Tmatrix(minSize = min(dff$size,na.rm=TRUE), maxSize = max(dff$size,na.rm = TRUE), envMatrix = makeEnvObj(dff), growObj = makeGrowthObj(dff, explanatoryVariables = "size+size2+covariate"), survObj = makeSurvObj(dff, explanatoryVariables = "size+size2+covariate"))
slotNames(Tmatrix)
makeFecObj
dff <- generateDataDiscrete()
table(dff$stage)
makediscreteTrans
create.IPM.Tmatrix
 makeListFmatrix
dff <- generateData()#
grlist <- makePostGrowthObjs(dff, explanatoryVariables="size",nitt = 5000)#
svlist <- makePostSurvivalObjs(dff, explanatoryVariables="size", nitt = 5000)
TmatrixList <- makeListTmatrix(grlist,svlist,#
		nBigMatrix=20,#
		minSize=-5,#
		maxSize=35)
res <- getIPMoutput(TmatrixList, targetSize=5, Fmatrixlist=NULL)#
names(res)
fv <- makePostFecObjs(dff, explanatoryVariables="size+size2", #
		nitt=10000,Transform="log")#
FmatrixList <- makeListFmatrix(fv,nBigMatrix=20,minSize=-5,maxSize=35,cov=FALSE)#
res <- getIPMoutput(TmatrixList,targetSize=5,FmatrixList)
length(FmatrixList )
getIPMoutput
length(Tmatrixlist)
TmatrixList
length(TmatrixList)
length(FmatrixList)
res <- getIPMoutput(TmatrixList[1:length(FmatrixList)],targetSize=5,FmatrixList)
par(mfrow=c(2,2),bty="l")#
nmesh <- TmatrixList[[1]]@nBigMatrix#
CI <- apply(res$LE,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$LE), type="n",xlab="Size", ylab="Life expectancy",#
     ylim=range(quantile(res$LE,c(0.025,0.975), na.rm=TRUE)), xlim=range(dff$size,na.rm=TRUE))#
     #
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$LE),type="l",lty=3)#
#
CI <- apply(res$ptime,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$ptime),#
     type="n",xlab="Size", ylab="Passage time", xlim=range(dff$size[dff$size<5], na.rm=TRUE),#
     ylim=range(quantile(res$ptime[,TmatrixList[[1]]@meshpoints<max(dff$size,na.rm=T)],c(0.025,0.975),na.rm=TRUE)))#
#
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$ptime),type="l",lty=3)#
#
res$stable.size <- abs(Re(res$stable.size))#
res$stable.size <- res$stable.size/rowSums(res$stable.size)#
res$stable.size[!is.finite(res$stable.size) | is.na(res$stable.size)] <- 0#
CI <- apply(res$stable.size,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$stable.size), type="n",xlab="Size", ylab="Stable.size",#
     ylim=range(quantile(res$stable.size,c(0.025,0.975), na.rm=TRUE)))#
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$stable.size, na.rm=TRUE),type="l",lty=3)#
#
hist(res$lambda,xlab=expression(lambda),ylab="",main="")
names(res)
par(mfrow=c(2,2),bty="l")#
nmesh <- TmatrixList[[1]]@nBigMatrix#
CI <- apply(res$LE,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$LE), type="n",xlab="Size", ylab="Life expectancy",#
     ylim=range(quantile(res$LE,c(0.025,0.975), na.rm=TRUE)), xlim=range(dff$size,na.rm=TRUE))#
     #
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$LE),type="l",lty=3)#
#
CI <- apply(res$pTime,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$ptime),#
     type="n",xlab="Size", ylab="Passage time", xlim=range(dff$size[dff$size<5], na.rm=TRUE),#
     ylim=range(quantile(res$pTime[,TmatrixList[[1]]@meshpoints<max(dff$size,na.rm=T)],#
					 c(0.025,0.975),na.rm=TRUE)))#
#
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$pTime),type="l",lty=3)#
#
res$stable.size <- abs(Re(res$stableSize))#
res$stable.size <- res$stableSize/rowSums(res$stableSize)#
res$stable.size[!is.finite(res$stableSize) | is.na(res$stableSize)] <- 0#
CI <- apply(res$stableSize,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$stableSize), type="n",#
		xlab="Size", ylab="Stable.size",#
     ylim=range(quantile(res$stableSize,c(0.025,0.975), na.rm=TRUE)))#
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$stableSize, na.rm=TRUE),type="l",lty=3)#
#
hist(res$lambda,xlab=expression(lambda),ylab="",main="")
par(mfrow=c(2,2),bty="l")#
nmesh <- TmatrixList[[1]]@nBigMatrix#
CI <- apply(res$LE,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$LE), type="n",xlab="Size", ylab="Life expectancy",#
     ylim=range(quantile(res$LE,c(0.025,0.975), na.rm=TRUE)), xlim=range(dff$size,na.rm=TRUE))#
     #
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$LE),type="l",lty=3)#
#
CI <- apply(res$pTime,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$ptime),#
     type="n",xlab="Size", ylab="Passage time", xlim=range(dff$size[dff$size<5], na.rm=TRUE),#
     ylim=range(quantile(res$pTime[,TmatrixList[[1]]@meshpoints<max(dff$size,na.rm=T)],#
					 c(0.025,0.975),na.rm=TRUE)))#
#
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$pTime),type="l",lty=3)#
#
res$stableSize <- abs(Re(res$stableSize))#
res$stableSize <- res$stableSize/rowSums(res$stableSize)#
res$stableSize[!is.finite(res$stableSize) | is.na(res$stableSize)] <- 0#
CI <- apply(res$stableSize,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$stableSize), type="n",#
		xlab="Size", ylab="Stable.size",#
     ylim=range(quantile(res$stableSize,c(0.025,0.975), na.rm=TRUE)))#
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$stableSize, na.rm=TRUE),type="l",lty=3)#
#
hist(res$lambda,xlab=expression(lambda),ylab="",main="")
names(res)
res <- getIPMoutput(TmatrixList[1:length(FmatrixList)],targetSize=5,FmatrixList)
par(mfrow=c(2,2),bty="l")#
nmesh <- TmatrixList[[1]]@nBigMatrix#
CI <- apply(res$LE,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$LE), type="n",xlab="Size", ylab="Life expectancy",#
     ylim=range(quantile(res$LE,c(0.025,0.975), na.rm=TRUE)), xlim=range(dff$size,na.rm=TRUE))#
     #
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$LE),type="l",lty=3)#
#
CI <- apply(res$pTime,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$pTime),#
     type="n",xlab="Size", ylab="Passage time", xlim=range(dff$size[dff$size<5], na.rm=TRUE),#
     ylim=range(quantile(res$pTime[,TmatrixList[[1]]@meshpoints<max(dff$size,na.rm=T)],#
					 c(0.025,0.975),na.rm=TRUE)))#
#
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$pTime),type="l",lty=3)#
#
res$stableSize <- abs(Re(res$stableSize))#
res$stableSize <- res$stableSize/rowSums(res$stableSize)#
res$stableSize[!is.finite(res$stableSize) | is.na(res$stableSize)] <- 0#
CI <- apply(res$stableSize,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$stableSize), type="n",#
		xlab="Size", ylab="Stable.size",#
     ylim=range(quantile(res$stableSize,c(0.025,0.975), na.rm=TRUE)))#
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$stableSize, na.rm=TRUE),type="l",lty=3)#
#
hist(res$lambda,xlab=expression(lambda),ylab="",main="")
names(res)
res <- getIPMoutput(TmatrixList[1:length(FmatrixList)],targetSize=5,FmatrixList)
Re(res$stableSize)
res$stableSize
names(res)
getIPMoutput
par(mfrow=c(2,2),bty="l")#
nmesh <- TmatrixList[[1]]@nBigMatrix#
CI <- apply(res$LE,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$LE), type="n",xlab="Size", ylab="Life expectancy",#
     ylim=range(quantile(res$LE,c(0.025,0.975), na.rm=TRUE)), xlim=range(dff$size,na.rm=TRUE))#
     #
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$LE),type="l",lty=3)#
#
CI <- apply(res$pTime,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$pTime),#
     type="n",xlab="Size", ylab="Passage time", xlim=range(dff$size[dff$size<5], na.rm=TRUE),#
     ylim=range(quantile(res$pTime[,TmatrixList[[1]]@meshpoints<max(dff$size,na.rm=T)],#
					 c(0.025,0.975),na.rm=TRUE)))#
#
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$pTime),type="l",lty=3)#
#
res$stableStage <- abs(Re(res$stableStage))#
res$stableStage <- res$stableStage/rowSums(res$stableStage)#
res$stableStage[!is.finite(res$stableStage) | is.na(res$stableStage)] <- 0#
CI <- apply(res$stableStage,2,quantile,c(0.025,0.975))#
#
plot(TmatrixList[[1]]@meshpoints,colMeans(res$stableStage), type="n",#
		xlab="Size", ylab="Stable.size",#
     ylim=range(quantile(res$stableStage,c(0.025,0.975), na.rm=TRUE)))#
polygon(c(TmatrixList[[1]]@meshpoints)[c(1:nmesh,nmesh:1)],#
        c(CI[1,1:nmesh],CI[2,nmesh:1]),col="grey",border="white")#
points(TmatrixList[[1]]@meshpoints,colMeans(res$stableStage, na.rm=TRUE),type="l",lty=3)#
#
hist(res$lambda,xlab=expression(lambda),ylab="",main="")
create.IPM.Tmatrix
length(fv)
fv <- makePostFecObjs(dff, explanatoryVariables="size+size2", #
		nitt=10000,Transform="log")
length(fv)
fv[[1]]
length(fv)
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Impl.r")#
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Base.r")#
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Util.r")
fv <- makePostFecObjs(dff, explanatoryVariables="size+size2", #
		nitt=10000,Transform="log")
-MCMCglmm
MCMCglmm
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Impl.r")#
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Base.r")#
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Util.r")
fv <- makePostFecObjs(dff, explanatoryVariables="size+size2", #
		nitt=10000,Transform="log")
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Impl.r")#
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Base.r")#
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Util.r")
fv <- makePostFecObjs(dff, explanatoryVariables="size+size2", #
		nitt=10000,Transform="log")
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Impl.r")#
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Base.r")#
source("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/R/IPMpack-Util.r")
fv <- makePostFecObjs(dff, explanatoryVariables="size+size2", #
		nitt=10000,Transform="log")
dff <- generateData()#
grlist <- makePostGrowthObjs(dff, explanatoryVariables="size",nitt = 5000)#
svlist <- makePostSurvivalObjs(dff, explanatoryVariables="size", nitt = 5000)
TmatrixList <- makeListTmatrix(grlist,svlist,#
		nBigMatrix=20,#
		minSize=-5,#
		maxSize=35,correction="constant")
res <- getIPMoutput(TmatrixList, targetSize=5, Fmatrixlist=NULL)#
names(res)
fv <- makePostFecObjs(dff, explanatoryVariables="size+size2", #
		nitt=10000,Transform="log")#
FmatrixList <- makeListFmatrix(fv,nBigMatrix=20,minSize=-5,maxSize=35,cov=FALSE, correction="constant")#
res <- getIPMoutput(TmatrixList[1:length(FmatrixList)],targetSize=5,FmatrixList)
length(FmatrixList)
length(TmatrixList)
#
#
## Build a function to get stoch rate increase#
##
##
TrackPopStruct <- function(age.classes=1:50,#
			mort=c(0.18950, 0.04376, 0.02816, 0.01862, 0.01212, 0.00940, 0.00789, #
0.00682, 0.00589, 0.00568, 0.00601, 0.00574, 0.00546,0.00516, 0.00445, 0.00437, 0.00479, 0.00531, #
0.00556, 0.00554, 0.00584, 0.00675, 0.00759, 0.00702, 0.00653, 0.00650, 0.00652, 0.00685, 0.00858, #
0.00888, 0.00782, 0.00756, 0.00784, 0.00808, 0.00809, 0.00888, 0.00994, 0.00983, 0.00967, 0.00972,#
0.00994, 0.00948, 0.00948, 0.00953, 0.01012, 0.01049, 0.01065, 0.01109, 0.01130, 0.01152),   #one for every age class (danish 1835 cohort here)#
			mu.sick=1.01,	#how much more likely sick are to die#
			beta=c(0.1), #
			waning.maternal.par=1,#
			waning.immunity=0,#
			fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
			period=100,alpha=0.6,mag=0.8,Tmax=5000, n.runin=1000){#
			require(MASS)#
			#
			#get Fmatrix (won't change)#
			Fmat <- buildFMatrix(age.classes=age.classes,fert=fert)#
			#
			#get seasonal trans#
			seasTrans <- periodTrans(period=period,alpha=alpha,mag=mag,Tmax=Tmax)		#
#
			nt<-rep(0,length(age.classes)*4)#
			nt[1+seq(1,length(age.classes)*4,by=4)] <- 1#
			nt[2+seq(1,5*4,by=4)] <- 1#
			nt.store<-matrix(NA,length(age.classes)*4,Tmax)#
			#
			for (t in 1:Tmax) {#
				#build Tmat	#
				Tmat <- buildTMatrix(age.classes=age.classes,#
				mort=mort,   #one for every age class (danish 1835 cohort here)#
				mu.sick=mu.sick,	#how much more likely sick are to die#
				beta=seasTrans[t], #
				waning.maternal.par=waning.maternal.par,#
				waning.immunity=waning.immunity)#
#
				nt1<-(Tmat+Fmat) %*% nt	#
				nt.store[,t]<-nt1#
				nt<-nt1#
				#
			}#
			#
			m.inds <- seq(1,length(age.classes)*4,by=4)#
			s.inds <- m.inds+1			#
			i.inds <- m.inds+2			#
			r.inds <- m.inds+3			#
#
			return(list(nt.store=nt.store,m.inds=m.inds,s.inds=s.inds,i.inds=i.inds,r.inds=r.inds,seasTrans=seasTrans))#
		}
	a1<-TrackPopStruct(period=10)#
	b1<-TrackPopStruct(period=100)#
#
	par(mfrow=c(2,2),bty="l")#
	tlim <- 3000:3200#
	plot(colSums(a1[[1]][a1[[2]],tlim]), xlab="time", ylab="M", type="l")#
	points(colSums(	b1[[1]][b1[[2]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[3]],tlim]), xlab="time", ylab="S", type="l")#
	points(colSums(	b1[[1]][b1[[3]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[4]],tlim]), xlab="time", ylab="I", type="l")#
	points(colSums(	b1[[1]][b1[[4]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[5]],tlim]), xlab="time", ylab="R", type="l")#
	points(colSums(	b1[[1]][b1[[5]],tlim]), type="l", col=2)#
#
	par(mfrow=c(2,2)) #pop structure#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[2]],tlim])), xlab="time", ylab="age",main="M")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[3]],tlim])), xlab="time", ylab="age",main="S")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[4]],tlim])), xlab="time", ylab="age",main="I")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[5]],tlim])), xlab="time", ylab="age",main="R")#
#
	#total pop size compare#
	plot(colSums(a1[[1]][,tlim]), xlab="time", ylab="M", type="l")#
	points(colSums(b1[[1]][,tlim]), type="l",col=2)	#
#
	#highlights that problem with comparison across different seasonalities is that the more frequent have higher risk death anyway#
	mean(diff(colSums(a1[[1]][,tlim])))#
	mean(diff(colSums(b1[[1]][,tlim])))#
#
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,1,length=50)#
	pd <- c(2,10,100,200)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 5000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.01*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
#
		}}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")
#
#
## Function to simulate evolution of maternal immunity   #########################
# Need: M, S, I, R classes, structured over age#
#  S gives birth to S#
#  I and R give birth to M#
#  I dies at a rate defined by age survival * mu.sick#
#  Infection rate imposed externally (because want to explore different periodicities, etc)#
#
# Parameter explored = duration maternal immunity #
# Potential extra adv - if you move into R maybe you have slightly higher mortality because part of your memory is tied up. #
#
# Do yearly time-step (cos why not)#
# Calculate lambda_s#
#
#
#
## Funtion to build survival T transitions#
## an infection #
# #
buildTMatrix <- function(age.classes=1:50,#
			mort=c(0.18950, 0.04376, 0.02816, 0.01862, 0.01212, 0.00940, 0.00789, #
0.00682, 0.00589, 0.00568, 0.00601, 0.00574, 0.00546,0.00516, 0.00445, 0.00437, 0.00479, 0.00531, #
0.00556, 0.00554, 0.00584, 0.00675, 0.00759, 0.00702, 0.00653, 0.00650, 0.00652, 0.00685, 0.00858, #
0.00888, 0.00782, 0.00756, 0.00784, 0.00808, 0.00809, 0.00888, 0.00994, 0.00983, 0.00967, 0.00972,#
0.00994, 0.00948, 0.00948, 0.00953, 0.01012, 0.01049, 0.01065, 0.01109, 0.01130, 0.01152),   #one for every age class (danish 1835 cohort here)#
			mu.sick=1.01,	#how much more likely sick are to die#
			beta=c(0.1), #
			waning.maternal.par=1,#
			waning.immunity=0){#
#
	nage <- length(age.classes)#
	if (length(beta)==1) beta <- rep(beta,nage)#
	if (length(waning.immunity)==1) waning.immunity <- rep(waning.immunity,nage)	#
#
	waning.maternal<-exp(-waning.maternal.par*(age.classes))#
#
	mat1 <- matrix(0,4,4)#
#
	Tmat <- matrix(0,4*nage,4*nage)#
	for (j in 1:nage) { #
		#fill in epi matrix#
		mat1[] <- 0#
		mat1[1,1] <- waning.maternal[j]#
		mat1[2,1] <- 1-waning.maternal[j]#
		mat1[2,2] <- 1-beta[j]#
		mat1[3,2] <- beta[j]#
		mat1[4,3] <- 1#
		mat1[4,4] <- 1-waning.immunity[j]#
		mat1[2,4] <- waning.immunity[j]#
		#put in surv#
		surv <- rep(1-mort[j],4); surv[3] <- 1-(mu.sick*mort[j])#
		#fill in Tmatrix#
		if (j!=nage) { #
			Tmat[(j*4+1):(j*4+4),((j-1)*4+1):(j*4)] <- mat1*surv#
		} else { #
			Tmat[((j-1)*4+1):(j*4),((j-1)*4+1):(j*4)] <- mat1#
		}#
	}#
#
	return(Tmat)	#
#
}#
#
#
## Funtion to build fertility transitions#
## (prob only needs to happen once  #
# #
buildFMatrix <- function(age.classes=1:50,#
			fert=dnorm(1:50,25,5)){ 	#one for every age class#
	fert[age.classes<15] <- 0#
#
	nage <- length(age.classes)#
#
	Fmat <- matrix(0,4*nage,4*nage)#
	for (j in 1:nage) { #
		Fmat[1,((j-1)*4+1):(j*4)] <- c(0,0,fert[j],fert[j]) #the mat immune#
		Fmat[2,((j-1)*4+1):(j*4)]<- c(fert[j],fert[j],0,0) #the susceptible (mom didn't get sick)#
	}#
#
	return(Fmat)#
}#
#
#
#
#
## Build different yearly periodicity in trans#
##
periodTrans <- function(period=100,alpha=0.2,mag=0.01,Tmax=10000) { #
#
	u <- alpha*cos(2*pi*(1:Tmax)/period))#
	return(mag*(1+u))#
}#
#
#
## Build a function to get stoch rate increase#
##
##
StochGrowthRate <- function(age.classes=1:50,#
			mort=c(0.18950, 0.04376, 0.02816, 0.01862, 0.01212, 0.00940, 0.00789, #
0.00682, 0.00589, 0.00568, 0.00601, 0.00574, 0.00546,0.00516, 0.00445, 0.00437, 0.00479, 0.00531, #
0.00556, 0.00554, 0.00584, 0.00675, 0.00759, 0.00702, 0.00653, 0.00650, 0.00652, 0.00685, 0.00858, #
0.00888, 0.00782, 0.00756, 0.00784, 0.00808, 0.00809, 0.00888, 0.00994, 0.00983, 0.00967, 0.00972,#
0.00994, 0.00948, 0.00948, 0.00953, 0.01012, 0.01049, 0.01065, 0.01109, 0.01130, 0.01152),   #one for every age class (danish 1835 cohort here)#
			mu.sick=1.01,	#how much more likely sick are to die#
			beta=c(0.1), #
			waning.maternal.par=1,#
			waning.immunity=0,#
			fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
			period=100,alpha=0.2,mag=0.01,Tmax=5000, n.runin=1000){#
			require(MASS)#
			#
			#get Fmatrix (won't change)#
			Fmat <- buildFMatrix(age.classes=age.classes,fert=fert)#
			#
			#get seasonal trans#
			seasTrans <- periodTrans(period=period,alpha=alpha,mag=mag,Tmax=Tmax)		#
#
			nt<-rep(0,length(age.classes)*4)#
			nt[1+seq(1,length(age.classes)*4,by=4)] <- 1#
			nt[2+seq(1,5*4,by=4)] <- 1#
			Rt<-rep(NA,Tmax)#
			#
			for (t in 1:Tmax) {#
				#build Tmat	#
				Tmat <- buildTMatrix(age.classes=age.classes,#
				mort=mort,   #one for every age class (danish 1835 cohort here)#
				mu.sick=mu.sick,	#how much more likely sick are to die#
				beta=seasTrans[t], #
				waning.maternal.par=waning.maternal.par,#
				waning.immunity=waning.immunity)#
#
				nt1<-(Tmat+Fmat) %*% nt	#
				sum.nt1<-sum(nt1)#
				Rt[t]<-log(sum.nt1)#
				nt<-nt1/sum.nt1#
				#
			}#
			#
			res <- mean(Rt[n.runin:Tmax],na.rm=TRUE)#
			return(res)#
		}#
#
#
#
#
## Build a function to get stoch rate increase#
##
##
TrackPopStruct <- function(age.classes=1:50,#
			mort=c(0.18950, 0.04376, 0.02816, 0.01862, 0.01212, 0.00940, 0.00789, #
0.00682, 0.00589, 0.00568, 0.00601, 0.00574, 0.00546,0.00516, 0.00445, 0.00437, 0.00479, 0.00531, #
0.00556, 0.00554, 0.00584, 0.00675, 0.00759, 0.00702, 0.00653, 0.00650, 0.00652, 0.00685, 0.00858, #
0.00888, 0.00782, 0.00756, 0.00784, 0.00808, 0.00809, 0.00888, 0.00994, 0.00983, 0.00967, 0.00972,#
0.00994, 0.00948, 0.00948, 0.00953, 0.01012, 0.01049, 0.01065, 0.01109, 0.01130, 0.01152),   #one for every age class (danish 1835 cohort here)#
			mu.sick=1.01,	#how much more likely sick are to die#
			beta=c(0.1), #
			waning.maternal.par=1,#
			waning.immunity=0,#
			fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
			period=100,alpha=0.6,mag=0.8,Tmax=5000, n.runin=1000){#
			require(MASS)#
			#
			#get Fmatrix (won't change)#
			Fmat <- buildFMatrix(age.classes=age.classes,fert=fert)#
			#
			#get seasonal trans#
			seasTrans <- periodTrans(period=period,alpha=alpha,mag=mag,Tmax=Tmax)		#
#
			nt<-rep(0,length(age.classes)*4)#
			nt[1+seq(1,length(age.classes)*4,by=4)] <- 1#
			nt[2+seq(1,5*4,by=4)] <- 1#
			nt.store<-matrix(NA,length(age.classes)*4,Tmax)#
			#
			for (t in 1:Tmax) {#
				#build Tmat	#
				Tmat <- buildTMatrix(age.classes=age.classes,#
				mort=mort,   #one for every age class (danish 1835 cohort here)#
				mu.sick=mu.sick,	#how much more likely sick are to die#
				beta=seasTrans[t], #
				waning.maternal.par=waning.maternal.par,#
				waning.immunity=waning.immunity)#
#
				nt1<-(Tmat+Fmat) %*% nt	#
				nt.store[,t]<-nt1#
				nt<-nt1#
				#
			}#
			#
			m.inds <- seq(1,length(age.classes)*4,by=4)#
			s.inds <- m.inds+1			#
			i.inds <- m.inds+2			#
			r.inds <- m.inds+3			#
#
			return(list(nt.store=nt.store,m.inds=m.inds,s.inds=s.inds,i.inds=i.inds,r.inds=r.inds,seasTrans=seasTrans))#
		}#
#
#
#
picTrack <- function(){#
	a1<-TrackPopStruct(period=10)#
	b1<-TrackPopStruct(period=100)#
#
	par(mfrow=c(2,2),bty="l")#
	tlim <- 3000:3200#
	plot(colSums(a1[[1]][a1[[2]],tlim]), xlab="time", ylab="M", type="l")#
	points(colSums(	b1[[1]][b1[[2]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[3]],tlim]), xlab="time", ylab="S", type="l")#
	points(colSums(	b1[[1]][b1[[3]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[4]],tlim]), xlab="time", ylab="I", type="l")#
	points(colSums(	b1[[1]][b1[[4]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[5]],tlim]), xlab="time", ylab="R", type="l")#
	points(colSums(	b1[[1]][b1[[5]],tlim]), type="l", col=2)#
#
	par(mfrow=c(2,2)) #pop structure#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[2]],tlim])), xlab="time", ylab="age",main="M")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[3]],tlim])), xlab="time", ylab="age",main="S")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[4]],tlim])), xlab="time", ylab="age",main="I")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[5]],tlim])), xlab="time", ylab="age",main="R")#
#
	#total pop size compare#
	plot(colSums(a1[[1]][,tlim]), xlab="time", ylab="M", type="l")#
	points(colSums(b1[[1]][,tlim]), type="l",col=2)	#
#
	#highlights that problem with comparison across different seasonalities is that the more frequent have higher risk death anyway#
	mean(diff(colSums(a1[[1]][,tlim])))#
	mean(diff(colSums(b1[[1]][,tlim])))#
#
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,1,length=50)#
	pd <- c(2,10,100,200)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 5000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.01*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
#
		}}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
#
#
#
}
	a1<-TrackPopStruct(period=10)#
	b1<-TrackPopStruct(period=100)#
#
	par(mfrow=c(2,2),bty="l")#
	tlim <- 3000:3200#
	plot(colSums(a1[[1]][a1[[2]],tlim]), xlab="time", ylab="M", type="l")#
	points(colSums(	b1[[1]][b1[[2]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[3]],tlim]), xlab="time", ylab="S", type="l")#
	points(colSums(	b1[[1]][b1[[3]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[4]],tlim]), xlab="time", ylab="I", type="l")#
	points(colSums(	b1[[1]][b1[[4]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[5]],tlim]), xlab="time", ylab="R", type="l")#
	points(colSums(	b1[[1]][b1[[5]],tlim]), type="l", col=2)#
#
	par(mfrow=c(2,2)) #pop structure#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[2]],tlim])), xlab="time", ylab="age",main="M")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[3]],tlim])), xlab="time", ylab="age",main="S")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[4]],tlim])), xlab="time", ylab="age",main="I")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[5]],tlim])), xlab="time", ylab="age",main="R")#
#
	#total pop size compare#
	plot(colSums(a1[[1]][,tlim]), xlab="time", ylab="M", type="l")#
	points(colSums(b1[[1]][,tlim]), type="l",col=2)	#
#
	#highlights that problem with comparison across different seasonalities is that the more frequent have higher risk death anyway#
	mean(diff(colSums(a1[[1]][,tlim])))#
	mean(diff(colSums(b1[[1]][,tlim])))#
#
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,1,length=50)#
	pd <- c(2,10,100,200)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 5000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.01*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
#
		}}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")
#
#
#
## Build different yearly periodicity in trans#
##
periodTrans <- function(period=100,alpha=0.2,mag=0.01,Tmax=10000) { #
#
	u <- alpha*cos(2*pi*(1:Tmax)/period)#
	return(mag*(1+u))#
}
	a1<-TrackPopStruct(period=10)#
	b1<-TrackPopStruct(period=100)#
#
	par(mfrow=c(2,2),bty="l")#
	tlim <- 3000:3200#
	plot(colSums(a1[[1]][a1[[2]],tlim]), xlab="time", ylab="M", type="l")#
	points(colSums(	b1[[1]][b1[[2]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[3]],tlim]), xlab="time", ylab="S", type="l")#
	points(colSums(	b1[[1]][b1[[3]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[4]],tlim]), xlab="time", ylab="I", type="l")#
	points(colSums(	b1[[1]][b1[[4]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[5]],tlim]), xlab="time", ylab="R", type="l")#
	points(colSums(	b1[[1]][b1[[5]],tlim]), type="l", col=2)#
#
	par(mfrow=c(2,2)) #pop structure#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[2]],tlim])), xlab="time", ylab="age",main="M")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[3]],tlim])), xlab="time", ylab="age",main="S")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[4]],tlim])), xlab="time", ylab="age",main="I")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[5]],tlim])), xlab="time", ylab="age",main="R")#
#
	#total pop size compare#
	plot(colSums(a1[[1]][,tlim]), xlab="time", ylab="M", type="l")#
	points(colSums(b1[[1]][,tlim]), type="l",col=2)	#
#
	#highlights that problem with comparison across different seasonalities is that the more frequent have higher risk death anyway#
	mean(diff(colSums(a1[[1]][,tlim])))#
	mean(diff(colSums(b1[[1]][,tlim])))#
#
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,1,length=50)#
	pd <- c(2,10,100,200)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 5000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.01*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
#
		}}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")
a1[[1]][a1[[3]],]
a1[[1]][a1[[3]],1:10]
a1$seasTrans
#
#
## Build a function to get stoch rate increase#
##
##
StochGrowthRate <- function(age.classes=1:50,#
			mort=c(0.18950, 0.04376, 0.02816, 0.01862, 0.01212, 0.00940, 0.00789, #
0.00682, 0.00589, 0.00568, 0.00601, 0.00574, 0.00546,0.00516, 0.00445, 0.00437, 0.00479, 0.00531, #
0.00556, 0.00554, 0.00584, 0.00675, 0.00759, 0.00702, 0.00653, 0.00650, 0.00652, 0.00685, 0.00858, #
0.00888, 0.00782, 0.00756, 0.00784, 0.00808, 0.00809, 0.00888, 0.00994, 0.00983, 0.00967, 0.00972,#
0.00994, 0.00948, 0.00948, 0.00953, 0.01012, 0.01049, 0.01065, 0.01109, 0.01130, 0.01152),   #one for every age class (danish 1835 cohort here)#
			mu.sick=1.01,	#how much more likely sick are to die#
			beta=c(0.1), #
			waning.maternal.par=1,#
			waning.immunity=0,#
			fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
			period=100,alpha=0.2,mag=0.01,Tmax=5000, n.runin=1000){#
			require(MASS)#
			#
			#get Fmatrix (won't change)#
			Fmat <- buildFMatrix(age.classes=age.classes,fert=fert)#
			#
			#get seasonal trans#
			seasTrans <- pmax(pmin(periodTrans(period=period,alpha=alpha,mag=mag,Tmax=Tmax),1),0)		#
#
			nt<-rep(0,length(age.classes)*4)#
			nt[1+seq(1,length(age.classes)*4,by=4)] <- 1#
			nt[2+seq(1,5*4,by=4)] <- 1#
			Rt<-rep(NA,Tmax)#
			#
			for (t in 1:Tmax) {#
				#build Tmat	#
				Tmat <- buildTMatrix(age.classes=age.classes,#
				mort=mort,   #one for every age class (danish 1835 cohort here)#
				mu.sick=mu.sick,	#how much more likely sick are to die#
				beta=seasTrans[t], #
				waning.maternal.par=waning.maternal.par,#
				waning.immunity=waning.immunity)#
#
				nt1<-(Tmat+Fmat) %*% nt	#
				sum.nt1<-sum(nt1)#
				Rt[t]<-log(sum.nt1)#
				nt<-nt1/sum.nt1#
				#
			}#
			#
			res <- mean(Rt[n.runin:Tmax],na.rm=TRUE)#
			return(res)#
		}#
#
#
#
#
## Build a function to get stoch rate increase#
##
##
TrackPopStruct <- function(age.classes=1:50,#
			mort=c(0.18950, 0.04376, 0.02816, 0.01862, 0.01212, 0.00940, 0.00789, #
0.00682, 0.00589, 0.00568, 0.00601, 0.00574, 0.00546,0.00516, 0.00445, 0.00437, 0.00479, 0.00531, #
0.00556, 0.00554, 0.00584, 0.00675, 0.00759, 0.00702, 0.00653, 0.00650, 0.00652, 0.00685, 0.00858, #
0.00888, 0.00782, 0.00756, 0.00784, 0.00808, 0.00809, 0.00888, 0.00994, 0.00983, 0.00967, 0.00972,#
0.00994, 0.00948, 0.00948, 0.00953, 0.01012, 0.01049, 0.01065, 0.01109, 0.01130, 0.01152),   #one for every age class (danish 1835 cohort here)#
			mu.sick=1.01,	#how much more likely sick are to die#
			beta=c(0.1), #
			waning.maternal.par=1,#
			waning.immunity=0,#
			fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
			period=100,alpha=0.6,mag=0.8,Tmax=5000, n.runin=1000){#
			require(MASS)#
			#
			#get Fmatrix (won't change)#
			Fmat <- buildFMatrix(age.classes=age.classes,fert=fert)#
			#
			#get seasonal trans#
			seasTrans <- pmax(pmin(periodTrans(period=period,alpha=alpha,mag=mag,Tmax=Tmax),1),0)		#
#
			nt<-rep(0,length(age.classes)*4)#
			nt[1+seq(1,length(age.classes)*4,by=4)] <- 1#
			nt[2+seq(1,5*4,by=4)] <- 1#
			nt.store<-matrix(NA,length(age.classes)*4,Tmax)#
			#
			for (t in 1:Tmax) {#
				#build Tmat	#
				Tmat <- buildTMatrix(age.classes=age.classes,#
				mort=mort,   #one for every age class (danish 1835 cohort here)#
				mu.sick=mu.sick,	#how much more likely sick are to die#
				beta=seasTrans[t], #
				waning.maternal.par=waning.maternal.par,#
				waning.immunity=waning.immunity)#
#
				nt1<-(Tmat+Fmat) %*% nt	#
				nt.store[,t]<-nt1#
				nt<-nt1#
				#
			}#
			#
			m.inds <- seq(1,length(age.classes)*4,by=4)#
			s.inds <- m.inds+1			#
			i.inds <- m.inds+2			#
			r.inds <- m.inds+3			#
#
			return(list(nt.store=nt.store,m.inds=m.inds,s.inds=s.inds,i.inds=i.inds,r.inds=r.inds,seasTrans=seasTrans))#
		}
	a1<-TrackPopStruct(period=10)#
	b1<-TrackPopStruct(period=100)#
#
	par(mfrow=c(2,2),bty="l")#
	tlim <- 3000:3200#
	plot(colSums(a1[[1]][a1[[2]],tlim]), xlab="time", ylab="M", type="l")#
	points(colSums(	b1[[1]][b1[[2]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[3]],tlim]), xlab="time", ylab="S", type="l")#
	points(colSums(	b1[[1]][b1[[3]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[4]],tlim]), xlab="time", ylab="I", type="l")#
	points(colSums(	b1[[1]][b1[[4]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[5]],tlim]), xlab="time", ylab="R", type="l")#
	points(colSums(	b1[[1]][b1[[5]],tlim]), type="l", col=2)#
#
	par(mfrow=c(2,2)) #pop structure#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[2]],tlim])), xlab="time", ylab="age",main="M")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[3]],tlim])), xlab="time", ylab="age",main="S")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[4]],tlim])), xlab="time", ylab="age",main="I")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[5]],tlim])), xlab="time", ylab="age",main="R")
	#highlights that problem with comparison across different seasonalities is that the more frequent have higher risk death anyway#
	mean(diff(colSums(a1[[1]][,tlim])))#
	mean(diff(colSums(b1[[1]][,tlim])))
plot(a1[[1]][a1[[3]],3000],a1[[1]][a1[[4]],3000])
plot(a1[[1]][a1[[3]],3000],, type="l")
points(a1[[1]][a1[[4]],3000], type="l",col=2)
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,1,length=50)#
	pd <- c(2,10,100,200)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 5000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.01*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
#
		}}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")
#
#
#run this#
a1<-SimTsir()#
plot(bws,bw.ev71[,3]/ur,type="b",col=1,xlab="Year",ylab="Cases (raw data)",xaxt="n", bty="n")#
lines(a1$Ival,type="l",lwd=1.2,col="blue")#
#axis(1,at=seq(13,312,by=26),labels=c("2000","2001","2002","2003","2004","2005","2006","2007","2008","2009","2010","2011"))#
#
#check susce#
plot(bws,St, xlab="year", ylab="inferred susc")#
lines(a1$Sval,type="l",lwd=1.2,col="blue")
	which(st==apply(st,2,max))
	which(st==apply(st,1,max))
	which(st==apply(st,1,max),arr.ind=T)
plot(st[1,])
plot(st[1,], type="l")
plot(st[2,], type="l")
	plot(st[,1],type="l")
	plot(st[,2],type="l")
	which(st==apply(st,2,max),arr.ind=T)
	which(t(st)==apply(st,1,max),arr.ind=T)
	which(t(st)==apply(st,2,max),arr.ind=T)
matplot(t(st))
matplot(t(st), type="l")
matplot((st), type="l")
wanes[1]
wanes[2]
matplot((st), type="b")
matplot((st), type="b",pch=19)
wanes[1:5]
plot(1:50,exp(-wanes[1]*(1:50)), type="l")
points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)
points(1:50,exp(-wanes[3]*(1:50)), type="l",col=3)
plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))
points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)
points(1:50,exp(-wanes[3]*(1:50)), type="l",col=3)
#
##
TrackPopStruct <- function(age.classes=1:50,#
			mort=c(0.18950, 0.04376, 0.02816, 0.01862, 0.01212, 0.00940, 0.00789, #
0.00682, 0.00589, 0.00568, 0.00601, 0.00574, 0.00546,0.00516, 0.00445, 0.00437, 0.00479, 0.00531, #
0.00556, 0.00554, 0.00584, 0.00675, 0.00759, 0.00702, 0.00653, 0.00650, 0.00652, 0.00685, 0.00858, #
0.00888, 0.00782, 0.00756, 0.00784, 0.00808, 0.00809, 0.00888, 0.00994, 0.00983, 0.00967, 0.00972,#
0.00994, 0.00948, 0.00948, 0.00953, 0.01012, 0.01049, 0.01065, 0.01109, 0.01130, 0.01152),   #one for every age class (danish 1835 cohort here)#
			mu.sick=1.1,	#1.01 how much more likely sick are to die#
			beta=c(0.1), #
			waning.maternal.par=1,#
			waning.immunity=0,#
			fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
			period=100,alpha=0.6,mag=0.8,Tmax=5000, n.runin=1000){#
			require(MASS)#
			#
			#get Fmatrix (won't change)#
			Fmat <- buildFMatrix(age.classes=age.classes,fert=fert)#
			#
			#get seasonal trans#
			seasTrans <- pmax(pmin(periodTrans(period=period,alpha=alpha,mag=mag,Tmax=Tmax),1),0)		#
#
			nt<-rep(0,length(age.classes)*4)#
			nt[1+seq(1,length(age.classes)*4,by=4)] <- 1#
			nt[2+seq(1,5*4,by=4)] <- 1#
			nt.store<-matrix(NA,length(age.classes)*4,Tmax)#
			#
			for (t in 1:Tmax) {#
				#build Tmat	#
				Tmat <- buildTMatrix(age.classes=age.classes,#
				mort=mort,   #one for every age class (danish 1835 cohort here)#
				mu.sick=mu.sick,	#how much more likely sick are to die#
				beta=seasTrans[t], #
				waning.maternal.par=waning.maternal.par,#
				waning.immunity=waning.immunity)#
#
				nt1<-(Tmat+Fmat) %*% nt	#
				nt.store[,t]<-nt1#
				nt<-nt1#
				#
			}#
			#
			m.inds <- seq(1,length(age.classes)*4,by=4)#
			s.inds <- m.inds+1			#
			i.inds <- m.inds+2			#
			r.inds <- m.inds+3			#
#
			return(list(nt.store=nt.store,m.inds=m.inds,s.inds=s.inds,i.inds=i.inds,r.inds=r.inds,seasTrans=seasTrans))#
		}
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,1,length=50)#
	pd <- c(2,10,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 5000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.01*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
#
		}}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot((st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
waneds[2]
wanes[2]
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,0.04,length=5)#
	pd <- c(2,10,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 5000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.01*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
#
		}}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot((st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,0.04,length=5)#
	pd <- c(2,10,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 5000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.01*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax,mu.sick=1.5)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
#
		}}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot((st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,0.02,length=5)#
	pd <- c(2,10,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 5000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.01*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
				waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax,#
				mu.sick=1.5)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
#
		}}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot(wanes,(st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,0.02,length=5)#
	pd <- c(2,10)#,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 5000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
				waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax,#
				mu.sick=1.5)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
		}#
	print(wanes[j])#
	}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot(wanes,(st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
points(1:50,exp(-wanes[5]*(1:50)), type="l",col=1)
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,1,length=5)#
	pd <- c(2,10)#,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 5000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
				waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax,#
				mu.sick=1.5)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
		}#
	print(j)#
	}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot(wanes,(st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,0.6,length=5)#
	pd <- c(2,10)#,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 5000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
				waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax,#
				mu.sick=1.5)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
		}#
	print(j)#
	}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot(wanes,(st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
#
	par(mfrow=c(2,2)) #pop structure#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[2]],tlim])), xlab="time", ylab="age",main="M")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[3]],tlim])), xlab="time", ylab="age",main="S")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[4]],tlim])), xlab="time", ylab="age",main="I")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[5]],tlim])), xlab="time", ylab="age",main="R")
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,0.6,length=5)#
	pd <- c(2,50)#10,,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 3000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
				waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax,#
				mu.sick=1.5)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
		}#
	print(j)#
	}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot(wanes,(st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,0.3,length=5)#
	pd <- c(2,50)#10,,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 3000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
				waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax,#
				mu.sick=1.5)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
		}#
	print(j)#
	}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot(wanes,(st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,0.2,length=5)#
	pd <- c(2,50)#10,,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 3000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
				waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax,#
				mu.sick=1.5)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
		}#
	print(j)#
	}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot(wanes,(st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,0.05,length=5)#
	pd <- c(2)#,50)#10,,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 3000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
				waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax,#
				mu.sick=1.5)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
		}#
	print(j)#
	}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot(wanes,(st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,0.05,length=5)#
	pd <- c(2,100)#,50)#10,,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 3000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
				waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax,#
				mu.sick=1.5)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
		}#
	print(j)#
	}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot(wanes,(st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
#
	par(mfrow=c(2,2)) #pop structure#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[2]],tlim])), xlab="time", ylab="age",main="M")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[3]],tlim])), xlab="time", ylab="age",main="S")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[4]],tlim])), xlab="time", ylab="age",main="I")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[5]],tlim])), xlab="time", ylab="age",main="R")
tlim<-2500:3000
#
	par(mfrow=c(2,2)) #pop structure#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[2]],tlim])), xlab="time", ylab="age",main="M")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[3]],tlim])), xlab="time", ylab="age",main="S")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[4]],tlim])), xlab="time", ylab="age",main="I")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[5]],tlim])), xlab="time", ylab="age",main="R")
tlim<-2500:2700
#
	par(mfrow=c(2,2)) #pop structure#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[2]],tlim])), xlab="time", ylab="age",main="M")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[3]],tlim])), xlab="time", ylab="age",main="S")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[4]],tlim])), xlab="time", ylab="age",main="I")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[5]],tlim])), xlab="time", ylab="age",main="R")
#
	par(mfrow=c(2,2)) #pop structure#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[2]][1:10],tlim])), xlab="time", ylab="age",main="M")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[3]][1:10],tlim])), xlab="time", ylab="age",main="S")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[4]][1:10],tlim])), xlab="time", ylab="age",main="I")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[5]][1:10],tlim])), xlab="time", ylab="age",main="R")
a1[[2]]
#
	par(mfrow=c(2,2)) #pop structure#
	image(tlim,c(1:(nrow(a1$nt.store)/4))[1:10],t(log(a1[[1]][a1[[2]][1:10],tlim])), xlab="time", ylab="age",main="M")#
	image(tlim,c(1:(nrow(a1$nt.store)/4))[1:10],t(log(a1[[1]][a1[[3]][1:10],tlim])), xlab="time", ylab="age",main="S")#
	image(tlim,c(1:(nrow(a1$nt.store)/4))[1:10],t(log(a1[[1]][a1[[4]][1:10],tlim])), xlab="time", ylab="age",main="I")#
	image(tlim,c(1:(nrow(a1$nt.store)/4))[1:10],t(log(a1[[1]][a1[[5]][1:10],tlim])), xlab="time", ylab="age",main="R")
#
#
## Function to simulate evolution of maternal immunity   #########################
# Need: M, S, I, R classes, structured over age#
#  S gives birth to S#
#  I and R give birth to M#
#  I dies at a rate defined by age survival * mu.sick#
#  Infection rate imposed externally (because want to explore different periodicities, etc)#
#
# Parameter explored = duration maternal immunity #
# Potential extra adv - if you move into R maybe you have slightly higher mortality because part of your memory is tied up. #
#
# Do yearly time-step (cos why not)#
# Calculate lambda_s#
#
#
#
## Funtion to build survival T transitions#
## an infection #
# #
buildTMatrix <- function(age.classes=1:50,#
			mort=c(0.18950, 0.04376, 0.02816, 0.01862, 0.01212, 0.00940, 0.00789, #
0.00682, 0.00589, 0.00568, 0.00601, 0.00574, 0.00546,0.00516, 0.00445, 0.00437, 0.00479, 0.00531, #
0.00556, 0.00554, 0.00584, 0.00675, 0.00759, 0.00702, 0.00653, 0.00650, 0.00652, 0.00685, 0.00858, #
0.00888, 0.00782, 0.00756, 0.00784, 0.00808, 0.00809, 0.00888, 0.00994, 0.00983, 0.00967, 0.00972,#
0.00994, 0.00948, 0.00948, 0.00953, 0.01012, 0.01049, 0.01065, 0.01109, 0.01130, 0.01152),   #one for every age class (danish 1835 cohort here)#
			mu.sick=1.01,	#how much more likely sick are to die#
			beta=c(0.1), #
			waning.maternal.par=1,#
			waning.immunity=0){#
#
	nage <- length(age.classes)#
	if (length(beta)==1) beta <- rep(beta,nage)#
	if (length(waning.immunity)==1) waning.immunity <- rep(waning.immunity,nage)	#
#
	waning.maternal<-exp(-waning.maternal.par*(age.classes))#
#
	mat1 <- matrix(0,4,4)#
#
	Tmat <- matrix(0,4*nage,4*nage)#
	for (j in 1:nage) { #
		#fill in epi matrix#
		mat1[] <- 0#
		mat1[1,1] <- waning.maternal[j]#
		mat1[2,1] <- 1-waning.maternal[j]#
		mat1[2,2] <- 1-beta[j]#
		mat1[3,2] <- beta[j]#
		mat1[4,3] <- 1#
		mat1[4,4] <- 1-waning.immunity[j]#
		mat1[2,4] <- waning.immunity[j]#
		#put in surv#
		surv <- rep(1-mort[j],4); surv[3] <- 1-(mu.sick*mort[j])#
		#fill in Tmatrix#
		if (j!=nage) { #
			Tmat[(j*4+1):(j*4+4),((j-1)*4+1):(j*4)] <- mat1*surv#
		} else { #
			Tmat[((j-1)*4+1):(j*4),((j-1)*4+1):(j*4)] <- mat1#
		}#
	}#
#
	return(Tmat)	#
#
}#
#
#
## Funtion to build fertility transitions#
## (prob only needs to happen once  #
# #
buildFMatrix <- function(age.classes=1:50,#
			fert=dnorm(1:50,25,5)){ 	#one for every age class#
	fert[age.classes<15] <- 0#
#
	nage <- length(age.classes)#
#
	Fmat <- matrix(0,4*nage,4*nage)#
	for (j in 1:nage) { #
		Fmat[1,((j-1)*4+1):(j*4)] <- c(0,0,fert[j],fert[j]) #the mat immune#
		Fmat[2,((j-1)*4+1):(j*4)]<- c(fert[j],fert[j],0,0) #the susceptible (mom didn't get sick)#
	}#
#
	return(Fmat)#
}#
#
#
#
#
## Build different yearly periodicity in trans#
##
periodTrans <- function(period=100,alpha=0.2,mag=0.01,Tmax=10000) { #
#
	u <- alpha*cos(2*pi*(1:Tmax)/period)#
	return(mag*(1+u))#
}#
#
#
## Build a function to get stoch rate increase#
##
##
StochGrowthRate <- function(age.classes=1:50,#
			mort=c(0.18950, 0.04376, 0.02816, 0.01862, 0.01212, 0.00940, 0.00789, #
0.00682, 0.00589, 0.00568, 0.00601, 0.00574, 0.00546,0.00516, 0.00445, 0.00437, 0.00479, 0.00531, #
0.00556, 0.00554, 0.00584, 0.00675, 0.00759, 0.00702, 0.00653, 0.00650, 0.00652, 0.00685, 0.00858, #
0.00888, 0.00782, 0.00756, 0.00784, 0.00808, 0.00809, 0.00888, 0.00994, 0.00983, 0.00967, 0.00972,#
0.00994, 0.00948, 0.00948, 0.00953, 0.01012, 0.01049, 0.01065, 0.01109, 0.01130, 0.01152),   #one for every age class (danish 1835 cohort here)#
			mu.sick=1.01,	#how much more likely sick are to die#
			beta=c(0.1), #
			waning.maternal.par=1,#
			waning.immunity=0,#
			fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
			period=100,alpha=0.2,mag=0.01,Tmax=5000, n.runin=1000){#
			require(MASS)#
			#
			#get Fmatrix (won't change)#
			Fmat <- buildFMatrix(age.classes=age.classes,fert=fert)#
			#
			#get seasonal trans#
			seasTrans <- pmax(pmin(periodTrans(period=period,alpha=alpha,mag=mag,Tmax=Tmax),1),0)		#
#
			nt<-rep(0,length(age.classes)*4)#
			nt[1+seq(1,length(age.classes)*4,by=4)] <- 1#
			nt[2+seq(1,5*4,by=4)] <- 1#
			Rt<-rep(NA,Tmax)#
			#
			for (t in 1:Tmax) {#
				#build Tmat	#
				Tmat <- buildTMatrix(age.classes=age.classes,#
				mort=mort,   #one for every age class (danish 1835 cohort here)#
				mu.sick=mu.sick,	#how much more likely sick are to die#
				beta=seasTrans[t], #
				waning.maternal.par=waning.maternal.par,#
				waning.immunity=waning.immunity)#
#
				nt1<-(Tmat+Fmat) %*% nt	#
				sum.nt1<-sum(nt1)#
				Rt[t]<-log(sum.nt1)#
				nt<-nt1/sum.nt1#
				#
			}#
			#
			res <- mean(Rt[n.runin:Tmax],na.rm=TRUE)#
			return(res)#
		}#
#
#
#
#
## Build a function to get stoch rate increase#
##
##
TrackPopStruct <- function(age.classes=1:50,#
			mort=c(0.18950, 0.04376, 0.02816, 0.01862, 0.01212, 0.00940, 0.00789, #
0.00682, 0.00589, 0.00568, 0.00601, 0.00574, 0.00546,0.00516, 0.00445, 0.00437, 0.00479, 0.00531, #
0.00556, 0.00554, 0.00584, 0.00675, 0.00759, 0.00702, 0.00653, 0.00650, 0.00652, 0.00685, 0.00858, #
0.00888, 0.00782, 0.00756, 0.00784, 0.00808, 0.00809, 0.00888, 0.00994, 0.00983, 0.00967, 0.00972,#
0.00994, 0.00948, 0.00948, 0.00953, 0.01012, 0.01049, 0.01065, 0.01109, 0.01130, 0.01152),   #one for every age class (danish 1835 cohort here)#
			mu.sick=1.1,	#1.01 how much more likely sick are to die#
			beta=c(0.1), #
			waning.maternal.par=1,#
			waning.immunity=0,#
			fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
			period=100,alpha=0.6,mag=0.8,Tmax=5000, n.runin=1000){#
			require(MASS)#
			#
			#get Fmatrix (won't change)#
			Fmat <- buildFMatrix(age.classes=age.classes,fert=fert)#
			#
			#get seasonal trans#
			seasTrans <- pmax(pmin(periodTrans(period=period,alpha=alpha,mag=mag,Tmax=Tmax),1),0)		#
#
			nt<-rep(0,length(age.classes)*4)#
			nt[1+seq(1,length(age.classes)*4,by=4)] <- 1#
			nt[2+seq(1,5*4,by=4)] <- 1#
			nt.store<-matrix(NA,length(age.classes)*4,Tmax)#
			#
			for (t in 1:Tmax) {#
				#build Tmat	#
				Tmat <- buildTMatrix(age.classes=age.classes,#
				mort=mort,   #one for every age class (danish 1835 cohort here)#
				mu.sick=mu.sick,	#how much more likely sick are to die#
				beta=seasTrans[t], #
				waning.maternal.par=waning.maternal.par,#
				waning.immunity=waning.immunity)#
#
				nt1<-(Tmat+Fmat) %*% nt	#
				nt.store[,t]<-nt1#
				nt<-nt1#
				#
			}#
			#
			m.inds <- seq(1,length(age.classes)*4,by=4)#
			s.inds <- m.inds+1			#
			i.inds <- m.inds+2			#
			r.inds <- m.inds+3			#
#
			return(list(nt.store=nt.store,m.inds=m.inds,s.inds=s.inds,i.inds=i.inds,r.inds=r.inds,seasTrans=seasTrans))#
		}#
#
#
#
picTrack <- function(){#
	a1<-TrackPopStruct(period=10)#
	b1<-TrackPopStruct(period=100)#
#
	par(mfrow=c(2,2),bty="l")#
	tlim <- 1000:1200#
	plot(colSums(a1[[1]][a1[[2]],tlim]), xlab="time", ylab="M", type="l")#
	points(colSums(	b1[[1]][b1[[2]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[3]],tlim]), xlab="time", ylab="S", type="l")#
	points(colSums(	b1[[1]][b1[[3]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[4]],tlim]), xlab="time", ylab="I", type="l")#
	points(colSums(	b1[[1]][b1[[4]],tlim]), type="l", col=2)#
	plot(colSums(a1[[1]][a1[[5]],tlim]), xlab="time", ylab="R", type="l")#
	points(colSums(	b1[[1]][b1[[5]],tlim]), type="l", col=2)#
#
	par(mfrow=c(2,2)) #pop structure#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[2]],tlim])), xlab="time", ylab="age",main="M")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[3]],tlim])), xlab="time", ylab="age",main="S")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[4]],tlim])), xlab="time", ylab="age",main="I")#
	image(tlim,1:(nrow(a1$nt.store)/4),t(log(a1[[1]][a1[[5]],tlim])), xlab="time", ylab="age",main="R")#
#
	#total pop size compare#
	plot(colSums(a1[[1]][,tlim]), xlab="time", ylab="M", type="l")#
	points(colSums(b1[[1]][,tlim]), type="l",col=2)	#
#
	#highlights that problem with comparison across different seasonalities is that the more frequent have higher risk death anyway#
	mean(diff(colSums(a1[[1]][,tlim])))#
	mean(diff(colSums(b1[[1]][,tlim])))#
#
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,0.6,length=5)#
	pd <- c(2,50)#10,,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 2000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
				waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax,#
				mu.sick=1.5)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
		}#
	print(j)#
	}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot(wanes,(st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)#
#
#
#
}
#
#
	##compare across a range of periodicities three different wanings#
	wanes <- seq(1e-9,0.6,length=5)#
	pd <- c(2,50)#10,,50,100)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 2000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
				waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax,#
				mu.sick=1.5)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
		}#
	print(j)#
	}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot(wanes,(st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
wanes <- seq(1e-9,0.6,length=50)#
	pd <- c(2,10,50,100,500)#
	st <- matrix(NA,length(wanes),length(pd))#
	Tmax <- 2000#
	for (j in 1:length(wanes)) { #
		for (k in 1:length(pd)) { #
		a1<-TrackPopStruct(fert=0.1*dnorm(1:50,25,5)/max(dnorm(1:50,25,5)),#
				waning.maternal.par=wanes[j],period=pd[k],Tmax=Tmax,#
				mu.sick=1.5)#
		st[j,k] <- mean(diff(colSums(a1[[1]][,(Tmax-500):Tmax])))#
		}#
	print(j)#
	}#
	image(wanes,pd,(st),xlab="waning rate", ylab="periodicity of outbreaks")#
#
	matplot(wanes,(st), type="b",pch=19)#
#
	plot(1:50,exp(-wanes[1]*(1:50)), type="l", ylim=c(0,1))#
	points(1:50,exp(-wanes[2]*(1:50)), type="l",col=2)#
	points(1:50,exp(-wanes[3]*(1:50)), type="l",col=1)
#
setwd("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/")#
source("R/IPMpack-Util.R")#
source("R/IPMpack-Base.R")#
source("R/IPMpack-Impl.R")
#
#
## Function to alter vector from status description to#
# 0s and 1s for survival#
##
# Parameters - character vector#
##
# Returns - numeric vector#
##
convertStatus <- function(x) {#
    y <- rep(NA,length(x))#
    y[x=="A"] <- 1#
    y[x=="D"] <- 0#
    y[x=="P"] <- 1 #this is a future tree, usually no size - prob alive, but these are not evenly sampled#
#
    return(y)#
}#
#
#
## Function to sort out names, create codes, etc for India data#
##  - dumped out now, so don't need to re-run! - #
###
getSp <- function(filename="data/"){#
#
    #write out species names - takes by hand editing so only do once#
    det <-  read.delim(paste(filename,"SpeciesDetails.txt", sep=""),header=TRUE)#
    genus.end <-  regexpr(" ", det[,2]);#
    mat <- cbind(as.character(det$Family), substr(det$LatinName,1,genus.end),#
                 as.character(det$LatinName))#
    write.table(paste(mat[,1],"/",mat[,2],"/",mat[,3], sep=""),#
                file="names.sp",row.names=FALSE, quote = FALSE)#
    #remember, make lower case, put _ between genus and species name, remove " /" for use with phylomatic#
    #
    #
#
}#
#
#
## Function to pull in all the data taken from#
## http://esapubs.org/archive/ecol/E092/115/default.htm#data#
## Ecological Archives, E092-115-D1.#
## and organize it into a format recognized by IPMpack#
##
# parameters - filename - file describing location of the data#
#            - species - chosen species (four letter code, e.g., "vain", "myda", or "hubr") or "all"#
##
# returns - a data-frame with headings size, sizenext (adjusted for time interval),#
#                incr (raw increment), surv (survival), spcode,#
#              and exactDate and exactDatel in days#
##
getData <- function(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                    species="all"){#
#
    #bring in the data#
    df <- read.delim(paste(filename,"WesternGhatTrees.txt", sep=""),header=TRUE)#
    if (species!="all") df <- df[df$SpCode==species,]#
#
    #
    #get matrix of dates, sizes, survival #
    dates.raw <- cbind(df$Date0,df$Date1,df$Date2, df$Date3, df$Date4, df$Date5)  #
    sizes.raw <- cbind(df$GBH0,df$GBH1,df$GBH2,df$GBH3,df$GBH4,df$GBH5)#
    surv.raw <- cbind(convertStatus(df$Status0),convertStatus(df$Status1),convertStatus(df$Status2),#
                   convertStatus(df$Status3),convertStatus(df$Status4),convertStatus(df$Status5))#
#
    #get the raw increment for fitting detailed survival model#
    incr <- cbind(df$GBH1-df$GBH0,df$GBH2-df$GBH1,df$GBH3-df$GBH2,df$GBH4-df$GBH3,df$GBH5-df$GBH4)#
    #
    #loop over, predict sizes at days closest to 365*4 (bi-yearly intrvals)#
    pred.dates <- (365*4)*c(0:5)#
    predict.sizes <- matrix(NA,length(df[,1]),length(pred.dates))#
    predict.surv <- matrix(1,length(df[,1]),length(pred.dates))#
        #
    for (k in 1:length(df[,1])) {#
        x <- as.numeric(dates.raw[k,])#
        y <- sizes.raw[k,]#
#
        bad <- is.na(x) | is.na(y)#
        x <- x[!bad]#
        y <- y[!bad]#
     #
        #linear regression#
        if (length(x)<4) { #
            fit <- lm(y~x)#
            predict.sizes[k,] <- predict(fit,newdata=data.frame(x=pred.dates)) #linear reg#
        } else { #
        #smooth spline#
            fit <- smooth.spline(y~x)#
            predict.sizes[k,] <- predict(fit,x=pred.dates)$y #smooth spline#
        }#
            #
        bad <- which(pred.dates>max(x,na.rm=TRUE), arr.ind=TRUE)#
        if (length(bad)>0) predict.sizes[k,bad] <- NA#
        #
        dead <- dates.raw[k,surv.raw[k,]==0][1]#
        loc.dead <- which((dead-pred.dates)^2==min((dead-pred.dates)^2), arr.ind=TRUE)#
        if (length(loc.dead)>0) predict.surv[k,loc.dead:length(pred.dates)] <- 0              #
    }#
#
    #reassure yourself it might work#
#    matplot(t(dates.raw),t(sizes.raw), type="b", pch=19,xlab="dates", ylab="sizes")#
#    abline(v=pred.dates)#
#
        #
    dataf <- data.frame(size=c(predict.sizes[,1:5]),sizenext=c(predict.sizes[,2:6]),#
                        incr=c(incr[,1:5]),#
                        surv=c(predict.surv[,2:6]), spcode=rep(df$SpCode, 5),#
                        exactDate=c(dates.raw[,1:5]), exactDatel=c(dates.raw[,2:6]))#
#
    dataf <- dataf[!is.na(dataf$size),]#
    #
    return(dataf)#
#
}#
#
#
#
#
#
#
## Function to fit survival with varying time increments and then write parameters#
## over onto a classic glm framework. #
##
# parameters - dataf - a dataframe including columns#
#                  size, surv, exactDate, and exactDatel, the latter two in days#
#            - nyrs - desired number of years in a time-step#
#            - par - starting values for the parameters#
#                     (must be of length one longer than covNames,#
#                       given intercept)#
#            - covNames - names of chosen covariates#
#            - method - method for optim ("Nelder-Mead", "SANN", etc.)#
##
# Returns  - output of optim#
##
fitSurvVaryingTimeIntervals <- function(dataf,#
                                        nyrs=5,#
                                        par=c(0.01,0.01,0.01,0.01),#
                                        covNames=c("size","size2","size3"),#
                                        method="Nelder-Mead") {#
#
    #warnings#
    if ((length(par)-1)!=length(covNames)) {#
        print("starting values does not match length of covariate names")#
    }#
#
    #make sure you have all the right covariates#
    if (length(covNames)>0) {#
        newd <- .makeCovDf(dataf$size, expVars[p])#
        dataf <- rbind(dataf,newd)#
    }#
    #
    tmp <- optim(par,likeSurvVaryingTimeIntervals,#
                 covNames=covNames,nyrs=nyrs,dataf=dataf,#
                 method=method)#
#
    #
    if (tmp$convergence!=0) {#
        tmp <- optim(tmp$par,likeSurvVaryingTimeIntervals,#
                     covNames=covNames,nyrs=nyrs,dataf=dataf,#
                     method=method)#
        if (tmp$convergence!=0)  print("not converged")        #
    }#
    #
    #write template over the top#
    if (length(covNames)>0) formula <- as.character(paste("surv~",paste(covNames,collapse="+"),collapse="")) else formula <- as.character("surv~1")#
    fit <- glm(formula,data=dataf,family=binomial)#
    #print(fit)#
    fit$coefficients <- tmp$par#
#
    sv1 <- new("survObj")#
    sv1@fit <- fit#
#
    tmp$sv1 <- sv1#
    #
    return(tmp)#
#
}#
#
#Function to calculate the likelihood for variable time-intervals for survival #
##
# parameters #
#            - par - starting values for the parameters#
#                     (must be of length one longer than covNames,#
#                       given intercept)#
#            - covNames - names of chosen covariates#
#            - nyrs - desired number of years in a time-step#
#            - dataf - a dataframe including columns in covNames, as well as#
#                  size, surv, exactDate, and exactDatel, the latter two in days#
##
# Returns  - numeric equal to minus the log likelihood#
##
likeSurvVaryingTimeIntervals <- function(par=c(0.01,0.01,0.01,0.01),#
                                         covNames=c("size","size2","size3"),#
                                         nyrs=5,#
                                         dataf) {#
#
    #
    #define time change#
    tdiff <- (dataf$exactDatel-dataf$exactDate)/(nyrs*365)#
    #print(range(tdiff, na.rm=TRUE))#
#
    #build predictor#
    if (length(covNames)>0) {#
        pred <-  t(t(dataf[,covNames])*par[2:length(par)])#
    }else { pred <- matrix(0,nrow(dataf),1)}#
    pred <- par[1] + rowSums(pred)#
    pred[pred>200] <- 200  #don't want bigger than exp(200) - gets infinite really quick#
    pred <- (exp(pred)/(1+exp(pred)))^(tdiff)#
    #
    #estimate likelihood#
    like <- dbinom(dataf$surv,1,pred, log=TRUE)#
    #like[like==-Inf] <- -exp(500)#
    #like[like==Inf] <- exp(500)#
#
    sumRows <- rep(0,nrow(dataf))#
    if (length(covNames)>1) sumRows <- rowSums(dataf[,covNames])#
    if (length(covNames)==1) sumRows <- dataf[,covNames]#
    #
    return(-sum(like[!is.na(sumRows) & !is.na(dataf$surv)],na.rm=TRUE))#
    #
}#
#
#
##note that there are very few species for which sufficient#
## mortality data is actually available! most just don't die...#
##
# vain, myda, hubr#
##
##
compareTmatrices <- function(dataf, growthObjList,survObjList, nBigMatrix=300,chosen.size=1500,#
                             do.plot=TRUE,do.legend=FALSE,...){ #
    #
    #STORAGE#
    LE <- LE1 <- ptime <- ptime1 <- array(dim=c(length(survObjList),length(growthObjList),nBigMatrix))#
      #
    ## LOOP OVER all possible combos#
    for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
             #
                sv1 <- survObjList[[j]]#
                gr1 <- growthObjList[[k]]#
                              #
                #BUILD Tmatrix#
                Tmatrix <- create.IPM.Tmatrix(nBigMatrix = nBigMatrix,#
                                              minSize = 0.9*min(dataf$size,na.rm=TRUE),#
                                              maxSize = 1.1*max(dataf$size,na.rm=TRUE),#
                                              growObj = gr1, survObj = sv1, correction="constant")#
                Tmatrix1 <- create.IPM.Tmatrix(nBigMatrix = nBigMatrix,#
                                               minSize = 0.9*min(dataf$size,na.rm=TRUE),#
                                               maxSize = 1.1*max(dataf$size,na.rm=TRUE),#
                                               growObj = gr1, survObj = sv1,integrate.type="cumul",#
                                               correction="constant")#
        #
                # Get the mean life expect from every size value in IPM#
                LE[j,k,] <- MeanLifeExpect(Tmatrix)#
                ptime[j,k,] <- PassageTime(chosen.size=chosen.size,Tmatrix); #print(ptime)#
                LE1[j,k,] <- MeanLifeExpect(Tmatrix1)#
                ptime1[j,k,] <- PassageTime(chosen.size=chosen.size,Tmatrix1); #print(ptime)#
#
    #
            }}#
#
    ## PLOT#
    if (do.plot) { #
#
        nyr <- 4#
        j<-k<-1#
        plot(Tmatrix@meshpoints,LE[j,k,]*nyr,type="l",xlab="size", ylab="life expectancy",#
             ylim=pmax(range(c(LE*nyr,LE1*nyr),na.rm=TRUE),1),...)#
#
        for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
                points(Tmatrix@meshpoints,LE[j,k,]*nyr,type="l",col=k)#
                points(Tmatrix1@meshpoints,LE1[j,k,]*nyr,type="l",col=k, lty=3)#
#
            }}#
#
        if (do.legend) { legend("bottomleft", legend=c("Power Law", "Monomolecular",#
                                              "Gompertz", "Logistic 3 par", "Logistic 4 par"),#
                                lty=1, col=1:5, bty="n", cex=0.8)}#
                         #
        #
        j<-k<-1#
        plot(Tmatrix@meshpoints,ptime[j,k,]*nyr,type="l",xlab="size", ylab="passage time",#
             ylim=pmax(range(c(ptime*nyr,ptime1*nyr),na.rm=TRUE),1),...)#
        for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
                points(Tmatrix@meshpoints,ptime[j,k,]*nyr,type="l",col=k)#
                points(Tmatrix1@meshpoints,ptime1[j,k,]*nyr,type="l",col=k,lty=3)#
#
            }}#
#
  #
    }#
            #
    #
   return(list(LE=LE,LE1=LE1,ptime=ptime,ptime1=ptime1, sizes=Tmatrix@meshpoints))#
    #
}#
#
#
#
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
    #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
            tmp <- fitSurvVaryingTimeIntervals(dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
dff<-getData()
a1<-survModelCompVaryInterval(dff)
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
    #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
                dataf <- rbind(dataf,newd)#
            }#
#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
#
#
#
## Function to fit survival with varying time increments and then write parameters#
## over onto a classic glm framework. #
##
# parameters - dataf - a dataframe including columns#
#                  size, surv, exactDate, and exactDatel, the latter two in days#
#            - nyrs - desired number of years in a time-step#
#            - par - starting values for the parameters#
#                     (must be of length one longer than covNames,#
#                       given intercept)#
#            - covNames - names of chosen covariates#
#            - method - method for optim ("Nelder-Mead", "SANN", etc.)#
##
# Returns  - output of optim#
##
fitSurvVaryingTimeIntervals <- function(dataf,#
                                        nyrs=5,#
                                        par=c(0.01,0.01,0.01,0.01),#
                                        covNames=c("size","size2","size3"),#
                                        method="Nelder-Mead") {#
#
    #warnings#
    if ((length(par)-1)!=length(covNames)) {#
        print("starting values does not match length of covariate names")#
    }#
#
    #
    tmp <- optim(par,likeSurvVaryingTimeIntervals,#
                 covNames=covNames,nyrs=nyrs,dataf=dataf,#
                 method=method)#
#
    #
    if (tmp$convergence!=0) {#
        tmp <- optim(tmp$par,likeSurvVaryingTimeIntervals,#
                     covNames=covNames,nyrs=nyrs,dataf=dataf,#
                     method=method)#
        if (tmp$convergence!=0)  print("not converged")        #
    }#
    #
    #write template over the top#
    if (length(covNames)>0) formula <- as.character(paste("surv~",paste(covNames,collapse="+"),collapse="")) else formula <- as.character("surv~1")#
    fit <- glm(formula,data=dataf,family=binomial)#
    #print(fit)#
    fit$coefficients <- tmp$par#
#
    sv1 <- new("survObj")#
    sv1@fit <- fit#
#
    tmp$sv1 <- sv1#
    #
    return(tmp)#
#
}#
#
#Function to calculate the likelihood for variable time-intervals for survival #
##
# parameters #
#            - par - starting values for the parameters#
#                     (must be of length one longer than covNames,#
#                       given intercept)#
#            - covNames - names of chosen covariates#
#            - nyrs - desired number of years in a time-step#
#            - dataf - a dataframe including columns in covNames, as well as#
#                  size, surv, exactDate, and exactDatel, the latter two in days#
##
# Returns  - numeric equal to minus the log likelihood#
##
likeSurvVaryingTimeIntervals <- function(par=c(0.01,0.01,0.01,0.01),#
                                         covNames=c("size","size2","size3"),#
                                         nyrs=5,#
                                         dataf) {#
#
    #
    #define time change#
    tdiff <- (dataf$exactDatel-dataf$exactDate)/(nyrs*365)#
    #print(range(tdiff, na.rm=TRUE))#
#
    #build predictor#
    if (length(covNames)>0) {#
        pred <-  t(t(dataf[,covNames])*par[2:length(par)])#
    }else { pred <- matrix(0,nrow(dataf),1)}#
    pred <- par[1] + rowSums(pred)#
    pred[pred>200] <- 200  #don't want bigger than exp(200) - gets infinite really quick#
    pred <- (exp(pred)/(1+exp(pred)))^(tdiff)#
    #
    #estimate likelihood#
    like <- dbinom(dataf$surv,1,pred, log=TRUE)#
    #like[like==-Inf] <- -exp(500)#
    #like[like==Inf] <- exp(500)#
#
    sumRows <- rep(0,nrow(dataf))#
    if (length(covNames)>1) sumRows <- rowSums(dataf[,covNames])#
    if (length(covNames)==1) sumRows <- dataf[,covNames]#
    #
    return(-sum(like[!is.na(sumRows) & !is.na(dataf$surv)],na.rm=TRUE))#
    #
}#
#
#
##note that there are very few species for which sufficient#
## mortality data is actually available! most just don't die...#
##
# vain, myda, hubr#
##
##
compareTmatrices <- function(dataf, growthObjList,survObjList, nBigMatrix=300,chosen.size=1500,#
                             do.plot=TRUE,do.legend=FALSE,...){ #
    #
    #STORAGE#
    LE <- LE1 <- ptime <- ptime1 <- array(dim=c(length(survObjList),length(growthObjList),nBigMatrix))#
      #
    ## LOOP OVER all possible combos#
    for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
             #
                sv1 <- survObjList[[j]]#
                gr1 <- growthObjList[[k]]#
                              #
                #BUILD Tmatrix#
                Tmatrix <- create.IPM.Tmatrix(nBigMatrix = nBigMatrix,#
                                              minSize = 0.9*min(dataf$size,na.rm=TRUE),#
                                              maxSize = 1.1*max(dataf$size,na.rm=TRUE),#
                                              growObj = gr1, survObj = sv1, correction="constant")#
                Tmatrix1 <- create.IPM.Tmatrix(nBigMatrix = nBigMatrix,#
                                               minSize = 0.9*min(dataf$size,na.rm=TRUE),#
                                               maxSize = 1.1*max(dataf$size,na.rm=TRUE),#
                                               growObj = gr1, survObj = sv1,integrate.type="cumul",#
                                               correction="constant")#
        #
                # Get the mean life expect from every size value in IPM#
                LE[j,k,] <- MeanLifeExpect(Tmatrix)#
                ptime[j,k,] <- PassageTime(chosen.size=chosen.size,Tmatrix); #print(ptime)#
                LE1[j,k,] <- MeanLifeExpect(Tmatrix1)#
                ptime1[j,k,] <- PassageTime(chosen.size=chosen.size,Tmatrix1); #print(ptime)#
#
    #
            }}#
#
    ## PLOT#
    if (do.plot) { #
#
        nyr <- 4#
        j<-k<-1#
        plot(Tmatrix@meshpoints,LE[j,k,]*nyr,type="l",xlab="size", ylab="life expectancy",#
             ylim=pmax(range(c(LE*nyr,LE1*nyr),na.rm=TRUE),1),...)#
#
        for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
                points(Tmatrix@meshpoints,LE[j,k,]*nyr,type="l",col=k)#
                points(Tmatrix1@meshpoints,LE1[j,k,]*nyr,type="l",col=k, lty=3)#
#
            }}#
#
        if (do.legend) { legend("bottomleft", legend=c("Power Law", "Monomolecular",#
                                              "Gompertz", "Logistic 3 par", "Logistic 4 par"),#
                                lty=1, col=1:5, bty="n", cex=0.8)}#
                         #
        #
        j<-k<-1#
        plot(Tmatrix@meshpoints,ptime[j,k,]*nyr,type="l",xlab="size", ylab="passage time",#
             ylim=pmax(range(c(ptime*nyr,ptime1*nyr),na.rm=TRUE),1),...)#
        for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
                points(Tmatrix@meshpoints,ptime[j,k,]*nyr,type="l",col=k)#
                points(Tmatrix1@meshpoints,ptime1[j,k,]*nyr,type="l",col=k,lty=3)#
#
            }}#
#
  #
    }#
            #
    #
   return(list(LE=LE,LE1=LE1,ptime=ptime,ptime1=ptime1, sizes=Tmatrix@meshpoints))#
    #
}#
#
#
#
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
    #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
                dataf <- rbind(dataf,newd)#
            }#
#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
    #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
                print(dim(dataf))#
                print(dim(newd))#
                print(head(dataf))#
                pring(head(newd))#
                dataf <- rbind(dataf,newd)#
            }#
#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
?data.frame
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
    #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
                dataf <- cbind(dataf,newd)#
            }#
#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
    #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
                dataf <- cbind(dataf,newd)#
                print(head(dataf))#
            }#
#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
    #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
            }#
#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=newd,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
    #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
                dataf  <-  cbind(dataf,newd[,2:ncol(newd)]) #don't need "size"#
            }#
#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=newd,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
    #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
                dataf  <-  cbind(dataf,newd[,2:ncol(newd)]) #don't need "size"#
            }#
#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
    #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
                if (ncol(newd)>1) dataf  <-  cbind(dataf,newd[,2:ncol(newd)]) #don't need "size"#
            }#
#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
    #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
                if (ncol(newd)>1) dataf  <-  cbind(dataf,newd[,2:ncol(newd)]) #don't need "size"#
            }#
#
            print(head(dataf))#
            print(covNames)#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
    #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
                if (ncol(newd)>1) { #
                    newd  <-  cbind(dataf,newd[,2:ncol(newd)]) #don't need "size"#
                    colnames(newd) <- c(colnames(dataf),colnames(newd[2:ncol(newd)]))#
                }#
            }#
#
            print(head(dataf))#
            print(covNames)#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=newd,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
                if (ncol(newd)>1) { #
                    newd  <-  cbind(dataf,newd[,2:ncol(newd)]) #don't need "size"#
                    colnames(newd) <- c(colnames(dataf),colnames(newd[2:ncol(newd)]))#
                }#
            }#
#
            print(head(dataf))#
            print(covNames)#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=newd,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
                if (ncol(newd)>1) { #
                    newd  <-  cbind(dataf,newd[,2:ncol(newd)]) #don't need "size"#
                    colnames(newd) <- c(colnames(dataf),colnames(newd[2:ncol(newd)]))#
                }#
            }#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=newd,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
likeSurvVaryingTimeIntervals <- function(par=c(0.01,0.01,0.01,0.01),#
                                         covNames=c("size","size2","size3"),#
                                         nyrs=5,#
                                         dataf) {#
#
    #
    #define time change#
    tdiff <- (dataf$exactDatel-dataf$exactDate)/(nyrs*365)#
    #print(range(tdiff, na.rm=TRUE))#
#
    print(covNames)#
    print(head(dataf[,covNames]))#
    #
    #build predictor#
    if (length(covNames)>0) {#
        pred <-  t(t(dataf[,covNames])*par[2:length(par)])#
    }else { pred <- matrix(0,nrow(dataf),1)}#
    pred <- par[1] + rowSums(pred)#
    pred[pred>200] <- 200  #don't want bigger than exp(200) - gets infinite really quick#
    pred <- (exp(pred)/(1+exp(pred)))^(tdiff)#
    #
    #estimate likelihood#
    like <- dbinom(dataf$surv,1,pred, log=TRUE)#
    #like[like==-Inf] <- -exp(500)#
    #like[like==Inf] <- exp(500)#
#
    sumRows <- rep(0,nrow(dataf))#
    if (length(covNames)>1) sumRows <- rowSums(dataf[,covNames])#
    if (length(covNames)==1) sumRows <- dataf[,covNames]#
    #
    return(-sum(like[!is.na(sumRows) & !is.na(dataf$surv)],na.rm=TRUE))#
    #
}
a1<-survModelCompVaryInterval(dff)
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
             #make sure you have all the right covariates#
            if (length(covNames)>0) {#
                newd <- .makeCovDf(dataf$size, expVars[v])#
                if (ncol(newd)>1) { #
                    newd  <-  cbind(dataf,newd[,2:ncol(newd)]) #don't need "size"#
                    colnames(newd) <- c(colnames(dataf),colnames(newd[2:ncol(newd)]))#
                }#
            }#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=newd,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
likeSurvVaryingTimeIntervals <- function(par=c(0.01,0.01,0.01,0.01),#
                                         covNames=c("size","size2","size3"),#
                                         nyrs=5,#
                                         dataf) {#
#
    #
    #define time change#
    tdiff <- (dataf$exactDatel-dataf$exactDate)/(nyrs*365)#
    #print(range(tdiff, na.rm=TRUE))#
#
    print(covNames)#
    print(head(dataf[,covNames]))#
    #
    #build predictor#
    if (length(covNames)>0) {#
        pred <-  t(t(dataf[,covNames])*par[2:length(par)])#
    }else { pred <- matrix(0,nrow(dataf),1)}#
    pred <- par[1] + rowSums(pred)#
    pred[pred>200] <- 200  #don't want bigger than exp(200) - gets infinite really quick#
    pred <- (exp(pred)/(1+exp(pred)))^(tdiff)#
#
    print("pred")#
    print(pred)#
    print(par)#
    #
    #estimate likelihood#
    like <- dbinom(dataf$surv,1,pred, log=TRUE)#
    #like[like==-Inf] <- -exp(500)#
    #like[like==Inf] <- exp(500)#
#
    sumRows <- rep(0,nrow(dataf))#
    if (length(covNames)>1) sumRows <- rowSums(dataf[,covNames])#
    if (length(covNames)==1) sumRows <- dataf[,covNames]#
    #
    return(-sum(like[!is.na(sumRows) & !is.na(dataf$surv)],na.rm=TRUE))#
    #
}
a1<-survModelCompVaryInterval(dff)
a1<-survModelCompVaryInterval(dff,explVar="size+size2")
a1<-survModelCompVaryInterval(dff,expVars="size+size2")
#
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
            #make sure you have all the right covariates#
            if(length(grep("size2",expVars[v])))#
			dataf$size2=(dataf$size)^2#
            if(length(grep("size3",expVars[v])))#
			dataf$size3=(dataf$size)^3#
            if(length(grep("logsize",expVars[v])))#
			dataf$logsize=log(dataf$size)#
            if(length(grep("logsize2",expVars[v])))#
			dataf$logsize=(log(dataf$size))^2#
	#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff,expVars="size+size2")
#
#
##### FUNCTIONS USED IN ANALYZING DATA FROM: http://esapubs.org/archive/ecol/E092/115/default.htm#data #
#
#
#setwd("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/")#
#source("R/IPMpack-Util.R")#
#source("R/IPMpack-Base.R")#
#source("R/IPMpack-Impl.R")#
#
#
## Function to alter vector from status description to#
# 0s and 1s for survival#
##
# Parameters - character vector#
##
# Returns - numeric vector#
##
convertStatus <- function(x) {#
    y <- rep(NA,length(x))#
    y[x=="A"] <- 1#
    y[x=="D"] <- 0#
    y[x=="P"] <- 1 #this is a future tree, usually no size - prob alive, but these are not evenly sampled#
#
    return(y)#
}#
#
#
## Function to sort out names, create codes, etc for India data#
##  - dumped out now, so don't need to re-run! - #
###
getSp <- function(filename="data/"){#
#
    #write out species names - takes by hand editing so only do once#
    det <-  read.delim(paste(filename,"SpeciesDetails.txt", sep=""),header=TRUE)#
    genus.end <-  regexpr(" ", det[,2]);#
    mat <- cbind(as.character(det$Family), substr(det$LatinName,1,genus.end),#
                 as.character(det$LatinName))#
    write.table(paste(mat[,1],"/",mat[,2],"/",mat[,3], sep=""),#
                file="names.sp",row.names=FALSE, quote = FALSE)#
    #remember, make lower case, put _ between genus and species name, remove " /" for use with phylomatic#
    #
    #
#
}#
#
#
## Function to pull in all the data taken from#
## http://esapubs.org/archive/ecol/E092/115/default.htm#data#
## Ecological Archives, E092-115-D1.#
## and organize it into a format recognized by IPMpack#
##
# parameters - filename - file describing location of the data#
#            - species - chosen species (four letter code, e.g., "vain", "myda", or "hubr") or "all"#
##
# returns - a data-frame with headings size, sizenext (adjusted for time interval),#
#                incr (raw increment), surv (survival), spcode,#
#              and exactDate and exactDatel in days#
##
getData <- function(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                    species="all"){#
#
    #bring in the data#
    df <- read.delim(paste(filename,"WesternGhatTrees.txt", sep=""),header=TRUE)#
    if (species!="all") df <- df[df$SpCode==species,]#
#
    #
    #get matrix of dates, sizes, survival #
    dates.raw <- cbind(df$Date0,df$Date1,df$Date2, df$Date3, df$Date4, df$Date5)  #
    sizes.raw <- cbind(df$GBH0,df$GBH1,df$GBH2,df$GBH3,df$GBH4,df$GBH5)#
    surv.raw <- cbind(convertStatus(df$Status0),convertStatus(df$Status1),convertStatus(df$Status2),#
                   convertStatus(df$Status3),convertStatus(df$Status4),convertStatus(df$Status5))#
#
    #get the raw increment for fitting detailed survival model#
    incr <- cbind(df$GBH1-df$GBH0,df$GBH2-df$GBH1,df$GBH3-df$GBH2,df$GBH4-df$GBH3,df$GBH5-df$GBH4)#
    #
    #loop over, predict sizes at days closest to 365*4 (bi-yearly intrvals)#
    pred.dates <- (365*4)*c(0:5)#
    predict.sizes <- matrix(NA,length(df[,1]),length(pred.dates))#
    predict.surv <- matrix(1,length(df[,1]),length(pred.dates))#
        #
    for (k in 1:length(df[,1])) {#
        x <- as.numeric(dates.raw[k,])#
        y <- sizes.raw[k,]#
#
        bad <- is.na(x) | is.na(y)#
        x <- x[!bad]#
        y <- y[!bad]#
     #
        #linear regression#
        if (length(x)<4) { #
            fit <- lm(y~x)#
            predict.sizes[k,] <- predict(fit,newdata=data.frame(x=pred.dates)) #linear reg#
        } else { #
        #smooth spline#
            fit <- smooth.spline(y~x)#
            predict.sizes[k,] <- predict(fit,x=pred.dates)$y #smooth spline#
        }#
            #
        bad <- which(pred.dates>max(x,na.rm=TRUE), arr.ind=TRUE)#
        if (length(bad)>0) predict.sizes[k,bad] <- NA#
        #
        dead <- dates.raw[k,surv.raw[k,]==0][1]#
        loc.dead <- which((dead-pred.dates)^2==min((dead-pred.dates)^2), arr.ind=TRUE)#
        if (length(loc.dead)>0) predict.surv[k,loc.dead:length(pred.dates)] <- 0              #
    }#
#
    #reassure yourself it might work#
#    matplot(t(dates.raw),t(sizes.raw), type="b", pch=19,xlab="dates", ylab="sizes")#
#    abline(v=pred.dates)#
#
        #
    dataf <- data.frame(size=c(predict.sizes[,1:5]),sizenext=c(predict.sizes[,2:6]),#
                        incr=c(incr[,1:5]),#
                        surv=c(predict.surv[,2:6]), spcode=rep(df$SpCode, 5),#
                        exactDate=c(dates.raw[,1:5]), exactDatel=c(dates.raw[,2:6]))#
#
    dataf <- dataf[!is.na(dataf$size),]#
    #
    return(dataf)#
#
}#
#
#
#
#
#
#
## Function to fit survival with varying time increments and then write parameters#
## over onto a classic glm framework. #
##
# parameters - dataf - a dataframe including columns#
#                  size, surv, exactDate, and exactDatel, the latter two in days#
#            - nyrs - desired number of years in a time-step#
#            - par - starting values for the parameters#
#                     (must be of length one longer than covNames,#
#                       given intercept)#
#            - covNames - names of chosen covariates#
#            - method - method for optim ("Nelder-Mead", "SANN", etc.)#
##
# Returns  - output of optim#
##
fitSurvVaryingTimeIntervals <- function(dataf,#
                                        nyrs=5,#
                                        par=c(0.01,0.01,0.01,0.01),#
                                        covNames=c("size","size2","size3"),#
                                        method="Nelder-Mead") {#
#
    #warnings#
    if ((length(par)-1)!=length(covNames)) {#
        print("starting values does not match length of covariate names")#
    }#
#
    #
    tmp <- optim(par,likeSurvVaryingTimeIntervals,#
                 covNames=covNames,nyrs=nyrs,dataf=dataf,#
                 method=method)#
#
    #
    if (tmp$convergence!=0) {#
        tmp <- optim(tmp$par,likeSurvVaryingTimeIntervals,#
                     covNames=covNames,nyrs=nyrs,dataf=dataf,#
                     method=method)#
        if (tmp$convergence!=0)  print("not converged")        #
    }#
    #
    #write template over the top#
    if (length(covNames)>0) formula <- as.character(paste("surv~",paste(covNames,collapse="+"),collapse="")) else formula <- as.character("surv~1")#
    fit <- glm(formula,data=dataf,family=binomial)#
    #print(fit)#
    fit$coefficients <- tmp$par#
#
    sv1 <- new("survObj")#
    sv1@fit <- fit#
#
    tmp$sv1 <- sv1#
    #
    return(tmp)#
#
}#
#
#Function to calculate the likelihood for variable time-intervals for survival #
##
# parameters #
#            - par - starting values for the parameters#
#                     (must be of length one longer than covNames,#
#                       given intercept)#
#            - covNames - names of chosen covariates#
#            - nyrs - desired number of years in a time-step#
#            - dataf - a dataframe including columns in covNames, as well as#
#                  size, surv, exactDate, and exactDatel, the latter two in days#
##
# Returns  - numeric equal to minus the log likelihood#
##
likeSurvVaryingTimeIntervals <- function(par=c(0.01,0.01,0.01,0.01),#
                                         covNames=c("size","size2","size3"),#
                                         nyrs=5,#
                                         dataf) {#
#
    #
    #define time change#
    tdiff <- (dataf$exactDatel-dataf$exactDate)/(nyrs*365)#
    #print(range(tdiff, na.rm=TRUE))#
#
    print(covNames)#
    print(head(dataf[,covNames]))#
    #
    #build predictor#
    if (length(covNames)>0) {#
        pred <-  t(t(dataf[,covNames])*par[2:length(par)])#
    }else { pred <- matrix(0,nrow(dataf),1)}#
    pred <- par[1] + rowSums(pred)#
    pred[pred>200] <- 200  #don't want bigger than exp(200) - gets infinite really quick#
    pred <- (exp(pred)/(1+exp(pred)))^(tdiff)#
   #
    #estimate likelihood#
    like <- dbinom(dataf$surv,1,pred, log=TRUE)#
    #like[like==-Inf] <- -exp(500)#
    #like[like==Inf] <- exp(500)#
#
    sumRows <- rep(0,nrow(dataf))#
    if (length(covNames)>1) sumRows <- rowSums(dataf[,covNames])#
    if (length(covNames)==1) sumRows <- dataf[,covNames]#
    #
    return(-sum(like[!is.na(sumRows) & !is.na(dataf$surv)],na.rm=TRUE))#
    #
}#
#
#
##note that there are very few species for which sufficient#
## mortality data is actually available! most just don't die...#
##
# vain, myda, hubr#
##
##
compareTmatrices <- function(dataf, growthObjList,survObjList, nBigMatrix=300,chosen.size=1500,#
                             do.plot=TRUE,do.legend=FALSE,...){ #
    #
    #STORAGE#
    LE <- LE1 <- ptime <- ptime1 <- array(dim=c(length(survObjList),length(growthObjList),nBigMatrix))#
      #
    ## LOOP OVER all possible combos#
    for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
             #
                sv1 <- survObjList[[j]]#
                gr1 <- growthObjList[[k]]#
                              #
                #BUILD Tmatrix#
                Tmatrix <- create.IPM.Tmatrix(nBigMatrix = nBigMatrix,#
                                              minSize = 0.9*min(dataf$size,na.rm=TRUE),#
                                              maxSize = 1.1*max(dataf$size,na.rm=TRUE),#
                                              growObj = gr1, survObj = sv1, correction="constant")#
                Tmatrix1 <- create.IPM.Tmatrix(nBigMatrix = nBigMatrix,#
                                               minSize = 0.9*min(dataf$size,na.rm=TRUE),#
                                               maxSize = 1.1*max(dataf$size,na.rm=TRUE),#
                                               growObj = gr1, survObj = sv1,integrate.type="cumul",#
                                               correction="constant")#
        #
                # Get the mean life expect from every size value in IPM#
                LE[j,k,] <- MeanLifeExpect(Tmatrix)#
                ptime[j,k,] <- PassageTime(chosen.size=chosen.size,Tmatrix); #print(ptime)#
                LE1[j,k,] <- MeanLifeExpect(Tmatrix1)#
                ptime1[j,k,] <- PassageTime(chosen.size=chosen.size,Tmatrix1); #print(ptime)#
#
    #
            }}#
#
    ## PLOT#
    if (do.plot) { #
#
        nyr <- 4#
        j<-k<-1#
        plot(Tmatrix@meshpoints,LE[j,k,]*nyr,type="l",xlab="size", ylab="life expectancy",#
             ylim=pmax(range(c(LE*nyr,LE1*nyr),na.rm=TRUE),1),...)#
#
        for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
                points(Tmatrix@meshpoints,LE[j,k,]*nyr,type="l",col=k)#
                points(Tmatrix1@meshpoints,LE1[j,k,]*nyr,type="l",col=k, lty=3)#
#
            }}#
#
        if (do.legend) { legend("bottomleft", legend=c("Power Law", "Monomolecular",#
                                              "Gompertz", "Logistic 3 par", "Logistic 4 par"),#
                                lty=1, col=1:5, bty="n", cex=0.8)}#
                         #
        #
        j<-k<-1#
        plot(Tmatrix@meshpoints,ptime[j,k,]*nyr,type="l",xlab="size", ylab="passage time",#
             ylim=pmax(range(c(ptime*nyr,ptime1*nyr),na.rm=TRUE),1),...)#
        for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
                points(Tmatrix@meshpoints,ptime[j,k,]*nyr,type="l",col=k)#
                points(Tmatrix1@meshpoints,ptime1[j,k,]*nyr,type="l",col=k,lty=3)#
#
            }}#
#
  #
    }#
            #
    #
   return(list(LE=LE,LE1=LE1,ptime=ptime,ptime1=ptime1, sizes=Tmatrix@meshpoints))#
    #
}#
#
#
#
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
#
            #make sure you have all the right covariates#
            if(length(grep("size2",expVars[v])))#
			dataf$size2=(dataf$size)^2#
            if(length(grep("size3",expVars[v])))#
			dataf$size3=(dataf$size)^3#
            if(length(grep("logsize",expVars[v])))#
			dataf$logsize=log(dataf$size)#
            if(length(grep("logsize2",expVars[v])))#
			dataf$logsize=(log(dataf$size))^2#
	#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}#
#
#
#
test <- function(){#
    #do simple to complicated, and use parameters from previous as starting values#
    m <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=0.01,cov.names=c())#
    m0 <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(0.01,0.01),cov.names=c("size"))#
    m1 <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m0$par,0),cov.names=c("size","size2"))#
    m2 <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m1$par,0),cov.names=c("size","size2","size3"))#
    #
    print("Comparison intercept and size")#
    print(1-pchisq(2*(m$value-m0$value),1))#
    print("Comparison size and size2")#
    print(1-pchisq(2*(m0$value-m1$value),1))#
    print("Comparison size2 and size3")#
    print(1-pchisq(2*(m1$value-m2$value),1))#
#
    m0a <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m0$par),cov.names=c("logsize"))#
    m1a <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m0$par,0),cov.names=c("size","logsize"))#
    m2a <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m1a$par,0),cov.names=c("size","logsize","logsize2"))#
#
    print("Comparison intercept and logsize")#
    print(1-pchisq(2*(m$value-m0a$value),1))#
    print("Comparison logsize and size+logsize")#
    print(1-pchisq(2*(m0a$value-m1a$value),1))#
    print("Comparison logsize and logsize2")#
    print(1-pchisq(2*(m1a$value-m2a$value),1))#
#
    print("Direct comparison likelihoods")#
    vals <- -c(m$value,m0$value,m1$value,m2$value,m0a$value,m1a$val,m2a$value) #log likelihood#
    AIC <- 2*c(length(m$par),length(m0$par),length(m1$par),length(m2$par),length(m0a$par),length(m1a$par),length(m2a$par))-2*vals#
    nmes <- c("1","size","size+size2","size+size2+size3","logsize","size+logsize","size+logsize+logsize2")#
    print(cbind(nmes,vals,AIC,order(vals)))#
    #
#
    if (plot) {#
        sizes <- seq(min(dataf$size,na.rm=TRUE), max(dataf$size,na.rm=TRUE),length=100)#
        picSurvData(dataf,ncuts=20)#
        points(sizes,surv(sizes,1,m$sv1),type="l",col=4, lty=2)#
        points(sizes,surv(sizes,1,m0$sv1),type="l",col=1, lty=2)#
        points(sizes,surv(sizes,1,m1$sv1),type="l",col=2, lty=2)#
        points(sizes,surv(sizes,1,m2$sv1),type="l",col=3, lty=2)#
        points(sizes,surv(sizes,1,m0a$sv1),type="l",col=1, lty=3)#
        points(sizes,surv(sizes,1,m1a$sv1),type="l",col=2, lty=3)#
        points(sizes,surv(sizes,1,m2a$sv1),type="l",col=3, lty=3)#
        legend("bottomleft", legend=paste(nmes,paste(", AIC=",round(AIC,1), sep="")), text.col=c(4,1:3,1:3),#
               col=c(4,1:3,1:3),lty=c(2,rep(2,3),rep(3,3)), bty="o", cex=0.8,bg="white",box.col="white")#
     #
    }#
#
    return(list(m=m,m0=m0,m1=m1,m2=m2,m0a=m0a,m1a=m1a,m2a=m2a))#
                 #
}#
#
#
#
#
## Just make a picture of the survival probs from the data#
## [Useful for overlaying various fits...]#
picSurvData <- function(dataf,ncuts=12,...) { #
#
    #organize data and plot mean of ncut successive sizes, so trend more obvious#
    os<-order(dataf$size); os.surv<-(dataf$surv)[os]; os.size<-(dataf$size)[os]; #
    psz<-tapply(os.size,as.numeric(cut(os.size,ncuts)),mean,na.rm=TRUE); #print(psz)#
    ps<-tapply(os.surv,as.numeric(cut(os.size,ncuts)),mean,na.rm=TRUE);#print(ps)#
#
    #plot data#
    plot(as.numeric(psz),as.numeric(ps),pch=19,#
         xlab="Size at t", ylab="Survival to t+1",...)#
    #
}#
#
likeCompareClassicGrowthFits <- function(dataf, plot=FALSE,responseType="sizenext") {#
#
    #Function to create a time-scaled incr or log increment (the incr in the dataf is actually the "true"#
    # over the arbitrary census interval)#
    if (responseType=="incr") dataf$incr <- (dataf$sizenext-dataf$size)#
    if (responseType=="logincr") dataf$logincr <- log(dataf$sizenext-dataf$size)#
    #
    #do simple to complicated, and use parameters from previous as starting values#
    m <- makeGrowthObjGeneral(dataf,explanatoryVariables="1",#
                               responseType=responseType,regType="constantVar")#
    m0 <- makeGrowthObjGeneral(dataf,explanatoryVariables="size",#
                               responseType=responseType,regType="constantVar")#
    m1 <- makeGrowthObjGeneral(dataf,explanatoryVariables="size+size2",#
                               responseType=responseType,regType="constantVar")#
    m2 <- makeGrowthObjGeneral(dataf,explanatoryVariables="size+size2+size3",#
                               responseType=responseType,regType="constantVar")#
    m0a <- makeGrowthObjGeneral(dataf,explanatoryVariables="logsize",#
                               responseType=responseType,regType="constantVar")#
    m1a <- makeGrowthObjGeneral(dataf,explanatoryVariables="logsize+size",#
                               responseType=responseType,regType="constantVar")#
    m2a <- makeGrowthObjGeneral(dataf,explanatoryVariables="logsize+size+size2",#
                               responseType=responseType,regType="constantVar")#
#
    print(anova(m@fit,m0@fit,test="Chi"))#
    print(anova(m0@fit,m1@fit,test="Chi"))#
    print(anova(m1@fit,m2@fit,test="Chi"))#
#
    print(anova(m@fit,m0a@fit,test="Chi"))#
    print(anova(m0a@fit,m1a@fit,test="Chi"))#
    print(anova(m1a@fit,m2a@fit,test="Chi"))#
#
#
    if (plot){#
        scalar <- 100; minsc <- 1e-9#
        sizes <- seq(min(dataf$size,na.rm=TRUE), max(dataf$size,na.rm=TRUE),length=500)#
        chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
        newd<-data.frame(size=sizes,size2=sizes^2,size3=sizes^3,logsize=log(sizes))#
        if (responseType=="sizenext")#
            plot(dff$size,dff$sizenext, pch=19,col="grey", xlab="Size at t", ylab="Size at t+delta")#
        if (responseType=="incr")#
            plot(dff$size,dff$incr, pch=19,col="grey", xlab="Size at t", ylab="Incr at t+delta")#
        if (responseType=="logincr")#
            plot(dff$size,dff$logincr, pch=19,col="grey", xlab="Size at t", ylab="Incr at t+delta")#
        if (responseType!="sizenext")points(sizes,predict(m@fit,newdata=newd),type="l",col=4, lty=2)#
        points(sizes,predict(m0@fit,newdata=newd),type="l",col=1, lty=2)#
        points(sizes,predict(m1@fit,newdata=newd),type="l",col=2, lty=2)#
        points(sizes,predict(m2@fit,newdata=newd),type="l",col=3, lty=2)#
        #points(sizes,predict(m0a@fit,newdata=newd),type="l",col=1, lty=3)#
        #points(sizes,predict(m1a@fit,newdata=newd),type="l",col=2, lty=3)#
        #points(sizes,predict(m2a@fit,newdata=newd),type="l",col=3, lty=3)#
        #
        for (k in 1:length(chs)) {#
            resp <- growth(sizes[chs[k]],sizes,1,m)*scalar; #resp[resp<minsc] <- NA   #
            if (responseType!="sizenext")#
                points(sizes[chs[k]]+resp,sizes, type="l", col=4, lty=2)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,m0)*scalar; #resp[resp<minsc] <- NA#
            #print(sizes[chs[k]]+resp)#
            points(sizes[chs[k]]+resp,sizes, type="l", col=1, lty=2)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,m1)*scalar; #resp[resp<minsc] <- NA   #
            points(sizes[chs[k]]+resp,sizes, type="l", col=2, lty=2)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,m2)*scalar; resp[resp<minsc] <- NA   #
            points(sizes[chs[k]]+resp,sizes, type="l", col=3, lty=2)                                       #
            #resp <- growth(sizes[chs[k]],sizes,1,m0a)*scalar; resp[resp<minsc] <- NA   #
            #points(sizes[chs[k]]+resp,sizes, type="l", col=1, lty=3)                                       #
            #resp <- growth(sizes[chs[k]],sizes,1,m1a)*scalar; resp[resp<minsc] <- NA   #
            #points(sizes[chs[k]]+resp,sizes, type="l", col=2, lty=3)                                       #
            #resp <- growth(sizes[chs[k]],sizes,1,m2a)*scalar; resp[resp<minsc] <- NA   #
            #points(sizes[chs[k]]+resp,sizes, type="l", col=3, lty=3)                                       #
        }#
          #
    }#
#
    return(list(m=m,m0=m0,m1=m1,m2=m2,m0a=m0a,m1a=m1a,m2a=m2a))#
}#
#
#
####################################################################################################
##
##
## Make Figure 1- showning basic qualities of the data ####
## for three species with sufficient mortality info ######
##
FigureOne <- function(){#
#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
#
    #
    # 1. create exact times figure#
    par(mfrow=c(1,3),bty="l")#
    brks <- c(-0.5,1.5,2.5,3.5,4.5,5.5)#
    #
    for (k in 1:length(sp.list)) {#
        a1<-hist(c(dff$exactDatel[dff$spcode==sp.list[k]]-dff$exactDate[dff$spcode==sp.list[k]])/365,#
        breaks=brks, plot=FALSE)#
        if (k==1) cts <- a1$counts#
        if (k>1) cts <- rbind(cts,a1$counts)#
    #
    }#
#
    barplot(cts,beside=TRUE, names.arg=c("<1","2","3","4","5"), xlab="Census interval (years)")#
    legend("topleft",legend=sp.names,col=gray.colors(length(sp.list)), pch=15, bty="n")#
#
    # 2. Create survival figure#
    sp.num <- rep(1,length(dff$spcode));#
    for (k in 2:length(sp.list)) sp.num[dff$spcode==sp.list[k]] <- k#
    surv.sp <- dff$surv + 10*sp.num#
    boxplot(dff$size~surv.sp,log="y",axes="FALSE", xlab="Survival status",#
            ylab="DBH (cm)", col=rep(gray.colors(length(sp.list)), each=2))#
    axis(2)#
    axis(1,at=1:6,lab=c(0,1,0,1,0,1))#
    legend("topright",legend=sp.names,col=gray.colors(length(sp.list)), pch=15, bty="n")#
#
    #
    # 3. Create corrected growth increment figure#
    incr.corrected <- dff$incr/((dff$exactDatel-dff$exactDate)/365)#
    boxplot(incr.corrected~sp.num, col=gray.colors(length(sp.list)),axes=FALSE,#
            ylab="Time adjusted increment (cm)", ylim=c(-1.5,5))#
    abline(h=0,lty=3)#
    legend("topright",legend=sp.names,col=gray.colors(length(sp.list)), pch=15, bty="n")#
    axis(2)#
    axis(1,at=1:3,lab=sp.names)#
    #
    #
    #
#
}#
#
#
#
#
## Make Figure 2 - various survival models#
##
##
FigureTwo <- function(){#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
#
    par(mfrow=c(1,3),bty="l",family = "Helvetica")#
    #
    res1 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE)#
    title(sp.names[1])#
    res2 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    title(sp.names[2])#
    res3 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    title(sp.names[3])#
#
#
}#
#
#
## Make Figure 3 - various growth models with data, and then predicted size, sizenext and densty functions#
##
#  NOTE - that this should be using the ADJUSTED increment, hence over-written below by difference sizenext-size#
#  which was obtained via the spline#
##
FigureThree <- function(){#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
    dff$incr <- dff$sizenext - dff$size#
    #
    #pic with the data - get all the estimates#
    par(mfrow=c(3,5),bty="l", pty="m")#
    res1 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE, plot.title=TRUE)#
    mtext(sp.names[1])#
    res2 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    mtext(sp.names[2])#
    res3 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    mtext(sp.names[3])#
#
    #pic size, size next with density functions on#
    par(mfrow=c(1,3),bty="l")#
    sizes <- seq(min(dff$size,na.rm=TRUE), max(dff$size,na.rm=TRUE),length=500)#
    chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
    scalar <- 100; minsc <- 0.0001#
   #
    for (j in 1:length(sp.list)) { #
        plot(dff$size[dff$spcode==sp.list[j]],dff$sizenext[dff$spcode==sp.list[j]], pch=19,col="grey", xlab="Size at t", ylab="Size at t+delta")#
        mtext(sp.names[j])#
#
        sizes <- seq(min(dff$size[dff$spcode==sp.list[j]],na.rm=TRUE),#
                       max(dff$size[dff$spcode==sp.list[j]],na.rm=TRUE),length=500)#
        chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
  #
        for (k in 1:length(chs)) {#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m1)*scalar; resp[resp<minsc] <- NA   #Power Law#
            points(sizes[chs[k]]+resp,sizes, type="l", col=1)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,res1$m2)*scalar; resp[resp<minsc] <- NA   #Monomolecular#
            points(sizes[chs[k]]+resp,sizes, type="l", col=2)#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m3)*scalar; resp[resp<minsc] <- NA   #Gompertz#
            points(sizes[chs[k]]+resp,sizes, type="l", col=3)                                #
            resp <- growth(sizes[chs[k]],sizes,1,res1$m4)*scalar; resp[resp<minsc] <- NA   #Logistic 3#
            points(sizes[chs[k]]+resp,sizes, type="l", col=4)#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m5)*scalar; resp[resp<minsc] <- NA   #Logistic 4#
            points(sizes[chs[k]]+resp,sizes, type="l", col=5)#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m6)*scalar; resp[resp<minsc] <- NA   #Hossfeld#
            points(sizes[chs[k]]+resp,sizes, type="l", col=6)#
            #
        }#
        if (j==1) legend("topleft", legend=c("Power Law", "Monomolecular",#
                                    "Gompertz", "Logistic 3 par", "Logistic 4 par", "Hossfeld"),#
            lty=1, col=1:6, bty="n", cex=0.8)#
        abline(0,1,lty=3)#
        #
    }#
#
    #pic just of increments#
    chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
    par(mfrow=c(3,1), bty="l",pty="m")#
    scalar <- 1#
    for (j in 1:3) { #
        plot(sizes, sizes, ylim=c(0,0.35),#
             type="n", xlab="Size", ylab="Density in next time-step", xlim=range(sizes[c(chs+10,chs-10)]))#
        for (k in 1:length(chs)) {#
#
            if (j==1) res <- res1#
            if (j==2) res <- res2#
            if (j==3) res <- res3            #
                                        #Power Law#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m1)*scalar, type="l", col=1)#
                                        #Monomolecular#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m2)*scalar, type="l", col=2)#
                                        #Gompertz#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m3)*scalar, type="l", col=3)#
                                        #Logistic 3#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m4)*scalar, type="l", col=4)#
                                        #Logistic 4#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m5)*scalar, type="l", col=5)#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m6)*scalar, type="l", col=6)#
            #
        }#
        if (j==1) legend(110,0.35,#
            legend=c("Power Law", "Monomolecular","Gompertz", "Logistic 3 par", "Logistic 4 par","Hossfeld"),#
            lty=1, col=1:6, bty="n", cex=0.8)#
        mtext(sp.names[j])#
        abline(v=sizes[chs], lty=3)#
        #
    }#
    #
    return(list(res1=res1,res2=res2,res3=res3))#
}#
#
#
#
Figure4 <- function(){#
#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    #get data#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
    dff$incr <- dff$sizenext - dff$size#
    #
    #pic with the data for growth - get all the estimates#
    par(mfrow=c(3,5),bty="l", pty="m")#
    grow.res1 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE, plot.title=TRUE)#
    mtext(sp.names[1])#
    grow.res2 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    mtext(sp.names[2])#
    grow.res3 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    mtext(sp.names[3])#
#
    #same for survival#
    surv.res1 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE)#
    title(sp.names[1])#
    surv.res2 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    title(sp.names[2])#
    surv.res3 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    title(sp.names[3])#
#
#
    #picture    #
    par(mfrow=c(2,2),bty="l")#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[1],],log="y",#
                           growthObjList=grow.res1[1:5],#
                           survObjList=list(surv.res1$m0$sv1), nBigMatrix=300,chosen.size=1500,#
                           do.legend=TRUE)#
    mtext(sp.list[1],side=3)#
#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[1],],log="y",#
                           growthObjList=grow.res1[1:5],#
                           survObjList=list(surv.res1$m1$sv1), nBigMatrix=300,chosen.size=1500)#
#
#
    par(mfrow=c(2,2),bty="l")#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[2],],log="y",#
                           growthObjList=grow.res2[1:5],#
                           survObjList=list(surv.res2$m0$sv1), nBigMatrix=300,chosen.size=1500,#
                           do.legend=TRUE)#
    mtext(sp.list[2],side=3)#
#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[2],],log="y",#
                           growthObjList=grow.res2[1:5],#
                           survObjList=list(surv.res2$m1$sv1), nBigMatrix=300,chosen.size=1500)#
#
    par(mfrow=c(2,2),bty="l")#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[3],],log="y",#
                           growthObjList=grow.res3[1:5],#
                           survObjList=list(surv.res3$m0$sv1), nBigMatrix=300,chosen.size=1500,#
                           do.legend=TRUE)#
    mtext(sp.list[3],side=3)#
#
#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[3],],log="y",#
                           growthObjList=grow.res3[1:5],#
                           survObjList=list(surv.res3$m1$sv1), nBigMatrix=300,chosen.size=1500)#
#
    #
}
a1<-survModelCompVaryInterval(dff,expVars="size+size2")
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
            print(parStart)#
            #
            #make sure you have all the right covariates#
            if(length(grep("size2",expVars[v])))#
			dataf$size2=(dataf$size)^2#
            if(length(grep("size3",expVars[v])))#
			dataf$size3=(dataf$size)^3#
            if(length(grep("logsize",expVars[v])))#
			dataf$logsize=log(dataf$size)#
            if(length(grep("logsize2",expVars[v])))#
			dataf$logsize=(log(dataf$size))^2#
	#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff,expVars="size+size2")
#
#
##### FUNCTIONS USED IN ANALYZING DATA FROM: http://esapubs.org/archive/ecol/E092/115/default.htm#data #
#
#
#setwd("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/")#
#source("R/IPMpack-Util.R")#
#source("R/IPMpack-Base.R")#
#source("R/IPMpack-Impl.R")#
#
#
## Function to alter vector from status description to#
# 0s and 1s for survival#
##
# Parameters - character vector#
##
# Returns - numeric vector#
##
convertStatus <- function(x) {#
    y <- rep(NA,length(x))#
    y[x=="A"] <- 1#
    y[x=="D"] <- 0#
    y[x=="P"] <- 1 #this is a future tree, usually no size - prob alive, but these are not evenly sampled#
#
    return(y)#
}#
#
#
## Function to sort out names, create codes, etc for India data#
##  - dumped out now, so don't need to re-run! - #
###
getSp <- function(filename="data/"){#
#
    #write out species names - takes by hand editing so only do once#
    det <-  read.delim(paste(filename,"SpeciesDetails.txt", sep=""),header=TRUE)#
    genus.end <-  regexpr(" ", det[,2]);#
    mat <- cbind(as.character(det$Family), substr(det$LatinName,1,genus.end),#
                 as.character(det$LatinName))#
    write.table(paste(mat[,1],"/",mat[,2],"/",mat[,3], sep=""),#
                file="names.sp",row.names=FALSE, quote = FALSE)#
    #remember, make lower case, put _ between genus and species name, remove " /" for use with phylomatic#
    #
    #
#
}#
#
#
## Function to pull in all the data taken from#
## http://esapubs.org/archive/ecol/E092/115/default.htm#data#
## Ecological Archives, E092-115-D1.#
## and organize it into a format recognized by IPMpack#
##
# parameters - filename - file describing location of the data#
#            - species - chosen species (four letter code, e.g., "vain", "myda", or "hubr") or "all"#
##
# returns - a data-frame with headings size, sizenext (adjusted for time interval),#
#                incr (raw increment), surv (survival), spcode,#
#              and exactDate and exactDatel in days#
##
getData <- function(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                    species="all"){#
#
    #bring in the data#
    df <- read.delim(paste(filename,"WesternGhatTrees.txt", sep=""),header=TRUE)#
    if (species!="all") df <- df[df$SpCode==species,]#
#
    #
    #get matrix of dates, sizes, survival #
    dates.raw <- cbind(df$Date0,df$Date1,df$Date2, df$Date3, df$Date4, df$Date5)  #
    sizes.raw <- cbind(df$GBH0,df$GBH1,df$GBH2,df$GBH3,df$GBH4,df$GBH5)#
    surv.raw <- cbind(convertStatus(df$Status0),convertStatus(df$Status1),convertStatus(df$Status2),#
                   convertStatus(df$Status3),convertStatus(df$Status4),convertStatus(df$Status5))#
#
    #get the raw increment for fitting detailed survival model#
    incr <- cbind(df$GBH1-df$GBH0,df$GBH2-df$GBH1,df$GBH3-df$GBH2,df$GBH4-df$GBH3,df$GBH5-df$GBH4)#
    #
    #loop over, predict sizes at days closest to 365*4 (bi-yearly intrvals)#
    pred.dates <- (365*4)*c(0:5)#
    predict.sizes <- matrix(NA,length(df[,1]),length(pred.dates))#
    predict.surv <- matrix(1,length(df[,1]),length(pred.dates))#
        #
    for (k in 1:length(df[,1])) {#
        x <- as.numeric(dates.raw[k,])#
        y <- sizes.raw[k,]#
#
        bad <- is.na(x) | is.na(y)#
        x <- x[!bad]#
        y <- y[!bad]#
     #
        #linear regression#
        if (length(x)<4) { #
            fit <- lm(y~x)#
            predict.sizes[k,] <- predict(fit,newdata=data.frame(x=pred.dates)) #linear reg#
        } else { #
        #smooth spline#
            fit <- smooth.spline(y~x)#
            predict.sizes[k,] <- predict(fit,x=pred.dates)$y #smooth spline#
        }#
            #
        bad <- which(pred.dates>max(x,na.rm=TRUE), arr.ind=TRUE)#
        if (length(bad)>0) predict.sizes[k,bad] <- NA#
        #
        dead <- dates.raw[k,surv.raw[k,]==0][1]#
        loc.dead <- which((dead-pred.dates)^2==min((dead-pred.dates)^2), arr.ind=TRUE)#
        if (length(loc.dead)>0) predict.surv[k,loc.dead:length(pred.dates)] <- 0              #
    }#
#
    #reassure yourself it might work#
#    matplot(t(dates.raw),t(sizes.raw), type="b", pch=19,xlab="dates", ylab="sizes")#
#    abline(v=pred.dates)#
#
        #
    dataf <- data.frame(size=c(predict.sizes[,1:5]),sizenext=c(predict.sizes[,2:6]),#
                        incr=c(incr[,1:5]),#
                        surv=c(predict.surv[,2:6]), spcode=rep(df$SpCode, 5),#
                        exactDate=c(dates.raw[,1:5]), exactDatel=c(dates.raw[,2:6]))#
#
    dataf <- dataf[!is.na(dataf$size),]#
    #
    return(dataf)#
#
}#
#
#
#
#
#
#
## Function to fit survival with varying time increments and then write parameters#
## over onto a classic glm framework. #
##
# parameters - dataf - a dataframe including columns#
#                  size, surv, exactDate, and exactDatel, the latter two in days#
#            - nyrs - desired number of years in a time-step#
#            - par - starting values for the parameters#
#                     (must be of length one longer than covNames,#
#                       given intercept)#
#            - covNames - names of chosen covariates#
#            - method - method for optim ("Nelder-Mead", "SANN", etc.)#
##
# Returns  - output of optim#
##
fitSurvVaryingTimeIntervals <- function(dataf,#
                                        nyrs=5,#
                                        par=c(0.01,0.01,0.01,0.01),#
                                        covNames=c("size","size2","size3"),#
                                        method="Nelder-Mead") {#
#
    #warnings#
    if ((length(par)-1)!=length(covNames)) {#
        print("starting values does not match length of covariate names")#
    }#
#
    #
    tmp <- optim(par,likeSurvVaryingTimeIntervals,#
                 covNames=covNames,nyrs=nyrs,dataf=dataf,#
                 method=method)#
#
    #
    if (tmp$convergence!=0) {#
        tmp <- optim(tmp$par,likeSurvVaryingTimeIntervals,#
                     covNames=covNames,nyrs=nyrs,dataf=dataf,#
                     method=method)#
        if (tmp$convergence!=0)  print("not converged")        #
    }#
    #
    #write template over the top#
    if (length(covNames)>0) formula <- as.character(paste("surv~",paste(covNames,collapse="+"),collapse="")) else formula <- as.character("surv~1")#
    fit <- glm(formula,data=dataf,family=binomial)#
    #print(fit)#
    fit$coefficients <- tmp$par#
#
    sv1 <- new("survObj")#
    sv1@fit <- fit#
#
    tmp$sv1 <- sv1#
    #
    return(tmp)#
#
}#
#
#Function to calculate the likelihood for variable time-intervals for survival #
##
# parameters #
#            - par - starting values for the parameters#
#                     (must be of length one longer than covNames,#
#                       given intercept)#
#            - covNames - names of chosen covariates#
#            - nyrs - desired number of years in a time-step#
#            - dataf - a dataframe including columns in covNames, as well as#
#                  size, surv, exactDate, and exactDatel, the latter two in days#
##
# Returns  - numeric equal to minus the log likelihood#
##
likeSurvVaryingTimeIntervals <- function(par=c(0.01,0.01,0.01,0.01),#
                                         covNames=c("size","size2","size3"),#
                                         nyrs=5,#
                                         dataf) {#
#
    #
    #define time change#
    tdiff <- (dataf$exactDatel-dataf$exactDate)/(nyrs*365)#
    #print(range(tdiff, na.rm=TRUE))#
#
    #print(covNames)#
    #print(head(dataf[,covNames]))#
    #
    #build predictor#
    if (length(covNames)>0) {#
        pred <-  t(t(dataf[,covNames])*par[2:length(par)])#
    }else { pred <- matrix(0,nrow(dataf),1)}#
    pred <- par[1] + rowSums(pred)#
    pred[pred>200] <- 200  #don't want bigger than exp(200) - gets infinite really quick#
    pred <- (exp(pred)/(1+exp(pred)))^(tdiff)#
   #
    #estimate likelihood#
    like <- dbinom(dataf$surv,1,pred, log=TRUE)#
    #like[like==-Inf] <- -exp(500)#
    #like[like==Inf] <- exp(500)#
#
    sumRows <- rep(0,nrow(dataf))#
    if (length(covNames)>1) sumRows <- rowSums(dataf[,covNames])#
    if (length(covNames)==1) sumRows <- dataf[,covNames]#
    #
    return(-sum(like[!is.na(sumRows) & !is.na(dataf$surv)],na.rm=TRUE))#
    #
}#
#
#
##note that there are very few species for which sufficient#
## mortality data is actually available! most just don't die...#
##
# vain, myda, hubr#
##
##
compareTmatrices <- function(dataf, growthObjList,survObjList, nBigMatrix=300,chosen.size=1500,#
                             do.plot=TRUE,do.legend=FALSE,...){ #
    #
    #STORAGE#
    LE <- LE1 <- ptime <- ptime1 <- array(dim=c(length(survObjList),length(growthObjList),nBigMatrix))#
      #
    ## LOOP OVER all possible combos#
    for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
             #
                sv1 <- survObjList[[j]]#
                gr1 <- growthObjList[[k]]#
                              #
                #BUILD Tmatrix#
                Tmatrix <- create.IPM.Tmatrix(nBigMatrix = nBigMatrix,#
                                              minSize = 0.9*min(dataf$size,na.rm=TRUE),#
                                              maxSize = 1.1*max(dataf$size,na.rm=TRUE),#
                                              growObj = gr1, survObj = sv1, correction="constant")#
                Tmatrix1 <- create.IPM.Tmatrix(nBigMatrix = nBigMatrix,#
                                               minSize = 0.9*min(dataf$size,na.rm=TRUE),#
                                               maxSize = 1.1*max(dataf$size,na.rm=TRUE),#
                                               growObj = gr1, survObj = sv1,integrate.type="cumul",#
                                               correction="constant")#
        #
                # Get the mean life expect from every size value in IPM#
                LE[j,k,] <- MeanLifeExpect(Tmatrix)#
                ptime[j,k,] <- PassageTime(chosen.size=chosen.size,Tmatrix); #print(ptime)#
                LE1[j,k,] <- MeanLifeExpect(Tmatrix1)#
                ptime1[j,k,] <- PassageTime(chosen.size=chosen.size,Tmatrix1); #print(ptime)#
#
    #
            }}#
#
    ## PLOT#
    if (do.plot) { #
#
        nyr <- 4#
        j<-k<-1#
        plot(Tmatrix@meshpoints,LE[j,k,]*nyr,type="l",xlab="size", ylab="life expectancy",#
             ylim=pmax(range(c(LE*nyr,LE1*nyr),na.rm=TRUE),1),...)#
#
        for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
                points(Tmatrix@meshpoints,LE[j,k,]*nyr,type="l",col=k)#
                points(Tmatrix1@meshpoints,LE1[j,k,]*nyr,type="l",col=k, lty=3)#
#
            }}#
#
        if (do.legend) { legend("bottomleft", legend=c("Power Law", "Monomolecular",#
                                              "Gompertz", "Logistic 3 par", "Logistic 4 par"),#
                                lty=1, col=1:5, bty="n", cex=0.8)}#
                         #
        #
        j<-k<-1#
        plot(Tmatrix@meshpoints,ptime[j,k,]*nyr,type="l",xlab="size", ylab="passage time",#
             ylim=pmax(range(c(ptime*nyr,ptime1*nyr),na.rm=TRUE),1),...)#
        for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
                points(Tmatrix@meshpoints,ptime[j,k,]*nyr,type="l",col=k)#
                points(Tmatrix1@meshpoints,ptime1[j,k,]*nyr,type="l",col=k,lty=3)#
#
            }}#
#
  #
    }#
            #
    #
   return(list(LE=LE,LE1=LE1,ptime=ptime,ptime1=ptime1, sizes=Tmatrix@meshpoints))#
    #
}#
#
#
#
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
            print(parStart)#
            #
            #make sure you have all the right covariates#
            if(length(grep("size2",expVars[v])))#
			dataf$size2=(dataf$size)^2#
            if(length(grep("size3",expVars[v])))#
			dataf$size3=(dataf$size)^3#
            if(length(grep("logsize",expVars[v])))#
			dataf$logsize=log(dataf$size)#
            if(length(grep("logsize2",expVars[v])))#
			dataf$logsize=(log(dataf$size))^2#
	#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}#
#
#
#
test <- function(){#
    #do simple to complicated, and use parameters from previous as starting values#
    m <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=0.01,cov.names=c())#
    m0 <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(0.01,0.01),cov.names=c("size"))#
    m1 <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m0$par,0),cov.names=c("size","size2"))#
    m2 <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m1$par,0),cov.names=c("size","size2","size3"))#
    #
    print("Comparison intercept and size")#
    print(1-pchisq(2*(m$value-m0$value),1))#
    print("Comparison size and size2")#
    print(1-pchisq(2*(m0$value-m1$value),1))#
    print("Comparison size2 and size3")#
    print(1-pchisq(2*(m1$value-m2$value),1))#
#
    m0a <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m0$par),cov.names=c("logsize"))#
    m1a <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m0$par,0),cov.names=c("size","logsize"))#
    m2a <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m1a$par,0),cov.names=c("size","logsize","logsize2"))#
#
    print("Comparison intercept and logsize")#
    print(1-pchisq(2*(m$value-m0a$value),1))#
    print("Comparison logsize and size+logsize")#
    print(1-pchisq(2*(m0a$value-m1a$value),1))#
    print("Comparison logsize and logsize2")#
    print(1-pchisq(2*(m1a$value-m2a$value),1))#
#
    print("Direct comparison likelihoods")#
    vals <- -c(m$value,m0$value,m1$value,m2$value,m0a$value,m1a$val,m2a$value) #log likelihood#
    AIC <- 2*c(length(m$par),length(m0$par),length(m1$par),length(m2$par),length(m0a$par),length(m1a$par),length(m2a$par))-2*vals#
    nmes <- c("1","size","size+size2","size+size2+size3","logsize","size+logsize","size+logsize+logsize2")#
    print(cbind(nmes,vals,AIC,order(vals)))#
    #
#
    if (plot) {#
        sizes <- seq(min(dataf$size,na.rm=TRUE), max(dataf$size,na.rm=TRUE),length=100)#
        picSurvData(dataf,ncuts=20)#
        points(sizes,surv(sizes,1,m$sv1),type="l",col=4, lty=2)#
        points(sizes,surv(sizes,1,m0$sv1),type="l",col=1, lty=2)#
        points(sizes,surv(sizes,1,m1$sv1),type="l",col=2, lty=2)#
        points(sizes,surv(sizes,1,m2$sv1),type="l",col=3, lty=2)#
        points(sizes,surv(sizes,1,m0a$sv1),type="l",col=1, lty=3)#
        points(sizes,surv(sizes,1,m1a$sv1),type="l",col=2, lty=3)#
        points(sizes,surv(sizes,1,m2a$sv1),type="l",col=3, lty=3)#
        legend("bottomleft", legend=paste(nmes,paste(", AIC=",round(AIC,1), sep="")), text.col=c(4,1:3,1:3),#
               col=c(4,1:3,1:3),lty=c(2,rep(2,3),rep(3,3)), bty="o", cex=0.8,bg="white",box.col="white")#
     #
    }#
#
    return(list(m=m,m0=m0,m1=m1,m2=m2,m0a=m0a,m1a=m1a,m2a=m2a))#
                 #
}#
#
#
#
#
## Just make a picture of the survival probs from the data#
## [Useful for overlaying various fits...]#
picSurvData <- function(dataf,ncuts=12,...) { #
#
    #organize data and plot mean of ncut successive sizes, so trend more obvious#
    os<-order(dataf$size); os.surv<-(dataf$surv)[os]; os.size<-(dataf$size)[os]; #
    psz<-tapply(os.size,as.numeric(cut(os.size,ncuts)),mean,na.rm=TRUE); #print(psz)#
    ps<-tapply(os.surv,as.numeric(cut(os.size,ncuts)),mean,na.rm=TRUE);#print(ps)#
#
    #plot data#
    plot(as.numeric(psz),as.numeric(ps),pch=19,#
         xlab="Size at t", ylab="Survival to t+1",...)#
    #
}#
#
likeCompareClassicGrowthFits <- function(dataf, plot=FALSE,responseType="sizenext") {#
#
    #Function to create a time-scaled incr or log increment (the incr in the dataf is actually the "true"#
    # over the arbitrary census interval)#
    if (responseType=="incr") dataf$incr <- (dataf$sizenext-dataf$size)#
    if (responseType=="logincr") dataf$logincr <- log(dataf$sizenext-dataf$size)#
    #
    #do simple to complicated, and use parameters from previous as starting values#
    m <- makeGrowthObjGeneral(dataf,explanatoryVariables="1",#
                               responseType=responseType,regType="constantVar")#
    m0 <- makeGrowthObjGeneral(dataf,explanatoryVariables="size",#
                               responseType=responseType,regType="constantVar")#
    m1 <- makeGrowthObjGeneral(dataf,explanatoryVariables="size+size2",#
                               responseType=responseType,regType="constantVar")#
    m2 <- makeGrowthObjGeneral(dataf,explanatoryVariables="size+size2+size3",#
                               responseType=responseType,regType="constantVar")#
    m0a <- makeGrowthObjGeneral(dataf,explanatoryVariables="logsize",#
                               responseType=responseType,regType="constantVar")#
    m1a <- makeGrowthObjGeneral(dataf,explanatoryVariables="logsize+size",#
                               responseType=responseType,regType="constantVar")#
    m2a <- makeGrowthObjGeneral(dataf,explanatoryVariables="logsize+size+size2",#
                               responseType=responseType,regType="constantVar")#
#
    print(anova(m@fit,m0@fit,test="Chi"))#
    print(anova(m0@fit,m1@fit,test="Chi"))#
    print(anova(m1@fit,m2@fit,test="Chi"))#
#
    print(anova(m@fit,m0a@fit,test="Chi"))#
    print(anova(m0a@fit,m1a@fit,test="Chi"))#
    print(anova(m1a@fit,m2a@fit,test="Chi"))#
#
#
    if (plot){#
        scalar <- 100; minsc <- 1e-9#
        sizes <- seq(min(dataf$size,na.rm=TRUE), max(dataf$size,na.rm=TRUE),length=500)#
        chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
        newd<-data.frame(size=sizes,size2=sizes^2,size3=sizes^3,logsize=log(sizes))#
        if (responseType=="sizenext")#
            plot(dff$size,dff$sizenext, pch=19,col="grey", xlab="Size at t", ylab="Size at t+delta")#
        if (responseType=="incr")#
            plot(dff$size,dff$incr, pch=19,col="grey", xlab="Size at t", ylab="Incr at t+delta")#
        if (responseType=="logincr")#
            plot(dff$size,dff$logincr, pch=19,col="grey", xlab="Size at t", ylab="Incr at t+delta")#
        if (responseType!="sizenext")points(sizes,predict(m@fit,newdata=newd),type="l",col=4, lty=2)#
        points(sizes,predict(m0@fit,newdata=newd),type="l",col=1, lty=2)#
        points(sizes,predict(m1@fit,newdata=newd),type="l",col=2, lty=2)#
        points(sizes,predict(m2@fit,newdata=newd),type="l",col=3, lty=2)#
        #points(sizes,predict(m0a@fit,newdata=newd),type="l",col=1, lty=3)#
        #points(sizes,predict(m1a@fit,newdata=newd),type="l",col=2, lty=3)#
        #points(sizes,predict(m2a@fit,newdata=newd),type="l",col=3, lty=3)#
        #
        for (k in 1:length(chs)) {#
            resp <- growth(sizes[chs[k]],sizes,1,m)*scalar; #resp[resp<minsc] <- NA   #
            if (responseType!="sizenext")#
                points(sizes[chs[k]]+resp,sizes, type="l", col=4, lty=2)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,m0)*scalar; #resp[resp<minsc] <- NA#
            #print(sizes[chs[k]]+resp)#
            points(sizes[chs[k]]+resp,sizes, type="l", col=1, lty=2)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,m1)*scalar; #resp[resp<minsc] <- NA   #
            points(sizes[chs[k]]+resp,sizes, type="l", col=2, lty=2)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,m2)*scalar; resp[resp<minsc] <- NA   #
            points(sizes[chs[k]]+resp,sizes, type="l", col=3, lty=2)                                       #
            #resp <- growth(sizes[chs[k]],sizes,1,m0a)*scalar; resp[resp<minsc] <- NA   #
            #points(sizes[chs[k]]+resp,sizes, type="l", col=1, lty=3)                                       #
            #resp <- growth(sizes[chs[k]],sizes,1,m1a)*scalar; resp[resp<minsc] <- NA   #
            #points(sizes[chs[k]]+resp,sizes, type="l", col=2, lty=3)                                       #
            #resp <- growth(sizes[chs[k]],sizes,1,m2a)*scalar; resp[resp<minsc] <- NA   #
            #points(sizes[chs[k]]+resp,sizes, type="l", col=3, lty=3)                                       #
        }#
          #
    }#
#
    return(list(m=m,m0=m0,m1=m1,m2=m2,m0a=m0a,m1a=m1a,m2a=m2a))#
}#
#
#
####################################################################################################
##
##
## Make Figure 1- showning basic qualities of the data ####
## for three species with sufficient mortality info ######
##
FigureOne <- function(){#
#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
#
    #
    # 1. create exact times figure#
    par(mfrow=c(1,3),bty="l")#
    brks <- c(-0.5,1.5,2.5,3.5,4.5,5.5)#
    #
    for (k in 1:length(sp.list)) {#
        a1<-hist(c(dff$exactDatel[dff$spcode==sp.list[k]]-dff$exactDate[dff$spcode==sp.list[k]])/365,#
        breaks=brks, plot=FALSE)#
        if (k==1) cts <- a1$counts#
        if (k>1) cts <- rbind(cts,a1$counts)#
    #
    }#
#
    barplot(cts,beside=TRUE, names.arg=c("<1","2","3","4","5"), xlab="Census interval (years)")#
    legend("topleft",legend=sp.names,col=gray.colors(length(sp.list)), pch=15, bty="n")#
#
    # 2. Create survival figure#
    sp.num <- rep(1,length(dff$spcode));#
    for (k in 2:length(sp.list)) sp.num[dff$spcode==sp.list[k]] <- k#
    surv.sp <- dff$surv + 10*sp.num#
    boxplot(dff$size~surv.sp,log="y",axes="FALSE", xlab="Survival status",#
            ylab="DBH (cm)", col=rep(gray.colors(length(sp.list)), each=2))#
    axis(2)#
    axis(1,at=1:6,lab=c(0,1,0,1,0,1))#
    legend("topright",legend=sp.names,col=gray.colors(length(sp.list)), pch=15, bty="n")#
#
    #
    # 3. Create corrected growth increment figure#
    incr.corrected <- dff$incr/((dff$exactDatel-dff$exactDate)/365)#
    boxplot(incr.corrected~sp.num, col=gray.colors(length(sp.list)),axes=FALSE,#
            ylab="Time adjusted increment (cm)", ylim=c(-1.5,5))#
    abline(h=0,lty=3)#
    legend("topright",legend=sp.names,col=gray.colors(length(sp.list)), pch=15, bty="n")#
    axis(2)#
    axis(1,at=1:3,lab=sp.names)#
    #
    #
    #
#
}#
#
#
#
#
## Make Figure 2 - various survival models#
##
##
FigureTwo <- function(){#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
#
    par(mfrow=c(1,3),bty="l",family = "Helvetica")#
    #
    res1 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE)#
    title(sp.names[1])#
    res2 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    title(sp.names[2])#
    res3 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    title(sp.names[3])#
#
#
}#
#
#
## Make Figure 3 - various growth models with data, and then predicted size, sizenext and densty functions#
##
#  NOTE - that this should be using the ADJUSTED increment, hence over-written below by difference sizenext-size#
#  which was obtained via the spline#
##
FigureThree <- function(){#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
    dff$incr <- dff$sizenext - dff$size#
    #
    #pic with the data - get all the estimates#
    par(mfrow=c(3,5),bty="l", pty="m")#
    res1 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE, plot.title=TRUE)#
    mtext(sp.names[1])#
    res2 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    mtext(sp.names[2])#
    res3 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    mtext(sp.names[3])#
#
    #pic size, size next with density functions on#
    par(mfrow=c(1,3),bty="l")#
    sizes <- seq(min(dff$size,na.rm=TRUE), max(dff$size,na.rm=TRUE),length=500)#
    chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
    scalar <- 100; minsc <- 0.0001#
   #
    for (j in 1:length(sp.list)) { #
        plot(dff$size[dff$spcode==sp.list[j]],dff$sizenext[dff$spcode==sp.list[j]], pch=19,col="grey", xlab="Size at t", ylab="Size at t+delta")#
        mtext(sp.names[j])#
#
        sizes <- seq(min(dff$size[dff$spcode==sp.list[j]],na.rm=TRUE),#
                       max(dff$size[dff$spcode==sp.list[j]],na.rm=TRUE),length=500)#
        chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
  #
        for (k in 1:length(chs)) {#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m1)*scalar; resp[resp<minsc] <- NA   #Power Law#
            points(sizes[chs[k]]+resp,sizes, type="l", col=1)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,res1$m2)*scalar; resp[resp<minsc] <- NA   #Monomolecular#
            points(sizes[chs[k]]+resp,sizes, type="l", col=2)#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m3)*scalar; resp[resp<minsc] <- NA   #Gompertz#
            points(sizes[chs[k]]+resp,sizes, type="l", col=3)                                #
            resp <- growth(sizes[chs[k]],sizes,1,res1$m4)*scalar; resp[resp<minsc] <- NA   #Logistic 3#
            points(sizes[chs[k]]+resp,sizes, type="l", col=4)#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m5)*scalar; resp[resp<minsc] <- NA   #Logistic 4#
            points(sizes[chs[k]]+resp,sizes, type="l", col=5)#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m6)*scalar; resp[resp<minsc] <- NA   #Hossfeld#
            points(sizes[chs[k]]+resp,sizes, type="l", col=6)#
            #
        }#
        if (j==1) legend("topleft", legend=c("Power Law", "Monomolecular",#
                                    "Gompertz", "Logistic 3 par", "Logistic 4 par", "Hossfeld"),#
            lty=1, col=1:6, bty="n", cex=0.8)#
        abline(0,1,lty=3)#
        #
    }#
#
    #pic just of increments#
    chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
    par(mfrow=c(3,1), bty="l",pty="m")#
    scalar <- 1#
    for (j in 1:3) { #
        plot(sizes, sizes, ylim=c(0,0.35),#
             type="n", xlab="Size", ylab="Density in next time-step", xlim=range(sizes[c(chs+10,chs-10)]))#
        for (k in 1:length(chs)) {#
#
            if (j==1) res <- res1#
            if (j==2) res <- res2#
            if (j==3) res <- res3            #
                                        #Power Law#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m1)*scalar, type="l", col=1)#
                                        #Monomolecular#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m2)*scalar, type="l", col=2)#
                                        #Gompertz#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m3)*scalar, type="l", col=3)#
                                        #Logistic 3#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m4)*scalar, type="l", col=4)#
                                        #Logistic 4#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m5)*scalar, type="l", col=5)#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m6)*scalar, type="l", col=6)#
            #
        }#
        if (j==1) legend(110,0.35,#
            legend=c("Power Law", "Monomolecular","Gompertz", "Logistic 3 par", "Logistic 4 par","Hossfeld"),#
            lty=1, col=1:6, bty="n", cex=0.8)#
        mtext(sp.names[j])#
        abline(v=sizes[chs], lty=3)#
        #
    }#
    #
    return(list(res1=res1,res2=res2,res3=res3))#
}#
#
#
#
Figure4 <- function(){#
#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    #get data#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
    dff$incr <- dff$sizenext - dff$size#
    #
    #pic with the data for growth - get all the estimates#
    par(mfrow=c(3,5),bty="l", pty="m")#
    grow.res1 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE, plot.title=TRUE)#
    mtext(sp.names[1])#
    grow.res2 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    mtext(sp.names[2])#
    grow.res3 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    mtext(sp.names[3])#
#
    #same for survival#
    surv.res1 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE)#
    title(sp.names[1])#
    surv.res2 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    title(sp.names[2])#
    surv.res3 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    title(sp.names[3])#
#
#
    #picture    #
    par(mfrow=c(2,2),bty="l")#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[1],],log="y",#
                           growthObjList=grow.res1[1:5],#
                           survObjList=list(surv.res1$m0$sv1), nBigMatrix=300,chosen.size=1500,#
                           do.legend=TRUE)#
    mtext(sp.list[1],side=3)#
#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[1],],log="y",#
                           growthObjList=grow.res1[1:5],#
                           survObjList=list(surv.res1$m1$sv1), nBigMatrix=300,chosen.size=1500)#
#
#
    par(mfrow=c(2,2),bty="l")#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[2],],log="y",#
                           growthObjList=grow.res2[1:5],#
                           survObjList=list(surv.res2$m0$sv1), nBigMatrix=300,chosen.size=1500,#
                           do.legend=TRUE)#
    mtext(sp.list[2],side=3)#
#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[2],],log="y",#
                           growthObjList=grow.res2[1:5],#
                           survObjList=list(surv.res2$m1$sv1), nBigMatrix=300,chosen.size=1500)#
#
    par(mfrow=c(2,2),bty="l")#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[3],],log="y",#
                           growthObjList=grow.res3[1:5],#
                           survObjList=list(surv.res3$m0$sv1), nBigMatrix=300,chosen.size=1500,#
                           do.legend=TRUE)#
    mtext(sp.list[3],side=3)#
#
#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[3],],log="y",#
                           growthObjList=grow.res3[1:5],#
                           survObjList=list(surv.res3$m1$sv1), nBigMatrix=300,chosen.size=1500)#
#
    #
}
a1<-survModelCompVaryInterval(dff,expVars="size+size2")
a1<-survModelCompVaryInterval(dff)
grep("size2","size+size2")
grep("size2","size+size")
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
            print(parStart)#
            #
            #make sure you have all the right covariates#
            if(length(grep("size2",expVars[v]))==1)#
			dataf$size2=(dataf$size)^2#
            if(length(grep("size3",expVars[v]))==1)#
			dataf$size3=(dataf$size)^3#
            if(length(grep("logsize",expVars[v]))==1)#
			dataf$logsize=log(dataf$size)#
            if(length(grep("logsize2",expVars[v]))==1)#
			dataf$logsize=(log(dataf$size))^2#
	#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
grep("size2","size+size")
a1<-survModelCompVaryInterval(dff)
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
            print(parStart)#
            #
            #make sure you have all the right covariates#
            if(length(grep("size2",expVars[v]))==1)#
			dataf$size2=(dataf$size)^2#
            if(length(grep("size3",expVars[v]))==1)#
			dataf$size3=(dataf$size)^3#
            if(length(grep("logsize",expVars[v]))==1)#
			dataf$logsize=log(dataf$size)#
            if(length(grep("logsize2",expVars[v]))==1)#
			dataf$logsize=(log(dataf$size))^2#
#
            print(head(dataf))#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
            print(parStart)#
            #
            #make sure you have all the right covariates#
            if(length(grep("size2",expVars[v]))==1)#
			dataf$size2=(dataf$size)^2#
            if(length(grep("size3",expVars[v]))==1)#
			dataf$size3=(dataf$size)^3#
            if(length(grep("logsize",expVars[v]))==1)#
			dataf$logsize=log(dataf$size)#
            if(length(grep("logsize2",expVars[v]))==1)#
			dataf$logsize=(log(dataf$size))^2#
#
            print(covNames)#
            print(head(dataf))#
            print(head(dataf[,"covNames"]))#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
            print(parStart)#
            #
            #make sure you have all the right covariates#
            if(length(grep("size2",expVars[v]))==1)#
			dataf$size2=(dataf$size)^2#
            if(length(grep("size3",expVars[v]))==1)#
			dataf$size3=(dataf$size)^3#
            if(length(grep("logsize",expVars[v]))==1)#
			dataf$logsize=log(dataf$size)#
            if(length(grep("logsize2",expVars[v]))==1)#
			dataf$logsize=(log(dataf$size))^2#
#
            print(covNames)#
            print(head(dataf))#
            if (length(covNames)>0) print(head(dataf[,"covNames"]))#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
#
## Function to pull in all the data taken from#
## http://esapubs.org/archive/ecol/E092/115/default.htm#data#
## Ecological Archives, E092-115-D1.#
## and organize it into a format recognized by IPMpack#
##
# parameters - filename - file describing location of the data#
#            - species - chosen species (four letter code, e.g., "vain", "myda", or "hubr") or "all"#
##
# returns - a data-frame with headings size, sizenext (adjusted for time interval),#
#                incr (raw increment), surv (survival), spcode,#
#              and exactDate and exactDatel in days#
##
getData <- function(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                    species="all"){#
#
    #bring in the data#
    df <- read.delim(paste(filename,"WesternGhatTrees.txt", sep=""),header=TRUE)#
    if (species!="all") df <- df[df$SpCode==species,]#
#
    #
    #get matrix of dates, sizes, survival #
    dates.raw <- cbind(df$Date0,df$Date1,df$Date2, df$Date3, df$Date4, df$Date5)  #
    sizes.raw <- cbind(df$GBH0,df$GBH1,df$GBH2,df$GBH3,df$GBH4,df$GBH5)#
    surv.raw <- cbind(convertStatus(df$Status0),convertStatus(df$Status1),convertStatus(df$Status2),#
                   convertStatus(df$Status3),convertStatus(df$Status4),convertStatus(df$Status5))#
#
    #get the raw increment for fitting detailed survival model#
    incr <- cbind(df$GBH1-df$GBH0,df$GBH2-df$GBH1,df$GBH3-df$GBH2,df$GBH4-df$GBH3,df$GBH5-df$GBH4)#
    #
    #loop over, predict sizes at days closest to 365*4 (bi-yearly intrvals)#
    pred.dates <- (365*4)*c(0:5)#
    predict.sizes <- matrix(NA,length(df[,1]),length(pred.dates))#
    predict.surv <- matrix(1,length(df[,1]),length(pred.dates))#
        #
    for (k in 1:length(df[,1])) {#
        x <- as.numeric(dates.raw[k,])#
        y <- sizes.raw[k,]#
#
        bad <- is.na(x) | is.na(y)#
        x <- x[!bad]#
        y <- y[!bad]#
     #
        #linear regression#
        if (length(x)<4) { #
            fit <- lm(y~x)#
            predict.sizes[k,] <- predict(fit,newdata=data.frame(x=pred.dates)) #linear reg#
        } else { #
        #smooth spline#
            fit <- smooth.spline(y~x)#
            predict.sizes[k,] <- predict(fit,x=pred.dates)$y #smooth spline#
        }#
            #
        bad <- which(pred.dates>max(x,na.rm=TRUE), arr.ind=TRUE)#
        if (length(bad)>0) predict.sizes[k,bad] <- NA#
        #
        dead <- dates.raw[k,surv.raw[k,]==0][1]#
        loc.dead <- which((dead-pred.dates)^2==min((dead-pred.dates)^2), arr.ind=TRUE)#
        if (length(loc.dead)>0) predict.surv[k,loc.dead:length(pred.dates)] <- 0              #
    }#
#
    #reassure yourself it might work#
#    matplot(t(dates.raw),t(sizes.raw), type="b", pch=19,xlab="dates", ylab="sizes")#
#    abline(v=pred.dates)#
#
        #
    dataf <- data.frame(size=c(predict.sizes[,1:5]),sizeNext=c(predict.sizes[,2:6]),#
                        incr=c(incr[,1:5]),#
                        surv=c(predict.surv[,2:6]), spcode=rep(df$SpCode, 5),#
                        exactDate=c(dates.raw[,1:5]), exactDatel=c(dates.raw[,2:6]))#
#
    dataf <- dataf[!is.na(dataf$size),]#
    #
    return(dataf)#
#
}
dff<-getData()
a1<-survModelCompVaryInterval(dff)
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    #require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- strsplit(as.character(expVars[v]),"[\\+]")[[1]]#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
            print(parStart)#
            #
            #make sure you have all the right covariates#
            if(length(grep("size2",expVars[v]))==1)#
			dataf$size2=(dataf$size)^2#
            if(length(grep("size3",expVars[v]))==1)#
			dataf$size3=(dataf$size)^3#
            if(length(grep("logsize",expVars[v]))==1)#
			dataf$logsize=log(dataf$size)#
            if(length(grep("logsize2",expVars[v]))==1)#
			dataf$logsize=(log(dataf$size))^2#
#
            print(covNames)#
            print(head(dataf))#
            if (length(covNames)>0) print(head(dataf[,covNames]))#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
head(dff)
dff[,"size"]
dff[1:5,"size"]
a1<-survModelCompVaryInterval(dff)
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- str_trim(strsplit(as.character(expVars[v]),"[\\+]")[[1]])#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
            print(parStart)#
            #
            #make sure you have all the right covariates#
            if(length(grep("size2",expVars[v]))==1)#
			dataf$size2=(dataf$size)^2#
            if(length(grep("size3",expVars[v]))==1)#
			dataf$size3=(dataf$size)^3#
            if(length(grep("logsize",expVars[v]))==1)#
			dataf$logsize=log(dataf$size)#
            if(length(grep("logsize2",expVars[v]))==1)#
			dataf$logsize=(log(dataf$size))^2#
#
            print(covNames)#
            print(head(dataf))#
            if (length(covNames)>0) print(head(dataf[,covNames]))#
            #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}
a1<-survModelCompVaryInterval(dff)
#
likeSurvVaryingTimeIntervals <- function(par=c(0.01,0.01,0.01,0.01),#
                                         covNames=c("size","size2","size3"),#
                                         nyrs=5,#
                                         dataf) {#
#
    #
    #define time change#
    tdiff <- (dataf$exactDatel-dataf$exactDate)/(nyrs*365)#
    #print(range(tdiff, na.rm=TRUE))#
#
    #print(covNames)#
    #print(head(dataf[,covNames]))#
    #
    #build predictor#
    if (length(covNames)>0) {#
        pred <-  t(t(dataf[,covNames])*par[2:length(par)])#
    }else { pred <- matrix(0,nrow(dataf),1)}#
    pred <- par[1] + rowSums(pred)#
    pred[pred>200] <- 200  #don't want bigger than exp(200) - gets infinite really quick#
    pred <- (exp(pred)/(1+exp(pred)))^(tdiff)#
#
    print(range(pred))#
    #
    #estimate likelihood#
    like <- dbinom(dataf$surv,1,pred, log=TRUE)#
    #like[like==-Inf] <- -exp(500)#
    #like[like==Inf] <- exp(500)#
#
    sumRows <- rep(0,nrow(dataf))#
    if (length(covNames)>1) sumRows <- rowSums(dataf[,covNames])#
    if (length(covNames)==1) sumRows <- dataf[,covNames]#
    #
    return(-sum(like[!is.na(sumRows) & !is.na(dataf$surv)],na.rm=TRUE))#
    #
}
a1<-survModelCompVaryInterval(dff)
#
#
##### FUNCTIONS USED IN ANALYZING DATA FROM: http://esapubs.org/archive/ecol/E092/115/default.htm#data #
#
#
#setwd("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/")#
#source("R/IPMpack-Util.R")#
#source("R/IPMpack-Base.R")#
#source("R/IPMpack-Impl.R")#
#
#
## Function to alter vector from status description to#
# 0s and 1s for survival#
##
# Parameters - character vector#
##
# Returns - numeric vector#
##
convertStatus <- function(x) {#
    y <- rep(NA,length(x))#
    y[x=="A"] <- 1#
    y[x=="D"] <- 0#
    y[x=="P"] <- 1 #this is a future tree, usually no size - prob alive, but these are not evenly sampled#
#
    return(y)#
}#
#
#
## Function to sort out names, create codes, etc for India data#
##  - dumped out now, so don't need to re-run! - #
###
getSp <- function(filename="data/"){#
#
    #write out species names - takes by hand editing so only do once#
    det <-  read.delim(paste(filename,"SpeciesDetails.txt", sep=""),header=TRUE)#
    genus.end <-  regexpr(" ", det[,2]);#
    mat <- cbind(as.character(det$Family), substr(det$LatinName,1,genus.end),#
                 as.character(det$LatinName))#
    write.table(paste(mat[,1],"/",mat[,2],"/",mat[,3], sep=""),#
                file="names.sp",row.names=FALSE, quote = FALSE)#
    #remember, make lower case, put _ between genus and species name, remove " /" for use with phylomatic#
    #
    #
#
}#
#
#
## Function to pull in all the data taken from#
## http://esapubs.org/archive/ecol/E092/115/default.htm#data#
## Ecological Archives, E092-115-D1.#
## and organize it into a format recognized by IPMpack#
##
# parameters - filename - file describing location of the data#
#            - species - chosen species (four letter code, e.g., "vain", "myda", or "hubr") or "all"#
##
# returns - a data-frame with headings size, sizenext (adjusted for time interval),#
#                incr (raw increment), surv (survival), spcode,#
#              and exactDate and exactDatel in days#
##
getData <- function(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                    species="all"){#
#
    #bring in the data#
    df <- read.delim(paste(filename,"WesternGhatTrees.txt", sep=""),header=TRUE)#
    if (species!="all") df <- df[df$SpCode==species,]#
#
    #
    #get matrix of dates, sizes, survival #
    dates.raw <- cbind(df$Date0,df$Date1,df$Date2, df$Date3, df$Date4, df$Date5)  #
    sizes.raw <- cbind(df$GBH0,df$GBH1,df$GBH2,df$GBH3,df$GBH4,df$GBH5)#
    surv.raw <- cbind(convertStatus(df$Status0),convertStatus(df$Status1),convertStatus(df$Status2),#
                   convertStatus(df$Status3),convertStatus(df$Status4),convertStatus(df$Status5))#
#
    #get the raw increment for fitting detailed survival model#
    incr <- cbind(df$GBH1-df$GBH0,df$GBH2-df$GBH1,df$GBH3-df$GBH2,df$GBH4-df$GBH3,df$GBH5-df$GBH4)#
    #
    #loop over, predict sizes at days closest to 365*4 (bi-yearly intrvals)#
    pred.dates <- (365*4)*c(0:5)#
    predict.sizes <- matrix(NA,length(df[,1]),length(pred.dates))#
    predict.surv <- matrix(1,length(df[,1]),length(pred.dates))#
        #
    for (k in 1:length(df[,1])) {#
        x <- as.numeric(dates.raw[k,])#
        y <- sizes.raw[k,]#
#
        bad <- is.na(x) | is.na(y)#
        x <- x[!bad]#
        y <- y[!bad]#
     #
        #linear regression#
        if (length(x)<4) { #
            fit <- lm(y~x)#
            predict.sizes[k,] <- predict(fit,newdata=data.frame(x=pred.dates)) #linear reg#
        } else { #
        #smooth spline#
            fit <- smooth.spline(y~x)#
            predict.sizes[k,] <- predict(fit,x=pred.dates)$y #smooth spline#
        }#
            #
        bad <- which(pred.dates>max(x,na.rm=TRUE), arr.ind=TRUE)#
        if (length(bad)>0) predict.sizes[k,bad] <- NA#
        #
        dead <- dates.raw[k,surv.raw[k,]==0][1]#
        loc.dead <- which((dead-pred.dates)^2==min((dead-pred.dates)^2), arr.ind=TRUE)#
        if (length(loc.dead)>0) predict.surv[k,loc.dead:length(pred.dates)] <- 0              #
    }#
#
    #reassure yourself it might work#
#    matplot(t(dates.raw),t(sizes.raw), type="b", pch=19,xlab="dates", ylab="sizes")#
#    abline(v=pred.dates)#
#
        #
    dataf <- data.frame(size=c(predict.sizes[,1:5]),sizeNext=c(predict.sizes[,2:6]),#
                        incr=c(incr[,1:5]),#
                        surv=c(predict.surv[,2:6]), spcode=rep(df$SpCode, 5),#
                        exactDate=c(dates.raw[,1:5]), exactDatel=c(dates.raw[,2:6]))#
#
    dataf <- dataf[!is.na(dataf$size),]#
    #
    return(dataf)#
#
}#
#
#
#
#
#
#
## Function to fit survival with varying time increments and then write parameters#
## over onto a classic glm framework. #
##
# parameters - dataf - a dataframe including columns#
#                  size, surv, exactDate, and exactDatel, the latter two in days#
#            - nyrs - desired number of years in a time-step#
#            - par - starting values for the parameters#
#                     (must be of length one longer than covNames,#
#                       given intercept)#
#            - covNames - names of chosen covariates#
#            - method - method for optim ("Nelder-Mead", "SANN", etc.)#
##
# Returns  - output of optim#
##
fitSurvVaryingTimeIntervals <- function(dataf,#
                                        nyrs=5,#
                                        par=c(0.01,0.01,0.01,0.01),#
                                        covNames=c("size","size2","size3"),#
                                        method="Nelder-Mead") {#
#
    #warnings#
    if ((length(par)-1)!=length(covNames)) {#
        print("starting values does not match length of covariate names")#
    }#
#
    #
    tmp <- optim(par,likeSurvVaryingTimeIntervals,#
                 covNames=covNames,nyrs=nyrs,dataf=dataf,#
                 method=method)#
#
    #
    if (tmp$convergence!=0) {#
        tmp <- optim(tmp$par,likeSurvVaryingTimeIntervals,#
                     covNames=covNames,nyrs=nyrs,dataf=dataf,#
                     method=method)#
        if (tmp$convergence!=0)  print("not converged")        #
    }#
    #
    #write template over the top#
    if (length(covNames)>0) formula <- as.character(paste("surv~",paste(covNames,collapse="+"),collapse="")) else formula <- as.character("surv~1")#
    fit <- glm(formula,data=dataf,family=binomial)#
    #print(fit)#
    fit$coefficients <- tmp$par#
#
    sv1 <- new("survObj")#
    sv1@fit <- fit#
#
    tmp$sv1 <- sv1#
    #
    return(tmp)#
#
}#
#
#Function to calculate the likelihood for variable time-intervals for survival #
##
# parameters #
#            - par - starting values for the parameters#
#                     (must be of length one longer than covNames,#
#                       given intercept)#
#            - covNames - names of chosen covariates#
#            - nyrs - desired number of years in a time-step#
#            - dataf - a dataframe including columns in covNames, as well as#
#                  size, surv, exactDate, and exactDatel, the latter two in days#
##
# Returns  - numeric equal to minus the log likelihood#
##
likeSurvVaryingTimeIntervals <- function(par=c(0.01,0.01,0.01,0.01),#
                                         covNames=c("size","size2","size3"),#
                                         nyrs=5,#
                                         dataf) {#
#
    #
    #define time change#
    tdiff <- (dataf$exactDatel-dataf$exactDate)/(nyrs*365)#
    #print(range(tdiff, na.rm=TRUE))#
#
    #print(covNames)#
    #print(head(dataf[,covNames]))#
    #
    #build predictor#
    if (length(covNames)>0) {#
        pred <-  t(t(dataf[,covNames])*par[2:length(par)])#
    }else { pred <- matrix(0,nrow(dataf),1)}#
    pred <- par[1] + rowSums(pred)#
    pred[pred>200] <- 200  #don't want bigger than exp(200) - gets infinite really quick#
    pred <- (exp(pred)/(1+exp(pred)))^(tdiff)#
#
    print(range(pred))#
    #
    #estimate likelihood#
    like <- dbinom(dataf$surv,1,pred, log=TRUE)#
    #like[like==-Inf] <- -exp(500)#
    #like[like==Inf] <- exp(500)#
#
    sumRows <- rep(0,nrow(dataf))#
    if (length(covNames)>1) sumRows <- rowSums(dataf[,covNames])#
    if (length(covNames)==1) sumRows <- dataf[,covNames]#
    #
    return(-sum(like[!is.na(sumRows) & !is.na(dataf$surv)],na.rm=TRUE))#
    #
}#
#
#
##note that there are very few species for which sufficient#
## mortality data is actually available! most just don't die...#
##
# vain, myda, hubr#
##
##
compareTmatrices <- function(dataf, growthObjList,survObjList, nBigMatrix=300,chosen.size=1500,#
                             do.plot=TRUE,do.legend=FALSE,...){ #
    #
    #STORAGE#
    LE <- LE1 <- ptime <- ptime1 <- array(dim=c(length(survObjList),length(growthObjList),nBigMatrix))#
      #
    ## LOOP OVER all possible combos#
    for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
             #
                sv1 <- survObjList[[j]]#
                gr1 <- growthObjList[[k]]#
                              #
                #BUILD Tmatrix#
                Tmatrix <- create.IPM.Tmatrix(nBigMatrix = nBigMatrix,#
                                              minSize = 0.9*min(dataf$size,na.rm=TRUE),#
                                              maxSize = 1.1*max(dataf$size,na.rm=TRUE),#
                                              growObj = gr1, survObj = sv1, correction="constant")#
                Tmatrix1 <- create.IPM.Tmatrix(nBigMatrix = nBigMatrix,#
                                               minSize = 0.9*min(dataf$size,na.rm=TRUE),#
                                               maxSize = 1.1*max(dataf$size,na.rm=TRUE),#
                                               growObj = gr1, survObj = sv1,integrate.type="cumul",#
                                               correction="constant")#
        #
                # Get the mean life expect from every size value in IPM#
                LE[j,k,] <- MeanLifeExpect(Tmatrix)#
                ptime[j,k,] <- PassageTime(chosen.size=chosen.size,Tmatrix); #print(ptime)#
                LE1[j,k,] <- MeanLifeExpect(Tmatrix1)#
                ptime1[j,k,] <- PassageTime(chosen.size=chosen.size,Tmatrix1); #print(ptime)#
#
    #
            }}#
#
    ## PLOT#
    if (do.plot) { #
#
        nyr <- 4#
        j<-k<-1#
        plot(Tmatrix@meshpoints,LE[j,k,]*nyr,type="l",xlab="size", ylab="life expectancy",#
             ylim=pmax(range(c(LE*nyr,LE1*nyr),na.rm=TRUE),1),...)#
#
        for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
                points(Tmatrix@meshpoints,LE[j,k,]*nyr,type="l",col=k)#
                points(Tmatrix1@meshpoints,LE1[j,k,]*nyr,type="l",col=k, lty=3)#
#
            }}#
#
        if (do.legend) { legend("bottomleft", legend=c("Power Law", "Monomolecular",#
                                              "Gompertz", "Logistic 3 par", "Logistic 4 par"),#
                                lty=1, col=1:5, bty="n", cex=0.8)}#
                         #
        #
        j<-k<-1#
        plot(Tmatrix@meshpoints,ptime[j,k,]*nyr,type="l",xlab="size", ylab="passage time",#
             ylim=pmax(range(c(ptime*nyr,ptime1*nyr),na.rm=TRUE),1),...)#
        for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
                points(Tmatrix@meshpoints,ptime[j,k,]*nyr,type="l",col=k)#
                points(Tmatrix1@meshpoints,ptime1[j,k,]*nyr,type="l",col=k,lty=3)#
#
            }}#
#
  #
    }#
            #
    #
   return(list(LE=LE,LE1=LE1,ptime=ptime,ptime1=ptime1, sizes=Tmatrix@meshpoints))#
    #
}#
#
#
#
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- str_trim(strsplit(as.character(expVars[v]),"[\\+]")[[1]])#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
            print(parStart)#
            #
            #make sure you have all the right covariates#
            if(length(grep("size2",expVars[v]))==1)#
			dataf$size2=(dataf$size)^2#
            if(length(grep("size3",expVars[v]))==1)#
			dataf$size3=(dataf$size)^3#
            if(length(grep("logsize",expVars[v]))==1)#
			dataf$logsize=log(dataf$size)#
            if(length(grep("logsize2",expVars[v]))==1)#
			dataf$logsize=(log(dataf$size))^2#
#
            print(likeSurvVaryingTimeIntervals(par=parStart,#
                                         covNames=covNames,#
                                         nyrs=4,#
                                         dataf=dataf))#
       #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}#
#
#
#
test <- function(){#
    #do simple to complicated, and use parameters from previous as starting values#
    m <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=0.01,cov.names=c())#
    m0 <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(0.01,0.01),cov.names=c("size"))#
    m1 <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m0$par,0),cov.names=c("size","size2"))#
    m2 <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m1$par,0),cov.names=c("size","size2","size3"))#
    #
    print("Comparison intercept and size")#
    print(1-pchisq(2*(m$value-m0$value),1))#
    print("Comparison size and size2")#
    print(1-pchisq(2*(m0$value-m1$value),1))#
    print("Comparison size2 and size3")#
    print(1-pchisq(2*(m1$value-m2$value),1))#
#
    m0a <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m0$par),cov.names=c("logsize"))#
    m1a <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m0$par,0),cov.names=c("size","logsize"))#
    m2a <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m1a$par,0),cov.names=c("size","logsize","logsize2"))#
#
    print("Comparison intercept and logsize")#
    print(1-pchisq(2*(m$value-m0a$value),1))#
    print("Comparison logsize and size+logsize")#
    print(1-pchisq(2*(m0a$value-m1a$value),1))#
    print("Comparison logsize and logsize2")#
    print(1-pchisq(2*(m1a$value-m2a$value),1))#
#
    print("Direct comparison likelihoods")#
    vals <- -c(m$value,m0$value,m1$value,m2$value,m0a$value,m1a$val,m2a$value) #log likelihood#
    AIC <- 2*c(length(m$par),length(m0$par),length(m1$par),length(m2$par),length(m0a$par),length(m1a$par),length(m2a$par))-2*vals#
    nmes <- c("1","size","size+size2","size+size2+size3","logsize","size+logsize","size+logsize+logsize2")#
    print(cbind(nmes,vals,AIC,order(vals)))#
    #
#
    if (plot) {#
        sizes <- seq(min(dataf$size,na.rm=TRUE), max(dataf$size,na.rm=TRUE),length=100)#
        picSurvData(dataf,ncuts=20)#
        points(sizes,surv(sizes,1,m$sv1),type="l",col=4, lty=2)#
        points(sizes,surv(sizes,1,m0$sv1),type="l",col=1, lty=2)#
        points(sizes,surv(sizes,1,m1$sv1),type="l",col=2, lty=2)#
        points(sizes,surv(sizes,1,m2$sv1),type="l",col=3, lty=2)#
        points(sizes,surv(sizes,1,m0a$sv1),type="l",col=1, lty=3)#
        points(sizes,surv(sizes,1,m1a$sv1),type="l",col=2, lty=3)#
        points(sizes,surv(sizes,1,m2a$sv1),type="l",col=3, lty=3)#
        legend("bottomleft", legend=paste(nmes,paste(", AIC=",round(AIC,1), sep="")), text.col=c(4,1:3,1:3),#
               col=c(4,1:3,1:3),lty=c(2,rep(2,3),rep(3,3)), bty="o", cex=0.8,bg="white",box.col="white")#
     #
    }#
#
    return(list(m=m,m0=m0,m1=m1,m2=m2,m0a=m0a,m1a=m1a,m2a=m2a))#
                 #
}#
#
#
#
#
## Just make a picture of the survival probs from the data#
## [Useful for overlaying various fits...]#
picSurvData <- function(dataf,ncuts=12,...) { #
#
    #organize data and plot mean of ncut successive sizes, so trend more obvious#
    os<-order(dataf$size); os.surv<-(dataf$surv)[os]; os.size<-(dataf$size)[os]; #
    psz<-tapply(os.size,as.numeric(cut(os.size,ncuts)),mean,na.rm=TRUE); #print(psz)#
    ps<-tapply(os.surv,as.numeric(cut(os.size,ncuts)),mean,na.rm=TRUE);#print(ps)#
#
    #plot data#
    plot(as.numeric(psz),as.numeric(ps),pch=19,#
         xlab="Size at t", ylab="Survival to t+1",...)#
    #
}#
#
likeCompareClassicGrowthFits <- function(dataf, plot=FALSE,responseType="sizenext") {#
#
    #Function to create a time-scaled incr or log increment (the incr in the dataf is actually the "true"#
    # over the arbitrary census interval)#
    if (responseType=="incr") dataf$incr <- (dataf$sizenext-dataf$size)#
    if (responseType=="logincr") dataf$logincr <- log(dataf$sizenext-dataf$size)#
    #
    #do simple to complicated, and use parameters from previous as starting values#
    m <- makeGrowthObjGeneral(dataf,explanatoryVariables="1",#
                               responseType=responseType,regType="constantVar")#
    m0 <- makeGrowthObjGeneral(dataf,explanatoryVariables="size",#
                               responseType=responseType,regType="constantVar")#
    m1 <- makeGrowthObjGeneral(dataf,explanatoryVariables="size+size2",#
                               responseType=responseType,regType="constantVar")#
    m2 <- makeGrowthObjGeneral(dataf,explanatoryVariables="size+size2+size3",#
                               responseType=responseType,regType="constantVar")#
    m0a <- makeGrowthObjGeneral(dataf,explanatoryVariables="logsize",#
                               responseType=responseType,regType="constantVar")#
    m1a <- makeGrowthObjGeneral(dataf,explanatoryVariables="logsize+size",#
                               responseType=responseType,regType="constantVar")#
    m2a <- makeGrowthObjGeneral(dataf,explanatoryVariables="logsize+size+size2",#
                               responseType=responseType,regType="constantVar")#
#
    print(anova(m@fit,m0@fit,test="Chi"))#
    print(anova(m0@fit,m1@fit,test="Chi"))#
    print(anova(m1@fit,m2@fit,test="Chi"))#
#
    print(anova(m@fit,m0a@fit,test="Chi"))#
    print(anova(m0a@fit,m1a@fit,test="Chi"))#
    print(anova(m1a@fit,m2a@fit,test="Chi"))#
#
#
    if (plot){#
        scalar <- 100; minsc <- 1e-9#
        sizes <- seq(min(dataf$size,na.rm=TRUE), max(dataf$size,na.rm=TRUE),length=500)#
        chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
        newd<-data.frame(size=sizes,size2=sizes^2,size3=sizes^3,logsize=log(sizes))#
        if (responseType=="sizenext")#
            plot(dff$size,dff$sizenext, pch=19,col="grey", xlab="Size at t", ylab="Size at t+delta")#
        if (responseType=="incr")#
            plot(dff$size,dff$incr, pch=19,col="grey", xlab="Size at t", ylab="Incr at t+delta")#
        if (responseType=="logincr")#
            plot(dff$size,dff$logincr, pch=19,col="grey", xlab="Size at t", ylab="Incr at t+delta")#
        if (responseType!="sizenext")points(sizes,predict(m@fit,newdata=newd),type="l",col=4, lty=2)#
        points(sizes,predict(m0@fit,newdata=newd),type="l",col=1, lty=2)#
        points(sizes,predict(m1@fit,newdata=newd),type="l",col=2, lty=2)#
        points(sizes,predict(m2@fit,newdata=newd),type="l",col=3, lty=2)#
        #points(sizes,predict(m0a@fit,newdata=newd),type="l",col=1, lty=3)#
        #points(sizes,predict(m1a@fit,newdata=newd),type="l",col=2, lty=3)#
        #points(sizes,predict(m2a@fit,newdata=newd),type="l",col=3, lty=3)#
        #
        for (k in 1:length(chs)) {#
            resp <- growth(sizes[chs[k]],sizes,1,m)*scalar; #resp[resp<minsc] <- NA   #
            if (responseType!="sizenext")#
                points(sizes[chs[k]]+resp,sizes, type="l", col=4, lty=2)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,m0)*scalar; #resp[resp<minsc] <- NA#
            #print(sizes[chs[k]]+resp)#
            points(sizes[chs[k]]+resp,sizes, type="l", col=1, lty=2)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,m1)*scalar; #resp[resp<minsc] <- NA   #
            points(sizes[chs[k]]+resp,sizes, type="l", col=2, lty=2)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,m2)*scalar; resp[resp<minsc] <- NA   #
            points(sizes[chs[k]]+resp,sizes, type="l", col=3, lty=2)                                       #
            #resp <- growth(sizes[chs[k]],sizes,1,m0a)*scalar; resp[resp<minsc] <- NA   #
            #points(sizes[chs[k]]+resp,sizes, type="l", col=1, lty=3)                                       #
            #resp <- growth(sizes[chs[k]],sizes,1,m1a)*scalar; resp[resp<minsc] <- NA   #
            #points(sizes[chs[k]]+resp,sizes, type="l", col=2, lty=3)                                       #
            #resp <- growth(sizes[chs[k]],sizes,1,m2a)*scalar; resp[resp<minsc] <- NA   #
            #points(sizes[chs[k]]+resp,sizes, type="l", col=3, lty=3)                                       #
        }#
          #
    }#
#
    return(list(m=m,m0=m0,m1=m1,m2=m2,m0a=m0a,m1a=m1a,m2a=m2a))#
}#
#
#
####################################################################################################
##
##
## Make Figure 1- showning basic qualities of the data ####
## for three species with sufficient mortality info ######
##
FigureOne <- function(){#
#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
#
    #
    # 1. create exact times figure#
    par(mfrow=c(1,3),bty="l")#
    brks <- c(-0.5,1.5,2.5,3.5,4.5,5.5)#
    #
    for (k in 1:length(sp.list)) {#
        a1<-hist(c(dff$exactDatel[dff$spcode==sp.list[k]]-dff$exactDate[dff$spcode==sp.list[k]])/365,#
        breaks=brks, plot=FALSE)#
        if (k==1) cts <- a1$counts#
        if (k>1) cts <- rbind(cts,a1$counts)#
    #
    }#
#
    barplot(cts,beside=TRUE, names.arg=c("<1","2","3","4","5"), xlab="Census interval (years)")#
    legend("topleft",legend=sp.names,col=gray.colors(length(sp.list)), pch=15, bty="n")#
#
    # 2. Create survival figure#
    sp.num <- rep(1,length(dff$spcode));#
    for (k in 2:length(sp.list)) sp.num[dff$spcode==sp.list[k]] <- k#
    surv.sp <- dff$surv + 10*sp.num#
    boxplot(dff$size~surv.sp,log="y",axes="FALSE", xlab="Survival status",#
            ylab="DBH (cm)", col=rep(gray.colors(length(sp.list)), each=2))#
    axis(2)#
    axis(1,at=1:6,lab=c(0,1,0,1,0,1))#
    legend("topright",legend=sp.names,col=gray.colors(length(sp.list)), pch=15, bty="n")#
#
    #
    # 3. Create corrected growth increment figure#
    incr.corrected <- dff$incr/((dff$exactDatel-dff$exactDate)/365)#
    boxplot(incr.corrected~sp.num, col=gray.colors(length(sp.list)),axes=FALSE,#
            ylab="Time adjusted increment (cm)", ylim=c(-1.5,5))#
    abline(h=0,lty=3)#
    legend("topright",legend=sp.names,col=gray.colors(length(sp.list)), pch=15, bty="n")#
    axis(2)#
    axis(1,at=1:3,lab=sp.names)#
    #
    #
    #
#
}#
#
#
#
#
## Make Figure 2 - various survival models#
##
##
FigureTwo <- function(){#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
#
    par(mfrow=c(1,3),bty="l",family = "Helvetica")#
    #
    res1 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE)#
    title(sp.names[1])#
    res2 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    title(sp.names[2])#
    res3 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    title(sp.names[3])#
#
#
}#
#
#
## Make Figure 3 - various growth models with data, and then predicted size, sizenext and densty functions#
##
#  NOTE - that this should be using the ADJUSTED increment, hence over-written below by difference sizenext-size#
#  which was obtained via the spline#
##
FigureThree <- function(){#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
    dff$incr <- dff$sizenext - dff$size#
    #
    #pic with the data - get all the estimates#
    par(mfrow=c(3,5),bty="l", pty="m")#
    res1 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE, plot.title=TRUE)#
    mtext(sp.names[1])#
    res2 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    mtext(sp.names[2])#
    res3 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    mtext(sp.names[3])#
#
    #pic size, size next with density functions on#
    par(mfrow=c(1,3),bty="l")#
    sizes <- seq(min(dff$size,na.rm=TRUE), max(dff$size,na.rm=TRUE),length=500)#
    chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
    scalar <- 100; minsc <- 0.0001#
   #
    for (j in 1:length(sp.list)) { #
        plot(dff$size[dff$spcode==sp.list[j]],dff$sizenext[dff$spcode==sp.list[j]], pch=19,col="grey", xlab="Size at t", ylab="Size at t+delta")#
        mtext(sp.names[j])#
#
        sizes <- seq(min(dff$size[dff$spcode==sp.list[j]],na.rm=TRUE),#
                       max(dff$size[dff$spcode==sp.list[j]],na.rm=TRUE),length=500)#
        chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
  #
        for (k in 1:length(chs)) {#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m1)*scalar; resp[resp<minsc] <- NA   #Power Law#
            points(sizes[chs[k]]+resp,sizes, type="l", col=1)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,res1$m2)*scalar; resp[resp<minsc] <- NA   #Monomolecular#
            points(sizes[chs[k]]+resp,sizes, type="l", col=2)#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m3)*scalar; resp[resp<minsc] <- NA   #Gompertz#
            points(sizes[chs[k]]+resp,sizes, type="l", col=3)                                #
            resp <- growth(sizes[chs[k]],sizes,1,res1$m4)*scalar; resp[resp<minsc] <- NA   #Logistic 3#
            points(sizes[chs[k]]+resp,sizes, type="l", col=4)#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m5)*scalar; resp[resp<minsc] <- NA   #Logistic 4#
            points(sizes[chs[k]]+resp,sizes, type="l", col=5)#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m6)*scalar; resp[resp<minsc] <- NA   #Hossfeld#
            points(sizes[chs[k]]+resp,sizes, type="l", col=6)#
            #
        }#
        if (j==1) legend("topleft", legend=c("Power Law", "Monomolecular",#
                                    "Gompertz", "Logistic 3 par", "Logistic 4 par", "Hossfeld"),#
            lty=1, col=1:6, bty="n", cex=0.8)#
        abline(0,1,lty=3)#
        #
    }#
#
    #pic just of increments#
    chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
    par(mfrow=c(3,1), bty="l",pty="m")#
    scalar <- 1#
    for (j in 1:3) { #
        plot(sizes, sizes, ylim=c(0,0.35),#
             type="n", xlab="Size", ylab="Density in next time-step", xlim=range(sizes[c(chs+10,chs-10)]))#
        for (k in 1:length(chs)) {#
#
            if (j==1) res <- res1#
            if (j==2) res <- res2#
            if (j==3) res <- res3            #
                                        #Power Law#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m1)*scalar, type="l", col=1)#
                                        #Monomolecular#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m2)*scalar, type="l", col=2)#
                                        #Gompertz#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m3)*scalar, type="l", col=3)#
                                        #Logistic 3#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m4)*scalar, type="l", col=4)#
                                        #Logistic 4#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m5)*scalar, type="l", col=5)#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m6)*scalar, type="l", col=6)#
            #
        }#
        if (j==1) legend(110,0.35,#
            legend=c("Power Law", "Monomolecular","Gompertz", "Logistic 3 par", "Logistic 4 par","Hossfeld"),#
            lty=1, col=1:6, bty="n", cex=0.8)#
        mtext(sp.names[j])#
        abline(v=sizes[chs], lty=3)#
        #
    }#
    #
    return(list(res1=res1,res2=res2,res3=res3))#
}#
#
#
#
Figure4 <- function(){#
#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    #get data#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
    dff$incr <- dff$sizenext - dff$size#
    #
    #pic with the data for growth - get all the estimates#
    par(mfrow=c(3,5),bty="l", pty="m")#
    grow.res1 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE, plot.title=TRUE)#
    mtext(sp.names[1])#
    grow.res2 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    mtext(sp.names[2])#
    grow.res3 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    mtext(sp.names[3])#
#
    #same for survival#
    surv.res1 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE)#
    title(sp.names[1])#
    surv.res2 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    title(sp.names[2])#
    surv.res3 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    title(sp.names[3])#
#
#
    #picture    #
    par(mfrow=c(2,2),bty="l")#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[1],],log="y",#
                           growthObjList=grow.res1[1:5],#
                           survObjList=list(surv.res1$m0$sv1), nBigMatrix=300,chosen.size=1500,#
                           do.legend=TRUE)#
    mtext(sp.list[1],side=3)#
#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[1],],log="y",#
                           growthObjList=grow.res1[1:5],#
                           survObjList=list(surv.res1$m1$sv1), nBigMatrix=300,chosen.size=1500)#
#
#
    par(mfrow=c(2,2),bty="l")#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[2],],log="y",#
                           growthObjList=grow.res2[1:5],#
                           survObjList=list(surv.res2$m0$sv1), nBigMatrix=300,chosen.size=1500,#
                           do.legend=TRUE)#
    mtext(sp.list[2],side=3)#
#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[2],],log="y",#
                           growthObjList=grow.res2[1:5],#
                           survObjList=list(surv.res2$m1$sv1), nBigMatrix=300,chosen.size=1500)#
#
    par(mfrow=c(2,2),bty="l")#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[3],],log="y",#
                           growthObjList=grow.res3[1:5],#
                           survObjList=list(surv.res3$m0$sv1), nBigMatrix=300,chosen.size=1500,#
                           do.legend=TRUE)#
    mtext(sp.list[3],side=3)#
#
#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[3],],log="y",#
                           growthObjList=grow.res3[1:5],#
                           survObjList=list(surv.res3$m1$sv1), nBigMatrix=300,chosen.size=1500)#
#
    #
}
a1<-survModelCompVaryInterval(dff)
#
likeSurvVaryingTimeIntervals <- function(par=c(0.01,0.01,0.01,0.01),#
                                         covNames=c("size","size2","size3"),#
                                         nyrs=5,#
                                         dataf) {#
#
    #
    #define time change#
    tdiff <- (dataf$exactDatel-dataf$exactDate)/(nyrs*365)#
    #print(range(tdiff, na.rm=TRUE))#
#
    #print(covNames)#
    #print(head(dataf[,covNames]))#
    #
    #build predictor#
    if (length(covNames)>0) {#
        pred <-  t(t(dataf[,covNames])*par[2:length(par)])#
    }else { pred <- matrix(0,nrow(dataf),1)}#
    pred <- par[1] + rowSums(pred)#
    pred[pred>100] <- 100  #don't want bigger than exp(200) - gets infinite really quick#
    pred <- (exp(pred)/(1+exp(pred)))^(tdiff)#
#
    #
    #estimate likelihood#
    like <- dbinom(dataf$surv,1,pred, log=TRUE)#
    #like[like==-Inf] <- -exp(500)#
    #like[like==Inf] <- exp(500)#
#
    sumRows <- rep(0,nrow(dataf))#
    if (length(covNames)>1) sumRows <- rowSums(dataf[,covNames])#
    if (length(covNames)==1) sumRows <- dataf[,covNames]#
    #
    return(-sum(like[!is.na(sumRows) & !is.na(dataf$surv)],na.rm=TRUE))#
    #
}
a1<-survModelCompVaryInterval(dff)
#
likeSurvVaryingTimeIntervals <- function(par=c(0.01,0.01,0.01,0.01),#
                                         covNames=c("size","size2","size3"),#
                                         nyrs=5,#
                                         dataf) {#
#
    #
    #define time change#
    tdiff <- (dataf$exactDatel-dataf$exactDate)/(nyrs*365)#
    #print(range(tdiff, na.rm=TRUE))#
#
    #print(covNames)#
    #print(head(dataf[,covNames]))#
    #
    #build predictor#
    if (length(covNames)>0) {#
        pred <-  t(t(dataf[,covNames])*par[2:length(par)])#
    }else { pred <- matrix(0,nrow(dataf),1)}#
    pred <- par[1] + rowSums(pred)#
    pred[pred>200] <- 200  #don't want bigger than exp(200) - gets infinite really quick#
    pred <- (exp(pred)/(1+exp(pred)))^(tdiff)#
    print(range(pred))#
    #
    #estimate likelihood#
    like <- dbinom(dataf$surv,1,pred, log=TRUE)#
    #like[like==-Inf] <- -exp(500)#
    #like[like==Inf] <- exp(500)#
#
    sumRows <- rep(0,nrow(dataf))#
    if (length(covNames)>1) sumRows <- rowSums(dataf[,covNames])#
    if (length(covNames)==1) sumRows <- dataf[,covNames]#
    #
    return(-sum(like[!is.na(sumRows) & !is.na(dataf$surv)],na.rm=TRUE))#
    #
}
a1<-survModelCompVaryInterval(dff)
#
#
##### FUNCTIONS USED IN ANALYZING DATA FROM: http://esapubs.org/archive/ecol/E092/115/default.htm#data #
#
#
#setwd("/Users/cjessicametcalf/Documents/workspace/IPMpack/pkg/")#
#source("R/IPMpack-Util.R")#
#source("R/IPMpack-Base.R")#
#source("R/IPMpack-Impl.R")#
#
#
## Function to alter vector from status description to#
# 0s and 1s for survival#
##
# Parameters - character vector#
##
# Returns - numeric vector#
##
convertStatus <- function(x) {#
    y <- rep(NA,length(x))#
    y[x=="A"] <- 1#
    y[x=="D"] <- 0#
    y[x=="P"] <- 1 #this is a future tree, usually no size - prob alive, but these are not evenly sampled#
#
    return(y)#
}#
#
#
## Function to sort out names, create codes, etc for India data#
##  - dumped out now, so don't need to re-run! - #
###
getSp <- function(filename="data/"){#
#
    #write out species names - takes by hand editing so only do once#
    det <-  read.delim(paste(filename,"SpeciesDetails.txt", sep=""),header=TRUE)#
    genus.end <-  regexpr(" ", det[,2]);#
    mat <- cbind(as.character(det$Family), substr(det$LatinName,1,genus.end),#
                 as.character(det$LatinName))#
    write.table(paste(mat[,1],"/",mat[,2],"/",mat[,3], sep=""),#
                file="names.sp",row.names=FALSE, quote = FALSE)#
    #remember, make lower case, put _ between genus and species name, remove " /" for use with phylomatic#
    #
    #
#
}#
#
#
## Function to pull in all the data taken from#
## http://esapubs.org/archive/ecol/E092/115/default.htm#data#
## Ecological Archives, E092-115-D1.#
## and organize it into a format recognized by IPMpack#
##
# parameters - filename - file describing location of the data#
#            - species - chosen species (four letter code, e.g., "vain", "myda", or "hubr") or "all"#
##
# returns - a data-frame with headings size, sizenext (adjusted for time interval),#
#                incr (raw increment), surv (survival), spcode,#
#              and exactDate and exactDatel in days#
##
getData <- function(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                    species="all"){#
#
    #bring in the data#
    df <- read.delim(paste(filename,"WesternGhatTrees.txt", sep=""),header=TRUE)#
    if (species!="all") df <- df[df$SpCode==species,]#
#
    #
    #get matrix of dates, sizes, survival #
    dates.raw <- cbind(df$Date0,df$Date1,df$Date2, df$Date3, df$Date4, df$Date5)  #
    sizes.raw <- cbind(df$GBH0,df$GBH1,df$GBH2,df$GBH3,df$GBH4,df$GBH5)#
    surv.raw <- cbind(convertStatus(df$Status0),convertStatus(df$Status1),convertStatus(df$Status2),#
                   convertStatus(df$Status3),convertStatus(df$Status4),convertStatus(df$Status5))#
#
    #get the raw increment for fitting detailed survival model#
    incr <- cbind(df$GBH1-df$GBH0,df$GBH2-df$GBH1,df$GBH3-df$GBH2,df$GBH4-df$GBH3,df$GBH5-df$GBH4)#
    #
    #loop over, predict sizes at days closest to 365*4 (bi-yearly intrvals)#
    pred.dates <- (365*4)*c(0:5)#
    predict.sizes <- matrix(NA,length(df[,1]),length(pred.dates))#
    predict.surv <- matrix(1,length(df[,1]),length(pred.dates))#
        #
    for (k in 1:length(df[,1])) {#
        x <- as.numeric(dates.raw[k,])#
        y <- sizes.raw[k,]#
#
        bad <- is.na(x) | is.na(y)#
        x <- x[!bad]#
        y <- y[!bad]#
     #
        #linear regression#
        if (length(x)<4) { #
            fit <- lm(y~x)#
            predict.sizes[k,] <- predict(fit,newdata=data.frame(x=pred.dates)) #linear reg#
        } else { #
        #smooth spline#
            fit <- smooth.spline(y~x)#
            predict.sizes[k,] <- predict(fit,x=pred.dates)$y #smooth spline#
        }#
            #
        bad <- which(pred.dates>max(x,na.rm=TRUE), arr.ind=TRUE)#
        if (length(bad)>0) predict.sizes[k,bad] <- NA#
        #
        dead <- dates.raw[k,surv.raw[k,]==0][1]#
        loc.dead <- which((dead-pred.dates)^2==min((dead-pred.dates)^2), arr.ind=TRUE)#
        if (length(loc.dead)>0) predict.surv[k,loc.dead:length(pred.dates)] <- 0              #
    }#
#
    #reassure yourself it might work#
#    matplot(t(dates.raw),t(sizes.raw), type="b", pch=19,xlab="dates", ylab="sizes")#
#    abline(v=pred.dates)#
#
        #
    dataf <- data.frame(size=c(predict.sizes[,1:5]),sizeNext=c(predict.sizes[,2:6]),#
                        incr=c(incr[,1:5]),#
                        surv=c(predict.surv[,2:6]), spcode=rep(df$SpCode, 5),#
                        exactDate=c(dates.raw[,1:5]), exactDatel=c(dates.raw[,2:6]))#
#
    dataf <- dataf[!is.na(dataf$size),]#
    #
    return(dataf)#
#
}#
#
#
#
#
#
#
## Function to fit survival with varying time increments and then write parameters#
## over onto a classic glm framework. #
##
# parameters - dataf - a dataframe including columns#
#                  size, surv, exactDate, and exactDatel, the latter two in days#
#            - nyrs - desired number of years in a time-step#
#            - par - starting values for the parameters#
#                     (must be of length one longer than covNames,#
#                       given intercept)#
#            - covNames - names of chosen covariates#
#            - method - method for optim ("Nelder-Mead", "SANN", etc.)#
##
# Returns  - output of optim#
##
fitSurvVaryingTimeIntervals <- function(dataf,#
                                        nyrs=5,#
                                        par=c(0.01,0.01,0.01,0.01),#
                                        covNames=c("size","size2","size3"),#
                                        method="Nelder-Mead") {#
#
    #warnings#
    if ((length(par)-1)!=length(covNames)) {#
        print("starting values does not match length of covariate names")#
    }#
#
    #
    tmp <- optim(par,likeSurvVaryingTimeIntervals,#
                 covNames=covNames,nyrs=nyrs,dataf=dataf,#
                 method=method)#
#
    #
    if (tmp$convergence!=0) {#
        tmp <- optim(tmp$par,likeSurvVaryingTimeIntervals,#
                     covNames=covNames,nyrs=nyrs,dataf=dataf,#
                     method=method)#
        if (tmp$convergence!=0)  print("not converged")        #
    }#
    #
    #write template over the top#
    if (length(covNames)>0) formula <- as.character(paste("surv~",paste(covNames,collapse="+"),collapse="")) else formula <- as.character("surv~1")#
    fit <- glm(formula,data=dataf,family=binomial)#
    #print(fit)#
    fit$coefficients <- tmp$par#
#
    sv1 <- new("survObj")#
    sv1@fit <- fit#
#
    tmp$sv1 <- sv1#
    #
    return(tmp)#
#
}#
#
#Function to calculate the likelihood for variable time-intervals for survival #
##
# parameters #
#            - par - starting values for the parameters#
#                     (must be of length one longer than covNames,#
#                       given intercept)#
#            - covNames - names of chosen covariates#
#            - nyrs - desired number of years in a time-step#
#            - dataf - a dataframe including columns in covNames, as well as#
#                  size, surv, exactDate, and exactDatel, the latter two in days#
##
# Returns  - numeric equal to minus the log likelihood#
##
likeSurvVaryingTimeIntervals <- function(par=c(0.01,0.01,0.01,0.01),#
                                         covNames=c("size","size2","size3"),#
                                         nyrs=5,#
                                         dataf) {#
#
    #
    #define time change#
    tdiff <- (dataf$exactDatel-dataf$exactDate)/(nyrs*365)#
    #print(range(tdiff, na.rm=TRUE))#
#
    #print(covNames)#
    #print(head(dataf[,covNames]))#
    #
    #build predictor#
    if (length(covNames)>0) {#
        pred <-  t(t(dataf[,covNames])*par[2:length(par)])#
    }else { pred <- matrix(0,nrow(dataf),1)}#
    pred <- par[1] + rowSums(pred)#
    pred[pred>200] <- 200  #don't want bigger than exp(200) - gets infinite really quick#
    pred <- (exp(pred)/(1+exp(pred)))^(tdiff)#
#
    print(range(pred))#
    #
    #estimate likelihood#
    like <- dbinom(dataf$surv,1,pred, log=TRUE)#
    #like[like==-Inf] <- -exp(500)#
    #like[like==Inf] <- exp(500)#
#
    sumRows <- rep(0,nrow(dataf))#
    if (length(covNames)>1) sumRows <- rowSums(dataf[,covNames])#
    if (length(covNames)==1) sumRows <- dataf[,covNames]#
    #
    return(-sum(like[!is.na(sumRows) & !is.na(dataf$surv)],na.rm=TRUE))#
    #
}#
#
#
##note that there are very few species for which sufficient#
## mortality data is actually available! most just don't die...#
##
# vain, myda, hubr#
##
##
compareTmatrices <- function(dataf, growthObjList,survObjList, nBigMatrix=300,chosen.size=1500,#
                             do.plot=TRUE,do.legend=FALSE,...){ #
    #
    #STORAGE#
    LE <- LE1 <- ptime <- ptime1 <- array(dim=c(length(survObjList),length(growthObjList),nBigMatrix))#
      #
    ## LOOP OVER all possible combos#
    for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
             #
                sv1 <- survObjList[[j]]#
                gr1 <- growthObjList[[k]]#
                              #
                #BUILD Tmatrix#
                Tmatrix <- create.IPM.Tmatrix(nBigMatrix = nBigMatrix,#
                                              minSize = 0.9*min(dataf$size,na.rm=TRUE),#
                                              maxSize = 1.1*max(dataf$size,na.rm=TRUE),#
                                              growObj = gr1, survObj = sv1, correction="constant")#
                Tmatrix1 <- create.IPM.Tmatrix(nBigMatrix = nBigMatrix,#
                                               minSize = 0.9*min(dataf$size,na.rm=TRUE),#
                                               maxSize = 1.1*max(dataf$size,na.rm=TRUE),#
                                               growObj = gr1, survObj = sv1,integrate.type="cumul",#
                                               correction="constant")#
        #
                # Get the mean life expect from every size value in IPM#
                LE[j,k,] <- MeanLifeExpect(Tmatrix)#
                ptime[j,k,] <- PassageTime(chosen.size=chosen.size,Tmatrix); #print(ptime)#
                LE1[j,k,] <- MeanLifeExpect(Tmatrix1)#
                ptime1[j,k,] <- PassageTime(chosen.size=chosen.size,Tmatrix1); #print(ptime)#
#
    #
            }}#
#
    ## PLOT#
    if (do.plot) { #
#
        nyr <- 4#
        j<-k<-1#
        plot(Tmatrix@meshpoints,LE[j,k,]*nyr,type="l",xlab="size", ylab="life expectancy",#
             ylim=pmax(range(c(LE*nyr,LE1*nyr),na.rm=TRUE),1),...)#
#
        for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
                points(Tmatrix@meshpoints,LE[j,k,]*nyr,type="l",col=k)#
                points(Tmatrix1@meshpoints,LE1[j,k,]*nyr,type="l",col=k, lty=3)#
#
            }}#
#
        if (do.legend) { legend("bottomleft", legend=c("Power Law", "Monomolecular",#
                                              "Gompertz", "Logistic 3 par", "Logistic 4 par"),#
                                lty=1, col=1:5, bty="n", cex=0.8)}#
                         #
        #
        j<-k<-1#
        plot(Tmatrix@meshpoints,ptime[j,k,]*nyr,type="l",xlab="size", ylab="passage time",#
             ylim=pmax(range(c(ptime*nyr,ptime1*nyr),na.rm=TRUE),1),...)#
        for (j in 1:length(survObjList)){#
            for (k in 1:length(growthObjList)){#
                points(Tmatrix@meshpoints,ptime[j,k,]*nyr,type="l",col=k)#
                points(Tmatrix1@meshpoints,ptime1[j,k,]*nyr,type="l",col=k,lty=3)#
#
            }}#
#
  #
    }#
            #
    #
   return(list(LE=LE,LE1=LE1,ptime=ptime,ptime1=ptime1, sizes=Tmatrix@meshpoints))#
    #
}#
#
#
#
#
#
## Function to fit survival models and compare liklelihoods#
# works with maximizing likelihoods. It will help the function if the models#
# are ordered in increasing nestedness, since R will use parameters estimated for#
# first as starting values for next. #
#
survModelCompVaryInterval <- function(dataf,#
                                      expVars = c("1", "size", "size + size2"), #
                                      testType = "AIC",#
                                      makePlot = FALSE,#
                                      mainTitle = "",#
                                      nyrs=4) {#
    require(stringr)#
#
    #
        varN <- length(expVars)#
	treatN <- varN#
	summaryTable <- data.frame()#
	svObj <- vector("list", length = treatN)#
#
        parStart <- 0.01#
        newd <- dataf#
        #
	i <- 1#
	for(v in 1:varN) {#
            print(expVars[v])#
               #
            if (expVars[v]=="1") {#
                covNames <- c() } else {#
                    covNames <- str_trim(strsplit(as.character(expVars[v]),"[\\+]")[[1]])#
                }#
            parStart <- c(parStart,rep(0.01,length(covNames)-length(parStart)+1))#
            print(parStart)#
            #
            #make sure you have all the right covariates#
            if(length(grep("size2",expVars[v]))==1)#
			dataf$size2=(dataf$size)^2#
            if(length(grep("size3",expVars[v]))==1)#
			dataf$size3=(dataf$size)^3#
            if(length(grep("logsize",expVars[v]))==1)#
			dataf$logsize=log(dataf$size)#
            if(length(grep("logsize2",expVars[v]))==1)#
			dataf$logsize=(log(dataf$size))^2#
#
            print('starting value")#
            print(likeSurvVaryingTimeIntervals(par=parStart,#
                                         covNames=covNames,#
                                         nyrs=4,#
                                         dataf=dataf))#
       #
            tmp <- fitSurvVaryingTimeIntervals(dataf=dataf,nyrs=nyrs,par=parStart,covNames=covNames)#
#
            parStart <- tmp$par#
        #
            svObj[[i]] <- tmp$sv1#
            #
            if (testType=="AIC") val <- (2*length(covNames)+1)-2*tmp$value#
            if (testType=="logLik") val <- tmp$value#
            if (testType!="AIC" & testType!="logLik") { print("Unknown test; chose AIC or logLik"); val <- NA}  #
#
            summaryTable <- rbind(summaryTable, cbind(expVars[v], val))#
            i <- i + 1#
	}#
	summaryTable <- as.data.frame(summaryTable)#
	names(summaryTable) <- c("Exp. Vars", testType)#
	outputList <- list(summaryTable = summaryTable, survObjects = svObj)#
	#
	# PLOT SECTION ##
	if(makePlot == TRUE) {#
		## this is the surv picture    #
		plotSurvModelComp(svObj = svObj,#
                                  summaryTable = summaryTable,#
                                  dataf = dataf, expVars = expVars,#
                                  testType = testType, plotLegend = TRUE, mainTitle = mainTitle)#
	}#
	return(outputList)#
#
}#
#
#
#
test <- function(){#
    #do simple to complicated, and use parameters from previous as starting values#
    m <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=0.01,cov.names=c())#
    m0 <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(0.01,0.01),cov.names=c("size"))#
    m1 <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m0$par,0),cov.names=c("size","size2"))#
    m2 <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m1$par,0),cov.names=c("size","size2","size3"))#
    #
    print("Comparison intercept and size")#
    print(1-pchisq(2*(m$value-m0$value),1))#
    print("Comparison size and size2")#
    print(1-pchisq(2*(m0$value-m1$value),1))#
    print("Comparison size2 and size3")#
    print(1-pchisq(2*(m1$value-m2$value),1))#
#
    m0a <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m0$par),cov.names=c("logsize"))#
    m1a <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m0$par,0),cov.names=c("size","logsize"))#
    m2a <- fitSurvVaryingTimeIntervals(dataf,nyrs=4,par=c(m1a$par,0),cov.names=c("size","logsize","logsize2"))#
#
    print("Comparison intercept and logsize")#
    print(1-pchisq(2*(m$value-m0a$value),1))#
    print("Comparison logsize and size+logsize")#
    print(1-pchisq(2*(m0a$value-m1a$value),1))#
    print("Comparison logsize and logsize2")#
    print(1-pchisq(2*(m1a$value-m2a$value),1))#
#
    print("Direct comparison likelihoods")#
    vals <- -c(m$value,m0$value,m1$value,m2$value,m0a$value,m1a$val,m2a$value) #log likelihood#
    AIC <- 2*c(length(m$par),length(m0$par),length(m1$par),length(m2$par),length(m0a$par),length(m1a$par),length(m2a$par))-2*vals#
    nmes <- c("1","size","size+size2","size+size2+size3","logsize","size+logsize","size+logsize+logsize2")#
    print(cbind(nmes,vals,AIC,order(vals)))#
    #
#
    if (plot) {#
        sizes <- seq(min(dataf$size,na.rm=TRUE), max(dataf$size,na.rm=TRUE),length=100)#
        picSurvData(dataf,ncuts=20)#
        points(sizes,surv(sizes,1,m$sv1),type="l",col=4, lty=2)#
        points(sizes,surv(sizes,1,m0$sv1),type="l",col=1, lty=2)#
        points(sizes,surv(sizes,1,m1$sv1),type="l",col=2, lty=2)#
        points(sizes,surv(sizes,1,m2$sv1),type="l",col=3, lty=2)#
        points(sizes,surv(sizes,1,m0a$sv1),type="l",col=1, lty=3)#
        points(sizes,surv(sizes,1,m1a$sv1),type="l",col=2, lty=3)#
        points(sizes,surv(sizes,1,m2a$sv1),type="l",col=3, lty=3)#
        legend("bottomleft", legend=paste(nmes,paste(", AIC=",round(AIC,1), sep="")), text.col=c(4,1:3,1:3),#
               col=c(4,1:3,1:3),lty=c(2,rep(2,3),rep(3,3)), bty="o", cex=0.8,bg="white",box.col="white")#
     #
    }#
#
    return(list(m=m,m0=m0,m1=m1,m2=m2,m0a=m0a,m1a=m1a,m2a=m2a))#
                 #
}#
#
#
#
#
## Just make a picture of the survival probs from the data#
## [Useful for overlaying various fits...]#
picSurvData <- function(dataf,ncuts=12,...) { #
#
    #organize data and plot mean of ncut successive sizes, so trend more obvious#
    os<-order(dataf$size); os.surv<-(dataf$surv)[os]; os.size<-(dataf$size)[os]; #
    psz<-tapply(os.size,as.numeric(cut(os.size,ncuts)),mean,na.rm=TRUE); #print(psz)#
    ps<-tapply(os.surv,as.numeric(cut(os.size,ncuts)),mean,na.rm=TRUE);#print(ps)#
#
    #plot data#
    plot(as.numeric(psz),as.numeric(ps),pch=19,#
         xlab="Size at t", ylab="Survival to t+1",...)#
    #
}#
#
likeCompareClassicGrowthFits <- function(dataf, plot=FALSE,responseType="sizenext") {#
#
    #Function to create a time-scaled incr or log increment (the incr in the dataf is actually the "true"#
    # over the arbitrary census interval)#
    if (responseType=="incr") dataf$incr <- (dataf$sizenext-dataf$size)#
    if (responseType=="logincr") dataf$logincr <- log(dataf$sizenext-dataf$size)#
    #
    #do simple to complicated, and use parameters from previous as starting values#
    m <- makeGrowthObjGeneral(dataf,explanatoryVariables="1",#
                               responseType=responseType,regType="constantVar")#
    m0 <- makeGrowthObjGeneral(dataf,explanatoryVariables="size",#
                               responseType=responseType,regType="constantVar")#
    m1 <- makeGrowthObjGeneral(dataf,explanatoryVariables="size+size2",#
                               responseType=responseType,regType="constantVar")#
    m2 <- makeGrowthObjGeneral(dataf,explanatoryVariables="size+size2+size3",#
                               responseType=responseType,regType="constantVar")#
    m0a <- makeGrowthObjGeneral(dataf,explanatoryVariables="logsize",#
                               responseType=responseType,regType="constantVar")#
    m1a <- makeGrowthObjGeneral(dataf,explanatoryVariables="logsize+size",#
                               responseType=responseType,regType="constantVar")#
    m2a <- makeGrowthObjGeneral(dataf,explanatoryVariables="logsize+size+size2",#
                               responseType=responseType,regType="constantVar")#
#
    print(anova(m@fit,m0@fit,test="Chi"))#
    print(anova(m0@fit,m1@fit,test="Chi"))#
    print(anova(m1@fit,m2@fit,test="Chi"))#
#
    print(anova(m@fit,m0a@fit,test="Chi"))#
    print(anova(m0a@fit,m1a@fit,test="Chi"))#
    print(anova(m1a@fit,m2a@fit,test="Chi"))#
#
#
    if (plot){#
        scalar <- 100; minsc <- 1e-9#
        sizes <- seq(min(dataf$size,na.rm=TRUE), max(dataf$size,na.rm=TRUE),length=500)#
        chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
        newd<-data.frame(size=sizes,size2=sizes^2,size3=sizes^3,logsize=log(sizes))#
        if (responseType=="sizenext")#
            plot(dff$size,dff$sizenext, pch=19,col="grey", xlab="Size at t", ylab="Size at t+delta")#
        if (responseType=="incr")#
            plot(dff$size,dff$incr, pch=19,col="grey", xlab="Size at t", ylab="Incr at t+delta")#
        if (responseType=="logincr")#
            plot(dff$size,dff$logincr, pch=19,col="grey", xlab="Size at t", ylab="Incr at t+delta")#
        if (responseType!="sizenext")points(sizes,predict(m@fit,newdata=newd),type="l",col=4, lty=2)#
        points(sizes,predict(m0@fit,newdata=newd),type="l",col=1, lty=2)#
        points(sizes,predict(m1@fit,newdata=newd),type="l",col=2, lty=2)#
        points(sizes,predict(m2@fit,newdata=newd),type="l",col=3, lty=2)#
        #points(sizes,predict(m0a@fit,newdata=newd),type="l",col=1, lty=3)#
        #points(sizes,predict(m1a@fit,newdata=newd),type="l",col=2, lty=3)#
        #points(sizes,predict(m2a@fit,newdata=newd),type="l",col=3, lty=3)#
        #
        for (k in 1:length(chs)) {#
            resp <- growth(sizes[chs[k]],sizes,1,m)*scalar; #resp[resp<minsc] <- NA   #
            if (responseType!="sizenext")#
                points(sizes[chs[k]]+resp,sizes, type="l", col=4, lty=2)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,m0)*scalar; #resp[resp<minsc] <- NA#
            #print(sizes[chs[k]]+resp)#
            points(sizes[chs[k]]+resp,sizes, type="l", col=1, lty=2)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,m1)*scalar; #resp[resp<minsc] <- NA   #
            points(sizes[chs[k]]+resp,sizes, type="l", col=2, lty=2)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,m2)*scalar; resp[resp<minsc] <- NA   #
            points(sizes[chs[k]]+resp,sizes, type="l", col=3, lty=2)                                       #
            #resp <- growth(sizes[chs[k]],sizes,1,m0a)*scalar; resp[resp<minsc] <- NA   #
            #points(sizes[chs[k]]+resp,sizes, type="l", col=1, lty=3)                                       #
            #resp <- growth(sizes[chs[k]],sizes,1,m1a)*scalar; resp[resp<minsc] <- NA   #
            #points(sizes[chs[k]]+resp,sizes, type="l", col=2, lty=3)                                       #
            #resp <- growth(sizes[chs[k]],sizes,1,m2a)*scalar; resp[resp<minsc] <- NA   #
            #points(sizes[chs[k]]+resp,sizes, type="l", col=3, lty=3)                                       #
        }#
          #
    }#
#
    return(list(m=m,m0=m0,m1=m1,m2=m2,m0a=m0a,m1a=m1a,m2a=m2a))#
}#
#
#
####################################################################################################
##
##
## Make Figure 1- showning basic qualities of the data ####
## for three species with sufficient mortality info ######
##
FigureOne <- function(){#
#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
#
    #
    # 1. create exact times figure#
    par(mfrow=c(1,3),bty="l")#
    brks <- c(-0.5,1.5,2.5,3.5,4.5,5.5)#
    #
    for (k in 1:length(sp.list)) {#
        a1<-hist(c(dff$exactDatel[dff$spcode==sp.list[k]]-dff$exactDate[dff$spcode==sp.list[k]])/365,#
        breaks=brks, plot=FALSE)#
        if (k==1) cts <- a1$counts#
        if (k>1) cts <- rbind(cts,a1$counts)#
    #
    }#
#
    barplot(cts,beside=TRUE, names.arg=c("<1","2","3","4","5"), xlab="Census interval (years)")#
    legend("topleft",legend=sp.names,col=gray.colors(length(sp.list)), pch=15, bty="n")#
#
    # 2. Create survival figure#
    sp.num <- rep(1,length(dff$spcode));#
    for (k in 2:length(sp.list)) sp.num[dff$spcode==sp.list[k]] <- k#
    surv.sp <- dff$surv + 10*sp.num#
    boxplot(dff$size~surv.sp,log="y",axes="FALSE", xlab="Survival status",#
            ylab="DBH (cm)", col=rep(gray.colors(length(sp.list)), each=2))#
    axis(2)#
    axis(1,at=1:6,lab=c(0,1,0,1,0,1))#
    legend("topright",legend=sp.names,col=gray.colors(length(sp.list)), pch=15, bty="n")#
#
    #
    # 3. Create corrected growth increment figure#
    incr.corrected <- dff$incr/((dff$exactDatel-dff$exactDate)/365)#
    boxplot(incr.corrected~sp.num, col=gray.colors(length(sp.list)),axes=FALSE,#
            ylab="Time adjusted increment (cm)", ylim=c(-1.5,5))#
    abline(h=0,lty=3)#
    legend("topright",legend=sp.names,col=gray.colors(length(sp.list)), pch=15, bty="n")#
    axis(2)#
    axis(1,at=1:3,lab=sp.names)#
    #
    #
    #
#
}#
#
#
#
#
## Make Figure 2 - various survival models#
##
##
FigureTwo <- function(){#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
#
    par(mfrow=c(1,3),bty="l",family = "Helvetica")#
    #
    res1 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE)#
    title(sp.names[1])#
    res2 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    title(sp.names[2])#
    res3 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    title(sp.names[3])#
#
#
}#
#
#
## Make Figure 3 - various growth models with data, and then predicted size, sizenext and densty functions#
##
#  NOTE - that this should be using the ADJUSTED increment, hence over-written below by difference sizenext-size#
#  which was obtained via the spline#
##
FigureThree <- function(){#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
    dff$incr <- dff$sizenext - dff$size#
    #
    #pic with the data - get all the estimates#
    par(mfrow=c(3,5),bty="l", pty="m")#
    res1 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE, plot.title=TRUE)#
    mtext(sp.names[1])#
    res2 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    mtext(sp.names[2])#
    res3 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    mtext(sp.names[3])#
#
    #pic size, size next with density functions on#
    par(mfrow=c(1,3),bty="l")#
    sizes <- seq(min(dff$size,na.rm=TRUE), max(dff$size,na.rm=TRUE),length=500)#
    chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
    scalar <- 100; minsc <- 0.0001#
   #
    for (j in 1:length(sp.list)) { #
        plot(dff$size[dff$spcode==sp.list[j]],dff$sizenext[dff$spcode==sp.list[j]], pch=19,col="grey", xlab="Size at t", ylab="Size at t+delta")#
        mtext(sp.names[j])#
#
        sizes <- seq(min(dff$size[dff$spcode==sp.list[j]],na.rm=TRUE),#
                       max(dff$size[dff$spcode==sp.list[j]],na.rm=TRUE),length=500)#
        chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
  #
        for (k in 1:length(chs)) {#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m1)*scalar; resp[resp<minsc] <- NA   #Power Law#
            points(sizes[chs[k]]+resp,sizes, type="l", col=1)                                       #
            resp <- growth(sizes[chs[k]],sizes,1,res1$m2)*scalar; resp[resp<minsc] <- NA   #Monomolecular#
            points(sizes[chs[k]]+resp,sizes, type="l", col=2)#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m3)*scalar; resp[resp<minsc] <- NA   #Gompertz#
            points(sizes[chs[k]]+resp,sizes, type="l", col=3)                                #
            resp <- growth(sizes[chs[k]],sizes,1,res1$m4)*scalar; resp[resp<minsc] <- NA   #Logistic 3#
            points(sizes[chs[k]]+resp,sizes, type="l", col=4)#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m5)*scalar; resp[resp<minsc] <- NA   #Logistic 4#
            points(sizes[chs[k]]+resp,sizes, type="l", col=5)#
            resp <- growth(sizes[chs[k]],sizes,1,res1$m6)*scalar; resp[resp<minsc] <- NA   #Hossfeld#
            points(sizes[chs[k]]+resp,sizes, type="l", col=6)#
            #
        }#
        if (j==1) legend("topleft", legend=c("Power Law", "Monomolecular",#
                                    "Gompertz", "Logistic 3 par", "Logistic 4 par", "Hossfeld"),#
            lty=1, col=1:6, bty="n", cex=0.8)#
        abline(0,1,lty=3)#
        #
    }#
#
    #pic just of increments#
    chs <- floor(quantile(1:length(sizes),c(0.2,0.4,0.6,0.8)))#
    par(mfrow=c(3,1), bty="l",pty="m")#
    scalar <- 1#
    for (j in 1:3) { #
        plot(sizes, sizes, ylim=c(0,0.35),#
             type="n", xlab="Size", ylab="Density in next time-step", xlim=range(sizes[c(chs+10,chs-10)]))#
        for (k in 1:length(chs)) {#
#
            if (j==1) res <- res1#
            if (j==2) res <- res2#
            if (j==3) res <- res3            #
                                        #Power Law#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m1)*scalar, type="l", col=1)#
                                        #Monomolecular#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m2)*scalar, type="l", col=2)#
                                        #Gompertz#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m3)*scalar, type="l", col=3)#
                                        #Logistic 3#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m4)*scalar, type="l", col=4)#
                                        #Logistic 4#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m5)*scalar, type="l", col=5)#
            points(sizes,#
                   growth(sizes[chs[k]],sizes,1,res$m6)*scalar, type="l", col=6)#
            #
        }#
        if (j==1) legend(110,0.35,#
            legend=c("Power Law", "Monomolecular","Gompertz", "Logistic 3 par", "Logistic 4 par","Hossfeld"),#
            lty=1, col=1:6, bty="n", cex=0.8)#
        mtext(sp.names[j])#
        abline(v=sizes[chs], lty=3)#
        #
    }#
    #
    return(list(res1=res1,res2=res2,res3=res3))#
}#
#
#
#
Figure4 <- function(){#
#
#
    sp.list <- c("vain", "myda", "hubr")#
    sp.names <- c("Vateria indica", "Myristica dactyloides", "Humboldtia brunonis")#
#
    #get data#
    dff <- getData(filename="/Users/cjessicametcalf/Documents/IPM/data/",#
                   species="all")#
    dff <- dff[dff$spcode==sp.list[1] | dff$spcode==sp.list[2] | dff$spcode==sp.list[3],]#
    dff$incr <- dff$sizenext - dff$size#
    #
    #pic with the data for growth - get all the estimates#
    par(mfrow=c(3,5),bty="l", pty="m")#
    grow.res1 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE, plot.title=TRUE)#
    mtext(sp.names[1])#
    grow.res2 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    mtext(sp.names[2])#
    grow.res3 <- likeCompGrowthMech(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    mtext(sp.names[3])#
#
    #same for survival#
    surv.res1 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[1],], plot=TRUE)#
    title(sp.names[1])#
    surv.res2 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[2],], plot=TRUE)#
    title(sp.names[2])#
    surv.res3 <- likeCompSurvVaryInterval(dataf=dff[dff$spcode==sp.list[3],], plot=TRUE)#
    title(sp.names[3])#
#
#
    #picture    #
    par(mfrow=c(2,2),bty="l")#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[1],],log="y",#
                           growthObjList=grow.res1[1:5],#
                           survObjList=list(surv.res1$m0$sv1), nBigMatrix=300,chosen.size=1500,#
                           do.legend=TRUE)#
    mtext(sp.list[1],side=3)#
#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[1],],log="y",#
                           growthObjList=grow.res1[1:5],#
                           survObjList=list(surv.res1$m1$sv1), nBigMatrix=300,chosen.size=1500)#
#
#
    par(mfrow=c(2,2),bty="l")#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[2],],log="y",#
                           growthObjList=grow.res2[1:5],#
                           survObjList=list(surv.res2$m0$sv1), nBigMatrix=300,chosen.size=1500,#
                           do.legend=TRUE)#
    mtext(sp.list[2],side=3)#
#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[2],],log="y",#
                           growthObjList=grow.res2[1:5],#
                           survObjList=list(surv.res2$m1$sv1), nBigMatrix=300,chosen.size=1500)#
#
    par(mfrow=c(2,2),bty="l")#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[3],],log="y",#
                           growthObjList=grow.res3[1:5],#
                           survObjList=list(surv.res3$m0$sv1), nBigMatrix=300,chosen.size=1500,#
                           do.legend=TRUE)#
    mtext(sp.list[3],side=3)#
#
#
    a1 <- compareTmatrices(dataf=dff[dff$spcode==sp.list[3],],log="y",#
                           growthObjList=grow.res3[1:5],#
                           survObjList=list(surv.res3$m1$sv1), nBigMatrix=300,chosen.size=1500)#
#
    #
}
}
}
"{}}"
}
"
}
